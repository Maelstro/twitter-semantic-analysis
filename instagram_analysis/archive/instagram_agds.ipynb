{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instagram data analysis\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>441.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>535.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>531.000000</td>\n",
       "      <td>531.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>535.000000</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>535.000000</td>\n",
       "      <td>532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.648526</td>\n",
       "      <td>2.338710</td>\n",
       "      <td>1.953425</td>\n",
       "      <td>1.180723</td>\n",
       "      <td>2.107784</td>\n",
       "      <td>1.451327</td>\n",
       "      <td>1.946701</td>\n",
       "      <td>1.879656</td>\n",
       "      <td>2.894967</td>\n",
       "      <td>2.389785</td>\n",
       "      <td>...</td>\n",
       "      <td>2.082243</td>\n",
       "      <td>2.737336</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>2.137476</td>\n",
       "      <td>2.367925</td>\n",
       "      <td>2.130841</td>\n",
       "      <td>2.801126</td>\n",
       "      <td>2.547710</td>\n",
       "      <td>1.289720</td>\n",
       "      <td>2.609023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.884875</td>\n",
       "      <td>1.110259</td>\n",
       "      <td>1.301107</td>\n",
       "      <td>1.092624</td>\n",
       "      <td>1.051411</td>\n",
       "      <td>1.103983</td>\n",
       "      <td>1.293830</td>\n",
       "      <td>1.155876</td>\n",
       "      <td>0.796041</td>\n",
       "      <td>1.152147</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240983</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>1.192531</td>\n",
       "      <td>1.383845</td>\n",
       "      <td>0.994555</td>\n",
       "      <td>1.371760</td>\n",
       "      <td>1.008348</td>\n",
       "      <td>1.131681</td>\n",
       "      <td>1.264684</td>\n",
       "      <td>1.153621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         innocent        sage    explorer      outlaw    magician        hero  \\\n",
       "count  441.000000  372.000000  365.000000  332.000000  334.000000  339.000000   \n",
       "mean     2.648526    2.338710    1.953425    1.180723    2.107784    1.451327   \n",
       "std      0.884875    1.110259    1.301107    1.092624    1.051411    1.103983   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      2.000000    1.000000    1.000000    0.000000    1.000000    1.000000   \n",
       "50%      3.000000    3.000000    2.000000    1.000000    2.000000    1.000000   \n",
       "75%      3.000000    3.000000    3.000000    2.000000    3.000000    2.000000   \n",
       "max      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "\n",
       "            lover      jester    everyman   caregiver  ...  protective  \\\n",
       "count  394.000000  349.000000  457.000000  372.000000  ...  535.000000   \n",
       "mean     1.946701    1.879656    2.894967    2.389785  ...    2.082243   \n",
       "std      1.293830    1.155876    0.796041    1.152147  ...    1.240983   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      1.000000    1.000000    3.000000    1.000000  ...    1.000000   \n",
       "50%      2.000000    2.000000    3.000000    3.000000  ...    2.000000   \n",
       "75%      3.000000    3.000000    3.000000    3.000000  ...    3.000000   \n",
       "max      4.000000    4.000000    4.000000    4.000000  ...    4.000000   \n",
       "\n",
       "         generous     thrifty  favourable    balanced  sensuality  \\\n",
       "count  533.000000  531.000000  531.000000  530.000000  535.000000   \n",
       "mean     2.737336    1.355932    2.137476    2.367925    2.130841   \n",
       "std      0.737333    1.192531    1.383845    0.994555    1.371760   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      2.000000    0.000000    1.000000    1.000000    1.000000   \n",
       "50%      3.000000    1.000000    3.000000    3.000000    3.000000   \n",
       "75%      3.000000    2.000000    3.000000    3.000000    3.000000   \n",
       "max      4.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "\n",
       "       intelligent     believe  egocentric  allocentric  \n",
       "count   533.000000  524.000000  535.000000   532.000000  \n",
       "mean      2.801126    2.547710    1.289720     2.609023  \n",
       "std       1.008348    1.131681    1.264684     1.153621  \n",
       "min       0.000000    0.000000    0.000000     0.000000  \n",
       "25%       2.000000    2.000000    0.000000     2.000000  \n",
       "50%       3.000000    3.000000    1.000000     3.000000  \n",
       "75%       4.000000    3.000000    2.000000     3.000000  \n",
       "max       4.000000    4.000000    4.000000     4.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the .csv with annotated data\n",
    "arch_df = pd.read_csv('archetypes_pl.csv', index_col=0)\n",
    "\n",
    "# Get the DataFrame description\n",
    "arch_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marek_grodzki</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vege_style_life</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliwka__2007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_przestrzeni_serca</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaradne_warsztaty</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "id                                                                             \n",
       "marek_grodzki             0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "vege_style_life           0.0   0.0       4.0     0.0       0.0   0.0    0.0   \n",
       "oliwka__2007              0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "z_przestrzeni_serca       4.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "zaradne_warsztaty         3.0   0.0       0.0     0.0       3.0   0.0    0.0   \n",
       "\n",
       "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
       "id                                                ...                         \n",
       "marek_grodzki           4.0       0.0        0.0  ...         2.0       3.0   \n",
       "vege_style_life         0.0       0.0        0.0  ...         4.0       4.0   \n",
       "oliwka__2007            0.0       4.0        0.0  ...         2.0       2.0   \n",
       "z_przestrzeni_serca     0.0       0.0        0.0  ...         4.0       3.0   \n",
       "zaradne_warsztaty       2.0       3.0        4.0  ...         3.0       4.0   \n",
       "\n",
       "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "id                                                                            \n",
       "marek_grodzki            4.0         4.0       3.0         4.0          4.0   \n",
       "vege_style_life          4.0         4.0       3.0         3.0          3.0   \n",
       "oliwka__2007             0.0         3.0       1.0         2.0          4.0   \n",
       "z_przestrzeni_serca      0.0         4.0       4.0         3.0          4.0   \n",
       "zaradne_warsztaty        0.0         2.0       2.0         4.0          2.0   \n",
       "\n",
       "                     believe  egocentric  allocentric  \n",
       "id                                                     \n",
       "marek_grodzki            3.0         0.0          0.0  \n",
       "vege_style_life          2.0         0.0          3.0  \n",
       "oliwka__2007             1.0         0.0          3.0  \n",
       "z_przestrzeni_serca      4.0         0.0          1.0  \n",
       "zaradne_warsztaty        3.0         1.0          3.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of the dataset\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marek_grodzki</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vege_style_life</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliwka__2007</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_przestrzeni_serca</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaradne_warsztaty</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "id                                                                             \n",
       "marek_grodzki            -1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "vege_style_life          -1.0  -1.0       1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "oliwka__2007             -1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "z_przestrzeni_serca       1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "zaradne_warsztaty         0.5  -1.0      -1.0    -1.0       0.5  -1.0   -1.0   \n",
       "\n",
       "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
       "id                                                ...                         \n",
       "marek_grodzki           1.0      -1.0       -1.0  ...         0.0       0.5   \n",
       "vege_style_life        -1.0      -1.0       -1.0  ...         1.0       1.0   \n",
       "oliwka__2007           -1.0       1.0       -1.0  ...         0.0       0.0   \n",
       "z_przestrzeni_serca    -1.0      -1.0       -1.0  ...         1.0       0.5   \n",
       "zaradne_warsztaty       0.0       0.5        1.0  ...         0.5       1.0   \n",
       "\n",
       "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "id                                                                            \n",
       "marek_grodzki            1.0         1.0       0.5         1.0          1.0   \n",
       "vege_style_life          1.0         1.0       0.5         0.5          0.5   \n",
       "oliwka__2007            -1.0         0.5      -0.5         0.0          1.0   \n",
       "z_przestrzeni_serca     -1.0         1.0       1.0         0.5          1.0   \n",
       "zaradne_warsztaty       -1.0         0.0       0.0         1.0          0.0   \n",
       "\n",
       "                     believe  egocentric  allocentric  \n",
       "id                                                     \n",
       "marek_grodzki            0.5        -1.0         -1.0  \n",
       "vege_style_life          0.0        -1.0          0.5  \n",
       "oliwka__2007            -0.5        -1.0          0.5  \n",
       "z_przestrzeni_serca      1.0        -1.0         -0.5  \n",
       "zaradne_warsztaty        0.5        -0.5          0.5  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN values with Unrelated/Don't Know class\n",
    "arch_df = arch_df.fillna(2.0)\n",
    "\n",
    "# Replace values: 0 is -1, 1 is -0.5, 2 is 0.0, 3 is 0.5, 4 is 1.0\n",
    "arch_df = arch_df.replace(0.0, -1.0)\n",
    "arch_df = arch_df.replace(1.0, -0.5)\n",
    "arch_df = arch_df.replace(2.0, 0.0)\n",
    "arch_df = arch_df.replace(3.0, 0.5)\n",
    "arch_df = arch_df.replace(4.0, 1.0)\n",
    "arch_df = arch_df[~arch_df.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "# Print the head of the dataset after modification\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'innocent': -1.0, 'sage': -1.0, 'explorer': -1.0, 'outlaw': -1.0, 'magician': -1.0, 'hero': -1.0, 'lover': -1.0, 'jester': 1.0, 'everyman': -1.0, 'caregiver': -1.0, 'ruler': -1.0, 'creator': -1.0, 'dominant': 0.5, 'submissive': 3.0, 'maximalist': 0.5, 'minimalist': -1.0, 'inspiring': 4.0, 'systematic': 0.5, 'discovering': 3.0, 'conservative': -0.5, 'verifying': 1.0, 'overlooking': 0.5, 'sharpening': -1.0, 'harmonic': -0.5, 'empathic': 4.0, 'matter_of_fact': 0.5, 'brave': 1.0, 'protective': 0.0, 'generous': 0.5, 'thrifty': 1.0, 'favourable': 1.0, 'balanced': 0.5, 'sensuality': 1.0, 'intelligent': 1.0, 'believe': 0.5, 'egocentric': -1.0, 'allocentric': -1.0}\n"
     ]
    }
   ],
   "source": [
    "print(arch_df.loc[\"marek_grodzki\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InfluencerNode - node with user data\n",
    "\n",
    "import os\n",
    "import toml\n",
    "import re\n",
    "import itertools\n",
    "from text_cleaner import *\n",
    "from toml import TomlDecodeError\n",
    "\n",
    "class InfluencerNode(object):\n",
    "    def __init__(self, profile_name: str, db_directory: str, data_frame: pd.DataFrame):\n",
    "        self.username = profile_name\n",
    "        self.posts = []\n",
    "        self.hashtags = []\n",
    "\n",
    "        # Load the user data\n",
    "        try:\n",
    "            if os.path.exists(db_directory):\n",
    "                # Iterate over directories in categories:\n",
    "                category_dirs = os.listdir(db_directory)\n",
    "                for cat_dir in category_dirs:\n",
    "                    user_dir = os.path.join(db_directory, cat_dir)\n",
    "                    # Check if influencer username is present in this category\n",
    "                    if profile_name in os.listdir(user_dir):\n",
    "                        user_path = os.path.join(user_dir, profile_name)\n",
    "                        # Get user data\n",
    "                        with open(os.path.join(user_path, f\"{profile_name}.toml\"), \"r\") as f:\n",
    "                            toml_file = toml.load(f)\n",
    "                        \n",
    "                        # After reading .toml file, set up the node attributes\n",
    "                        self.full_name: str = toml_file[\"full_name\"]\n",
    "                        self.biography: str = toml_file[\"biography\"]\n",
    "                        self.business_category: str = toml_file[\"business_category_name\"]\n",
    "                        self.followers: int = toml_file[\"followers\"]\n",
    "                        self.followees: int = toml_file[\"followees\"]\n",
    "                        self.mediacount: int = toml_file[\"mediacount\"]\n",
    "                        self.posts: list = []\n",
    "\n",
    "                        # Red all posts into a list\n",
    "                        for file in os.listdir(user_path):\n",
    "                            if not file.endswith(\".toml\"):\n",
    "                                with open(os.path.join(user_path, file), \"r\") as post_f:\n",
    "                                    self.posts.append(post_f.read())\n",
    "\n",
    "                        self.hashtags = self.extract_hashtags()\n",
    "\n",
    "                        # Post reedition\n",
    "                        self.posts = [remove_stopwords(clean_up_text(post)) for post in self.posts]\n",
    "                        \n",
    "                        # Set up archetype/character trait weights\n",
    "                        traits = data_frame.loc[self.username].to_dict()\n",
    "                        for k, v in traits.items():\n",
    "                            setattr(self, k, v)\n",
    "                        break\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "\n",
    "    def extract_hashtags(self):\n",
    "        HASH_RE = re.compile(r\"\\#\\w+\")\n",
    "        out_list = []\n",
    "        for post in self.posts:\n",
    "            tmp = re.findall(HASH_RE, post)\n",
    "            out_list.append(list(set(tmp)))\n",
    "        out_list = list(itertools.chain.from_iterable(out_list))\n",
    "        return list(set(out_list))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#ukochojsie', '#termy', '#wyzwanie', '#family', '#newyear', '#men', '#monikakolakowska', '#siÅ‚ownia', '#trenerpersonalny', '#training', '#bieganie', '#inspiracja', '#trener', '#uÅ›miech', '#epidemia', '#brzuch', '#wielkanocnedekoracje', '#samoakceptacja', '#szczÄ™Å›cie', '#cytat', '#wpracy', '#zdrowystylÅ¼ycia', '#sniadaniemistrzow', '#fitness', '#diet', '#kocham', '#uroda', '#black', '#shape', '#running', '#eyes', '#kobietawbiznesie', '#marketing', '#rower', '#trening', '#zdrowystylzycia', '#photography', '#celebration', '#healthybreakfast', '#fotografia', '#morning', '#sport', '#poland', '#instalike', '#wyzwanie30dni', '#easter', '#dietetyk', '#owsianka', '#sukces', '#miÅ‚oÅ›Ä‡', '#milosc', '#ewachodakowska', '#photooftheday', '#blackcoffee', '#kryzys', '#sniadanie', '#fitmom', '#zostanwdomu', '#chodakowska', '#kochajsiebie', '#relationship', '#relax', '#warszawa', '#Å›wiÄ™ta', '#odzywianie', '#girl', '#polishgirl', '#czasdlasiebie', '#fitgirl', '#rozwoj', '#dreams', '#dziecko', '#coffeeholic', '#kwarantanna', '#body', '#breakfast', '#polskakobieta', '#kobietanasiÅ‚owni', '#biegambolubie', '#cheers', '#impreza', '#polskadziewczyna', '#muscle', '#biznes', '#sweetheart', '#beactive', '#szczÄ™scie', '#coffee', '#polskichlopak', '#siÅ‚a', '#chodakowskaewa', '#tasty', '#coffeetime', '#runner', '#elegant', '#czasnakawe', '#sanatorium', '#biznesonline', '#peace', '#kawiarnia', '#fitfam', '#red', '#pomoc', '#healthyfood', '#thai', '#foodie', '#man', '#zmiana', '#motivation', '#stopwymÃ³wkom', '#Å¼ycie', '#szczescie', '#odchudzanie', '#marzenia', '#polska', '#poznan', '#kulturystyka', '#health', '#thailand', '#model', '#people', '#wiemcojem', '#workout', '#urodziny', '#bediet', '#pool', '#wiedza', '#coffeelover', '#spring', '#befit', '#smile', '#beraw', '#gym', '#kawusia', '#warsaw', '#yummy', '#fajterka', '#bizneswoman', '#przemyslenia', '#motywacja', '#handsome', '#coach', '#kawa', '#espresso', '#wroclaw', '#dzwigajdziewczyno', '#kwiaty', '#wakacje', '#eko', '#mirror', '#besttime', '#beach', '#zdrowejedzenie', '#katowice', '#drinks', '#goodmorning', '#selfie', '#obiad', '#dziendobry', '#Å›niadanie', '#kobietasukcesu', '#zdrowo', '#radoÅ›Ä‡', '#polskiesylwetki', '#pasja', '#bieg', '#instaboy', '#restaurant', '#polishboy', '#rozwÃ³j', '#moda', '#nightout', '#weekend', '#uk', '#cwiczenia', '#Wyzwanie30dni', '#abs', '#eco', '#wife', '#familytime', '#healthylifestyle', '#mezczyzna', '#beautiful', '#redukcja', '#chodagang', '#misjachoda', '#zdrowie', '#fitnesskimoniki', '#silownia', '#fit', '#cytaty', '#specialtycoffee', '#kochamsiebie', '#rozwojosobisty', '#instafood', '#rodzina', '#kobieta', '#praca', '#poolparty', '#breakfasttime', '#cafe', '#edukacja', '#goals', '#handmade', '#hotel', '#birthday', '#bialystok', '#czystamicha', '#wielkanoc', '#dieta', '#forma', '#personaltrainer', '#ciechocinek', '#delicious', '#tbt', '#happyeaster', '#food', '#kobietazklasa', '#jedzenie', '#aktywnie', '#happiness', '#wiosna', '#Å¼yczenia', '#firma', '#instacoffee', '#healthy', '#latte', '#happy', '#summer', '#challenge', '#fitfood', '#love', '#bio', '#bodybuilding', '#run', '#flowershop', '#happynewyear', '#eggs', '#mojewszystko', '#fitnessmotivation', '#party', '#martini', '#woman', '#przemyÅ›lenia', '#rehabilitation', '#mareczek', '#kobietabiznesu', '#instagood', '#fitnessmodel', '#shredding', '#nogi', '#kobietaniezalezna', '#inspiration', '#domzdrowialila', '#bestfriends', '#spa', '#akceptacja', '#london', '#vegan', '#mylove', '#selflove', '#ciacho']\n"
     ]
    }
   ],
   "source": [
    "# Test the class\n",
    "test_user = InfluencerNode(\"marek_grodzki\", \"instagram_dataset/pl\", arch_df)\n",
    "\n",
    "# Print the hashtags associated with the user\n",
    "print(test_user.hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:00, 101.48it/s]marek_grodzki\n",
      "vege_style_life\n",
      "oliwka__2007\n",
      "z_przestrzeni_serca\n",
      "zaradne_warsztaty\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/rÄ™kodzieÅ‚o/zaradne_warsztaty/zaradne_warsztaty.toml'\n",
      "snatch.machine\n",
      "z_ksiazka_na_obcasach\n",
      "marzena_kowalewska\n",
      "moja_pasja_gotowanie\n",
      "miss.libro\n",
      "windrosephotograph\n",
      "hemliighet\n",
      "muzykujemy\n",
      "komorek.dietetyk\n",
      "ilona_browstylist\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/stylistyka/ilona_browstylist/ilona_browstylist.toml'\n",
      "pracownia.lepiej\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/pracownia.lepiej/pracownia.lepiej.toml'\n",
      "fachowydekarz\n",
      "karmiciel\n",
      "oskyyy_\n",
      "kwiaciarniaemi\n",
      "kri_s_and_tina\n",
      "bertrand_okna_i_drzwi\n",
      "33it [00:00, 74.28it/s] kartaikompas\n",
      "paniswojegoczasu_official\n",
      "milena.maszewska\n",
      "wygodnadieta\n",
      "adam.przemyk\n",
      "halmar.meble\n",
      "kamann_living\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/kamann_living/kamann_living.toml'\n",
      "ekodzielnia\n",
      "natalia_grzy\n",
      "rekodzielove\n",
      "iwy_impresje\n",
      "mr.bartoszrybak\n",
      "samanta_dryja_zabielska\n",
      "46it [00:00, 86.71it/s]sabina_sw\n",
      "grzewysocki\n",
      "natalie_interiors\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wnÄ™trza/natalie_interiors/natalie_interiors.toml'\n",
      "madalena_yoga\n",
      "prusikowe\n",
      "mama_moze_wszystko\n",
      "rocksanka\n",
      "salawa.mateusz\n",
      "dakuzo_com\n",
      "krewetkowo\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/krewetkowo/krewetkowo.toml'\n",
      "meg_adams_autorka\n",
      "wts_deski\n",
      "drzewofranciszka\n",
      "asymetria_wnetrza\n",
      "pracownialavida\n",
      "kuchniawrzoska\n",
      "64it [00:00, 72.00it/s]eliza.gwiazda_official\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/nauka/eliza.gwiazda_official/eliza.gwiazda_official.toml'\n",
      "gettinenglish\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/nauka/gettinenglish/gettinenglish.toml'\n",
      "oktawianowacka\n",
      "zdrowostki\n",
      "bambi_boho\n",
      "polilinia.design\n",
      "katkulesza\n",
      "magdalena_musz_\n",
      "marta_golebiewska_\n",
      "aga_lingas_loniewska_writer\n",
      "aldona.kaczmarek8\n",
      "mojawyspa.co.uk\n",
      "kamkamillka\n",
      "moni.leoni\n",
      "podziaranytata\n",
      "piekniejemy.dietetyka\n",
      "paulina.ihnat\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/uroda/paulina.ihnat/paulina.ihnat.toml'\n",
      "fotografia.w.kadrze\n",
      "74it [00:00, 77.97it/s]khrystynaanna_mua\n",
      "czarny.mat\n",
      "agnieszka.j.marciniak\n",
      "adam.dronuje\n",
      "najslodszarzecz\n",
      "home_in_garden\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/home_in_garden/home_in_garden.toml'\n",
      "mateusz.sternal\n",
      "onalubi\n",
      "klaudiatreningi\n",
      "karola_moskal\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/karola_moskal/karola_moskal.toml'\n",
      "niecodziennikparypl\n",
      "97it [00:01, 75.94it/s]alpeekbooks\n",
      "wierzbowa_architektura\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/wierzbowa_architektura/wierzbowa_architektura.toml'\n",
      "whowillsavetheplanet\n",
      "justka.ka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/sprzedaÅ¼/justka.ka/justka.ka.toml'\n",
      "_read_andzia_\n",
      "mamologia\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/psychologia/mamologia/mamologia.toml'\n",
      "kwejk\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/sprzedaÅ¼/kwejk/kwejk.toml'\n",
      "iam.nattie\n",
      "qqa_mrt\n",
      "elamazurcreative\n",
      "katka_reads26\n",
      "mlodamama_fit\n",
      "anibarpiomar\n",
      "gracjangornig\n",
      "julencja_karz_elek\n",
      "keto_kocur\n",
      "jacekgalinski\n",
      "patrycja.hrabyk\n",
      "107it [00:01, 59.46it/s]book_and_caffeine\n",
      "zielonaferajna\n",
      "systematycznosc\n",
      "dietetyk_sandra_malek\n",
      "agatazarzycka\n",
      "swiatwiedzy\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/polityka/swiatwiedzy/swiatwiedzy.toml'\n",
      "duda_dawid_\n",
      "chichi_xdd\n",
      "healthytorie\n",
      "okohorusa\n",
      "115it [00:01, 58.99it/s]kacper_emm\n",
      "rm_bateman\n",
      "pandawanda.pl\n",
      "sztosik.handmade\n",
      "olaszymanska_bodymind\n",
      "esey_o_silowni\n",
      "marzenia_kajomy\n",
      "error_pl\n",
      "damianolszewski.official\n",
      "izaskowronska\n",
      "petitefleur_pracownia\n",
      "magdaboruc.fotografia\n",
      "fitness_wyciechowski\n",
      "somethingbluepl\n",
      "klaudia_lasecka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/kobieta/klaudia_lasecka/klaudia_lasecka.toml'\n",
      "dom.w.kwiatach\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/rÄ™kodzieÅ‚o/dom.w.kwiatach/dom.w.kwiatach.toml'\n",
      "ak.kingamadej\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/ak.kingamadej/ak.kingamadej.toml'\n",
      "vicky.vs.books\n",
      "owsianapl\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/jÄ™zyki/owsianapl/owsianapl.toml'\n",
      "pawel_gajos_gaj\n",
      "greenmermaidblog\n",
      "130it [00:01, 77.64it/s]rozannasz\n",
      "pola.86\n",
      "_agnieszka_leszczynska\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/_agnieszka_leszczynska/_agnieszka_leszczynska.toml'\n",
      "thebeejoy.pl\n",
      "fit.pietrucha\n",
      "tengri_91\n",
      "karkareads\n",
      "keller_pl\n",
      "dowcipnik_pl\n",
      "sandrazenka_pl\n",
      "148it [00:02, 64.40it/s]cosmetics_pearls\n",
      "ciekawy_zycia\n",
      "dobrowolska.s.k\n",
      "markowe_jedzenie\n",
      "dziewczynyczytaja.pl\n",
      "anitka1official\n",
      "dietetyczka.nati\n",
      "czarna.owieczka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/czarna.owieczka/czarna.owieczka.toml'\n",
      "wall.done\n",
      "magdaskierska\n",
      "hellohomla\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/hellohomla/hellohomla.toml'\n",
      "obliczakobiety\n",
      "lux_bau\n",
      "156it [00:02, 61.23it/s]patka_ja\n",
      "dalialingerie\n",
      "ewa.oszek_mindfulness\n",
      "kulturoholiczka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/muzyka/kulturoholiczka/kulturoholiczka.toml'\n",
      "ubogacona\n",
      "aniolnaresorach\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/stylistyka/aniolnaresorach/aniolnaresorach.toml'\n",
      "lewaczka\n",
      "brzuchomechanika\n",
      "wyzwanie.zarabianie\n",
      "aldona_blaszczyk\n",
      "ptakfotografia\n",
      "172it [00:02, 61.74it/s]kaaroola.k\n",
      "bazamarzen\n",
      "krusia_domatorka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wnÄ™trza/krusia_domatorka/krusia_domatorka.toml'\n",
      "marlenasadventure\n",
      "magdalovena\n",
      "braciakleczek_trampoline\n",
      "anna.ruchala\n",
      "gotowanie_po_zmianie\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/gotowanie_po_zmianie/gotowanie_po_zmianie.toml'\n",
      "evegadomska\n",
      "milabozza.studio\n",
      "_go_ra\n",
      "designyourwedding_pl\n",
      "roslinniejemy\n",
      "michal.niemirowski\n",
      "189it [00:02, 67.60it/s]mrs.sikorka\n",
      "prosta.dieta\n",
      "lamotte_daniel\n",
      "marta.dietetyk\n",
      "lukaszodfoto\n",
      "ahojprzyrodo\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/nauka/ahojprzyrodo/ahojprzyrodo.toml'\n",
      "mandalalifeby_ada\n",
      "nataliadyoniziak\n",
      "mr.stejku\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/nauka/mr.stejku/mr.stejku.toml'\n",
      "martazielinskaaaa\n",
      "_zalija_\n",
      "innowacyjny_inwestor\n",
      "julka_barczyk\n",
      "kinianieruda\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/sprzedaÅ¼/kinianieruda/kinianieruda.toml'\n",
      "mojdommojemiejsce\n",
      "sugarfree\n",
      "poetkawpidzamie\n",
      "guardianofscience\n",
      "204it [00:03, 65.68it/s]eliza.slomka.nails\n",
      "exponerfoto\n",
      "pola_miko\n",
      "_natalia_kaczmarek\n",
      "marzenagunther\n",
      "alakko.reads\n",
      "remont_ciala\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/kultura/remont_ciala/remont_ciala.toml'\n",
      "wtld_\n",
      "aparat_w_krzokach\n",
      "nauka.jest.niesamowita\n",
      "kiniusiajel\n",
      "focusondentistry\n",
      "pilnikizalotka\n",
      "cooosure\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/cooosure/cooosure.toml'\n",
      "montessori_w_praktyce\n",
      "nurse_after_night_shift\n",
      "havriella\n",
      "patrycja_marzec_\n",
      "martapazera\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/martapazera/martapazera.toml'\n",
      "_paintedgarden.pl_\n",
      "ekobutelka\n",
      "zdrowy_talerz\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/jÄ™zyki/zdrowy_talerz/zdrowy_talerz.toml'\n",
      "lesiuk99\n",
      "alenapis.pl\n",
      "231it [00:03, 85.57it/s]jedrzej_fotografuje\n",
      "annabutrym.pl\n",
      "buduj.nl\n",
      "jawkrakowie\n",
      "rysunkowe_klimaty\n",
      "zycie_fizjoterapeuty\n",
      "annamboland\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/annamboland/annamboland.toml'\n",
      "panna_niebieska\n",
      "marketing_w_pigulce\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/marketing_w_pigulce/marketing_w_pigulce.toml'\n",
      "book_z_wami\n",
      "talkaboutlovepl\n",
      "ani_pudelko_piekna\n",
      "delfina.zazecke\n",
      "nebule_pl\n",
      "beepack.pl\n",
      "251it [00:03, 89.66it/s]achdeco_polska\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/achdeco_polska/achdeco_polska.toml'\n",
      "kamilcybul\n",
      "fit_nrs\n",
      "agataubysz\n",
      "sonka_kaminska\n",
      "s.piechowiak\n",
      "bookajka\n",
      "gregory.room\n",
      "imsokayka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/psychologia/imsokayka/imsokayka.toml'\n",
      "lipnickastodola\n",
      "psy_na_tropie_przyrody\n",
      "leexieena\n",
      "aleksandradebska_\n",
      "prosto.w.szarosci\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wnÄ™trza/prosto.w.szarosci/prosto.w.szarosci.toml'\n",
      "_que_hombre_\n",
      "fokajednooka\n",
      "lubelskiewesele.pl\n",
      "nieprzecietnezycie\n",
      "moni.monami\n",
      "beduintomek\n",
      "marcinlichota\n",
      "261it [00:03, 91.65it/s]ruthless.empress\n",
      "anna_gardenlove\n",
      "maslo.i.pieczywo\n",
      "lulu8802\n",
      "podroze.rodzinne\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/podrÃ³Å¼e/podroze.rodzinne/podroze.rodzinne.toml'\n",
      "vascorekuperacja\n",
      "fitbadurka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/fitbadurka/fitbadurka.toml'\n",
      "panifortuna\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/psychologia/panifortuna/panifortuna.toml'\n",
      "aga.miela_autorka\n",
      "szukajwarchiwach.gov.pl\n",
      "anna_miodynska\n",
      "kasiuniafalkowska\n",
      "kinga_strzalka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/stylistyka/kinga_strzalka/kinga_strzalka.toml'\n",
      "edytanatureaart\n",
      "ilonaaleksandrowicz\n",
      "jedz.pysznie\n",
      "285it [00:03, 94.87it/s]gotowe_projekty_domow_archon\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/gotowe_projekty_domow_archon/gotowe_projekty_domow_archon.toml'\n",
      "matka.boska\n",
      "myblogyoll\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/psychologia/myblogyoll/myblogyoll.toml'\n",
      "mariola.zielinska\n",
      "oliwiaknitter\n",
      "pani_przewodnik_warszawa\n",
      "joanna_jadachowska\n",
      "memy_z_insta_i_googla_\n",
      "justynabolek.official\n",
      "slawachm\n",
      "alezniejagentka\n",
      "_amimami_\n",
      "agnieszka.matysiak.photo\n",
      "zuzia_niemczycka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/zuzia_niemczycka/zuzia_niemczycka.toml'\n",
      "sercepodlasia\n",
      "dywanyluszczow\n",
      "kate.jozwik\n",
      "justa_w_ogrodzie\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/justa_w_ogrodzie/justa_w_ogrodzie.toml'\n",
      "majewska_klaudia\n",
      "rebecavij\n",
      "montownia_mebli\n",
      "bandura.dietetyk\n",
      "sosnaijegosadzonki\n",
      "petermanszlaga\n",
      "filipkowarski\n",
      "agiksonn\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/sprzedaÅ¼/agiksonn/agiksonn.toml'\n",
      "miesiecznik_znak\n",
      "311it [00:04, 105.79it/s]joyberlin_vip_tours\n",
      "artysia.studio\n",
      "rysia_k\n",
      "620_nad_poziomem_morza\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/620_nad_poziomem_morza/620_nad_poziomem_morza.toml'\n",
      "edziix_\n",
      "daagmarra\n",
      "photographer_mario_will\n",
      "swietlni\n",
      "b.obikko\n",
      "fotomateczka\n",
      "fit_gruszecka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/kobieta/fit_gruszecka/fit_gruszecka.toml'\n",
      "k.bukowska\n",
      "issabelall\n",
      "why_book_\n",
      "kitchenbymara\n",
      "suurvive\n",
      "karolinawiniarska.autor\n",
      "wydawnictwoznakpl\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/polityka/wydawnictwoznakpl/wydawnictwoznakpl.toml'\n",
      "karolqaa\n",
      "iggypizza\n",
      "martynagrajcke\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/sprzedaÅ¼/martynagrajcke/martynagrajcke.toml'\n",
      "kasper.mackowiak\n",
      "322it [00:04, 91.60it/s] plgbc\n",
      "_pawcio_17\n",
      "uciekamywbieszczady\n",
      "joanna_sobierajska\n",
      "whiteboooks\n",
      "blindsapphire\n",
      "staraochota_skrawki\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/mÄ™Å¼czyzna/staraochota_skrawki/staraochota_skrawki.toml'\n",
      "artfreak_pl\n",
      "leo_mega_mix\n",
      "nabakowskapracowniawnetrz\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wnÄ™trza/nabakowskapracowniawnetrz/nabakowskapracowniawnetrz.toml'\n",
      "ketomagazyn\n",
      "341it [00:04, 64.89it/s]n.on_back\n",
      "polczykmua\n",
      "drdietka\n",
      "razemlepiejpodcast\n",
      "patij_fit\n",
      "kittyailla\n",
      "anetaborysiewicz85\n",
      "smilesuee\n",
      "ajourneytoyourself\n",
      "k_madam\n",
      "pan_lis\n",
      "352it [00:04, 73.71it/s]czytelniczy.sad\n",
      "_alex_sandra_mama_\n",
      "niezleziolkoblog\n",
      "doomifit\n",
      "panich4os\n",
      "basia_bartas\n",
      "paulinarubaszka\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/paulinarubaszka/paulinarubaszka.toml'\n",
      "dumelcompl\n",
      "muai.studio\n",
      "lilylife.pl\n",
      "karolina_er_\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/karolina_er_/karolina_er_.toml'\n",
      "konopnadoktorka\n",
      "lavaredestylarnialawendy\n",
      "slowlifemydiary\n",
      "eulallka\n",
      "dieta_bez_diety\n",
      "379it [00:05, 92.19it/s]sylwia_romanek\n",
      "angelika_knop92\n",
      "wniebowziete_\n",
      "polka_w_toskanii\n",
      "dailywitekwtk\n",
      "koncertowezycie\n",
      "major_diwan\n",
      "art_belfer\n",
      "byledodrzemki\n",
      "aniagwiazdaa\n",
      "wydawnictwo_element\n",
      "paczynka_dietician\n",
      "justyna_gaca\n",
      "muntowska\n",
      "adam_romek\n",
      "teasnflowers\n",
      "momo.ffour\n",
      "dorisinsocialmedia\n",
      "lucas3city\n",
      "aga_bugaj\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/aga_bugaj/aga_bugaj.toml'\n",
      "kasiadulko\n",
      "weronika_health_fit_life\n",
      "390it [00:05, 68.14it/s]lab.07\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/lab.07/lab.07.toml'\n",
      "marcinn.ch\n",
      "skladnikiszczescia\n",
      "pasjonatkaestetka\n",
      "bo_tak_chce__\n",
      "felicjada\n",
      "ania_z_anina\n",
      "dr.michal.czapla\n",
      "ledwoledwo\n",
      "viola_okiem_dietetyka\n",
      "405it [00:05, 83.85it/s]wozniak_swimandtrain\n",
      "science_effect\n",
      "dobredomy\n",
      "jabzowka\n",
      "zaczytana_tak_po_prostu\n",
      "kiedymamaniespi\n",
      "pani_tester\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/uroda/pani_tester/pani_tester.toml'\n",
      "blogtasteaway\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/podrÃ³Å¼e/blogtasteaway/blogtasteaway.toml'\n",
      "klaudyszon\n",
      "baba_wrap_unofficial\n",
      "prawodumna\n",
      "ruda_czyta\n",
      "mateusz.rus\n",
      "monikagackowska.dietetyk\n",
      "krolowa.marysienka\n",
      "gabrieladom17\n",
      "indigobyjoannabandurska\n",
      "marta_pomaluje\n",
      "flammacandles\n",
      "magdalenazieleniewskateam\n",
      "426it [00:05, 83.15it/s]sandrawisniewska__\n",
      "pannasia\n",
      "klucz_dosukcesu\n",
      "ruda.ma.talent\n",
      "cafette21\n",
      "polawalentkowska\n",
      "onajedna_home\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/onajedna_home/onajedna_home.toml'\n",
      "ziarenkomaku\n",
      "magda_urbanska_blog\n",
      "languagebay\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/jÄ™zyki/languagebay/languagebay.toml'\n",
      "ankawstanka\n",
      "wyslowiona\n",
      "wega_lifestyle\n",
      "krakowskie_szkoly_artystyczne\n",
      "tam_i_nazot\n",
      "sklep.brat.pl\n",
      "kasia.gw\n",
      "jestrudo\n",
      "portalkobietcom\n",
      "446it [00:05, 84.11it/s]zawod_dietetyk\n",
      "domsonczyta\n",
      "alabasterfox\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/alabasterfox/alabasterfox.toml'\n",
      "chef_kubulewski\n",
      "aleksandra.herec\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/aleksandra.herec/aleksandra.herec.toml'\n",
      "rykalskaa\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/rykalskaa/rykalskaa.toml'\n",
      "domiogrod_przedsnem\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/domiogrod_przedsnem/domiogrod_przedsnem.toml'\n",
      "maartiiix3\n",
      "wynaturzonablog\n",
      "joanna.w_ke\n",
      "maddlajnn\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/podrÃ³Å¼e/maddlajnn/maddlajnn.toml'\n",
      "jezuici\n",
      "xkarmarber\n",
      "czytam2020\n",
      "alicja.official\n",
      "dariagaffke\n",
      "slavicgymnastic\n",
      "magdaczerkies\n",
      "rozowawieza\n",
      "455it [00:06, 76.54it/s]daszewskaflorist\n",
      "printy_mum\n",
      "adamowiczangelika\n",
      "akwarela_\n",
      "veraicon_lifestyle\n",
      "poczujsielepiej\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/psychologia/poczujsielepiej/poczujsielepiej.toml'\n",
      "karolinamizdal\n",
      "erillsstyle\n",
      "kasia_plawecka\n",
      "mazurskigospodarz\n",
      "potrzebawioski\n",
      "476it [00:06, 80.96it/s]26_days_off\n",
      "naszswiatt\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/naszswiatt/naszswiatt.toml'\n",
      "ann_juliette\n",
      "zdrowoczylisexy\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/zdrowoczylisexy/zdrowoczylisexy.toml'\n",
      "paulinowa\n",
      "angelika_mit\n",
      "rutynowa\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/jÄ™zyki/rutynowa/rutynowa.toml'\n",
      "aga.lanius\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/ogrÃ³d/aga.lanius/aga.lanius.toml'\n",
      "zmotywowany_\n",
      "balickadesign\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/wzornictwo/balickadesign/balickadesign.toml'\n",
      "ninika.muszynka\n",
      "sawik_style\n",
      "magbi77\n",
      "filizankazmieta\n",
      "milionrazy\n",
      "kwiaciarnia_ewa_antczak\n",
      "kurczaki_\n",
      "ewarzetelna_agentnieruchomosci\n",
      "wymarzone_mieszkanie\n",
      "_niebieskiemigdaly_\n",
      "step_into_the_past_\n",
      "lubie_gary\n",
      "gragorsiak\n",
      "agatadobrzanska_com\n",
      "496it [00:06, 80.94it/s]gawroszka\n",
      "klaudia_muniak\n",
      "pereciaszko\n",
      "kamomilpl\n",
      "czytaga\n",
      "kulka7\n",
      "becia73\n",
      "thelittlepuppyrose\n",
      "nowinki.sklepowe\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/jÄ™zyki/nowinki.sklepowe/nowinki.sklepowe.toml'\n",
      "moda_na_klasyki\n",
      "[Errno 2] No such file or directory: 'instagram_dataset/pl/motoryzacja/moda_na_klasyki/moda_na_klasyki.toml'\n",
      "kasiawizimirska\n",
      "pastellove_handmade\n",
      "kw_beautybar\n",
      "oftendifferent\n",
      "ela26486\n",
      "kj.graphic\n",
      "kwiaciarnia_cudawianki_lodz\n",
      "508it [00:06, 76.80it/s]_maartiniii\n",
      "twojsuchar\n",
      "adventure.never.sleeps\n",
      "mo_niczka1234\n",
      "paulinakorol\n",
      "alicja.ogonowska\n",
      "mrs_anna.b\n",
      "art_iwa\n",
      "Error count: 263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create node list (to be used for graph building)\n",
    "import copy\n",
    "node_list = []\n",
    "data_not_present = []\n",
    "available_arch_df = copy.deepcopy(arch_df)\n",
    "\n",
    "err_cnt = 0\n",
    "for i, row in tqdm(arch_df.iterrows()):\n",
    "    print(i)\n",
    "    try:\n",
    "        tmp = InfluencerNode(i, \"instagram_dataset/pl\", arch_df)\n",
    "        node_list.append(tmp)\n",
    "    except:\n",
    "        err_cnt += 1\n",
    "        available_arch_df = available_arch_df.drop(i, axis=0)\n",
    "print(f\"Error count: {err_cnt}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node list length: 245\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the processed node list\n",
    "print(f\"Node list length: {len(available_arch_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the available influencers to .csv\n",
    "available_arch_df.to_csv(\"archetypes_pl_available.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "def select_and_aggregate_per_trait(data_frame: pd.DataFrame):\n",
    "    # Select only the accounts assigned with the given trait\n",
    "    word_df = pd.DataFrame()\n",
    "    for col in tqdm(data_frame.columns):\n",
    "        out_df = data_frame[data_frame[col] != 0.0]\n",
    "        trait_posts = []\n",
    "        total_ctr = Counter()\n",
    "        for i, row in out_df.iterrows():\n",
    "            # Get the needed posts and hashtags\n",
    "            idx = data_frame.index.get_loc(i)\n",
    "            trait_posts += (list(itertools.chain.from_iterable(node_list[idx].posts)) + node_list[idx].hashtags) \n",
    "\n",
    "        # Get count of all words\n",
    "        tmp_ctr = Counter(trait_posts)\n",
    "        tmp_ctr = {k: v for k, v in tmp_ctr.items() if v >= 1}\n",
    "        total_ctr += tmp_ctr\n",
    "        word_df = pd.concat([word_df, pd.DataFrame.from_dict(total_ctr, orient=\"index\", columns=[col])])\n",
    "    \n",
    "    # Merge the duplicated indices\n",
    "    return word_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:14<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "word_df = select_and_aggregate_per_trait(available_arch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a pickle\n",
    "import pickle\n",
    "with open(\"word_df.pickle\", \"wb\") as f:\n",
    "    pickle.dump(word_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zainspirowany</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wczorajszym</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wywiadem</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odnoÅ›nie</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relacji</th>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "zainspirowany       3.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "wczorajszym         5.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "wywiadem            1.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "odnoÅ›nie           10.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "relacji            72.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "\n",
       "               jester  everyman  caregiver  ...  protective  generous  \\\n",
       "zainspirowany     NaN       NaN        NaN  ...         NaN       NaN   \n",
       "wczorajszym       NaN       NaN        NaN  ...         NaN       NaN   \n",
       "wywiadem          NaN       NaN        NaN  ...         NaN       NaN   \n",
       "odnoÅ›nie          NaN       NaN        NaN  ...         NaN       NaN   \n",
       "relacji           NaN       NaN        NaN  ...         NaN       NaN   \n",
       "\n",
       "               thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "zainspirowany      NaN         NaN       NaN         NaN          NaN   \n",
       "wczorajszym        NaN         NaN       NaN         NaN          NaN   \n",
       "wywiadem           NaN         NaN       NaN         NaN          NaN   \n",
       "odnoÅ›nie           NaN         NaN       NaN         NaN          NaN   \n",
       "relacji            NaN         NaN       NaN         NaN          NaN   \n",
       "\n",
       "               believe  egocentric  allocentric  \n",
       "zainspirowany      NaN         NaN          NaN  \n",
       "wczorajszym        NaN         NaN          NaN  \n",
       "wywiadem           NaN         NaN          NaN  \n",
       "odnoÅ›nie           NaN         NaN          NaN  \n",
       "relacji            NaN         NaN          NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the head of the file\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zainspirowany</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wczorajszym</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wywiadem</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odnoÅ›nie</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relacji</th>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Bezmatek</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#dna</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#prasa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#patrykhardziej</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#janion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480875 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "zainspirowany         3.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "wczorajszym           5.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "wywiadem              1.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "odnoÅ›nie             10.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "relacji              72.0   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "...                   ...   ...       ...     ...       ...   ...    ...   \n",
       "#Bezmatek             NaN   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "#dna                  NaN   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "#prasa                NaN   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "#patrykhardziej       NaN   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "#janion               NaN   NaN       NaN     NaN       NaN   NaN    NaN   \n",
       "\n",
       "                 jester  everyman  caregiver  ...  protective  generous  \\\n",
       "zainspirowany       NaN       NaN        NaN  ...         NaN       NaN   \n",
       "wczorajszym         NaN       NaN        NaN  ...         NaN       NaN   \n",
       "wywiadem            NaN       NaN        NaN  ...         NaN       NaN   \n",
       "odnoÅ›nie            NaN       NaN        NaN  ...         NaN       NaN   \n",
       "relacji             NaN       NaN        NaN  ...         NaN       NaN   \n",
       "...                 ...       ...        ...  ...         ...       ...   \n",
       "#Bezmatek           NaN       NaN        NaN  ...         NaN       NaN   \n",
       "#dna                NaN       NaN        NaN  ...         NaN       NaN   \n",
       "#prasa              NaN       NaN        NaN  ...         NaN       NaN   \n",
       "#patrykhardziej     NaN       NaN        NaN  ...         NaN       NaN   \n",
       "#janion             NaN       NaN        NaN  ...         NaN       NaN   \n",
       "\n",
       "                 thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "zainspirowany        NaN         NaN       NaN         NaN          NaN   \n",
       "wczorajszym          NaN         NaN       NaN         NaN          NaN   \n",
       "wywiadem             NaN         NaN       NaN         NaN          NaN   \n",
       "odnoÅ›nie             NaN         NaN       NaN         NaN          NaN   \n",
       "relacji              NaN         NaN       NaN         NaN          NaN   \n",
       "...                  ...         ...       ...         ...          ...   \n",
       "#Bezmatek            NaN         NaN       NaN         NaN          NaN   \n",
       "#dna                 NaN         NaN       NaN         NaN          NaN   \n",
       "#prasa               NaN         NaN       NaN         NaN          NaN   \n",
       "#patrykhardziej      NaN         NaN       NaN         NaN          NaN   \n",
       "#janion              NaN         NaN       NaN         NaN          NaN   \n",
       "\n",
       "                 believe  egocentric  allocentric  \n",
       "zainspirowany        NaN         NaN          NaN  \n",
       "wczorajszym          NaN         NaN          NaN  \n",
       "wywiadem             NaN         NaN          NaN  \n",
       "odnoÅ›nie             NaN         NaN          NaN  \n",
       "relacji              NaN         NaN          NaN  \n",
       "...                  ...         ...          ...  \n",
       "#Bezmatek            NaN         NaN          NaN  \n",
       "#dna                 NaN         NaN          NaN  \n",
       "#prasa               NaN         NaN          NaN  \n",
       "#patrykhardziej      NaN         NaN          NaN  \n",
       "#janion              NaN         NaN          NaN  \n",
       "\n",
       "[480875 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.groupby(word_df.index).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the duplicated indices\n",
    "import numpy as np\n",
    "word_df = word_df.groupby(word_df.index).aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#1000rzeczymniejw2020</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       innocent  sage  explorer  outlaw  magician  hero  \\\n",
       "#1                          2.0   2.0       1.0     1.0       1.0   1.0   \n",
       "#10                         0.0   0.0       0.0     0.0       0.0   0.0   \n",
       "#100                        0.0   1.0       0.0     0.0       0.0   0.0   \n",
       "#10000                      1.0   1.0       1.0     0.0       1.0   1.0   \n",
       "#1000rzeczymniejw2020       1.0   1.0       1.0     1.0       1.0   1.0   \n",
       "\n",
       "                       lover  jester  everyman  caregiver  ...  protective  \\\n",
       "#1                       0.0     1.0       0.0        1.0  ...         2.0   \n",
       "#10                      0.0     1.0       1.0        0.0  ...         1.0   \n",
       "#100                     0.0     0.0       0.0        0.0  ...         1.0   \n",
       "#10000                   0.0     1.0       0.0        1.0  ...         0.0   \n",
       "#1000rzeczymniejw2020    1.0     1.0       1.0        1.0  ...         1.0   \n",
       "\n",
       "                       generous  thrifty  favourable  balanced  sensuality  \\\n",
       "#1                          3.0      3.0         3.0       3.0         3.0   \n",
       "#10                         1.0      1.0         1.0       1.0         1.0   \n",
       "#100                        1.0      1.0         1.0       1.0         1.0   \n",
       "#10000                      0.0      1.0         1.0       1.0         0.0   \n",
       "#1000rzeczymniejw2020       1.0      1.0         1.0       1.0         1.0   \n",
       "\n",
       "                       intelligent  believe  egocentric  allocentric  \n",
       "#1                             3.0      2.0         3.0          3.0  \n",
       "#10                            1.0      1.0         1.0          1.0  \n",
       "#100                           1.0      1.0         1.0          1.0  \n",
       "#10000                         1.0      0.0         1.0          1.0  \n",
       "#1000rzeczymniejw2020          1.0      1.0         1.0          1.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word_df to .csv and to pickle\n",
    "word_df.to_csv(\"word_df_non_normalized.csv\")\n",
    "\n",
    "with open(\"word_df_non_normalized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(word_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the word_df\n",
    "word_df_sum = word_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df_norm = word_df.div(word_df_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       innocent      sage  explorer    outlaw  magician  \\\n",
      "#1                     0.000007  0.000008  0.000005  0.000005  0.000005   \n",
      "#10                    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "#100                   0.000000  0.000004  0.000000  0.000000  0.000000   \n",
      "#10000                 0.000004  0.000004  0.000005  0.000000  0.000005   \n",
      "#1000rzeczymniejw2020  0.000004  0.000004  0.000005  0.000005  0.000005   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "Å¼Å‚obka                 0.000015  0.000016  0.000015  0.000015  0.000016   \n",
      "Å¼Å‚obkach               0.000004  0.000004  0.000005  0.000005  0.000005   \n",
      "Å¼Å‚obki                 0.000007  0.000008  0.000010  0.000010  0.000011   \n",
      "Å¼Å‚obku                 0.000007  0.000008  0.000010  0.000010  0.000011   \n",
      "Å¼Å‚obkÃ³w                0.000004  0.000004  0.000005  0.000005  0.000005   \n",
      "\n",
      "                           hero     lover    jester  everyman  caregiver  ...  \\\n",
      "#1                     0.000006  0.000000  0.000005  0.000000   0.000004  ...   \n",
      "#10                    0.000000  0.000000  0.000005  0.000004   0.000000  ...   \n",
      "#100                   0.000000  0.000000  0.000000  0.000000   0.000000  ...   \n",
      "#10000                 0.000006  0.000000  0.000005  0.000000   0.000004  ...   \n",
      "#1000rzeczymniejw2020  0.000006  0.000004  0.000005  0.000004   0.000004  ...   \n",
      "...                         ...       ...       ...       ...        ...  ...   \n",
      "Å¼Å‚obka                 0.000017  0.000013  0.000015  0.000015   0.000017  ...   \n",
      "Å¼Å‚obkach               0.000000  0.000004  0.000005  0.000004   0.000004  ...   \n",
      "Å¼Å‚obki                 0.000000  0.000009  0.000010  0.000007   0.000008  ...   \n",
      "Å¼Å‚obku                 0.000011  0.000009  0.000010  0.000007   0.000008  ...   \n",
      "Å¼Å‚obkÃ³w                0.000000  0.000004  0.000005  0.000004   0.000004  ...   \n",
      "\n",
      "                       protective  generous   thrifty  favourable  balanced  \\\n",
      "#1                       0.000006  0.000010  0.000010    0.000009  0.000009   \n",
      "#10                      0.000003  0.000003  0.000003    0.000003  0.000003   \n",
      "#100                     0.000003  0.000003  0.000003    0.000003  0.000003   \n",
      "#10000                   0.000000  0.000000  0.000003    0.000003  0.000003   \n",
      "#1000rzeczymniejw2020    0.000003  0.000003  0.000003    0.000003  0.000003   \n",
      "...                           ...       ...       ...         ...       ...   \n",
      "Å¼Å‚obka                   0.000012  0.000003  0.000003    0.000012  0.000012   \n",
      "Å¼Å‚obkach                 0.000003  0.000003  0.000003    0.000003  0.000003   \n",
      "Å¼Å‚obki                   0.000006  0.000006  0.000007    0.000006  0.000006   \n",
      "Å¼Å‚obku                   0.000006  0.000000  0.000000    0.000006  0.000006   \n",
      "Å¼Å‚obkÃ³w                  0.000003  0.000003  0.000003    0.000003  0.000003   \n",
      "\n",
      "                       sensuality  intelligent   believe  egocentric  \\\n",
      "#1                       0.000009     0.000009  0.000006    0.000009   \n",
      "#10                      0.000003     0.000003  0.000003    0.000003   \n",
      "#100                     0.000003     0.000003  0.000003    0.000003   \n",
      "#10000                   0.000000     0.000003  0.000000    0.000003   \n",
      "#1000rzeczymniejw2020    0.000003     0.000003  0.000003    0.000003   \n",
      "...                           ...          ...       ...         ...   \n",
      "Å¼Å‚obka                   0.000011     0.000012  0.000013    0.000012   \n",
      "Å¼Å‚obkach                 0.000003     0.000003  0.000003    0.000003   \n",
      "Å¼Å‚obki                   0.000006     0.000006  0.000006    0.000006   \n",
      "Å¼Å‚obku                   0.000006     0.000006  0.000006    0.000006   \n",
      "Å¼Å‚obkÃ³w                  0.000003     0.000003  0.000003    0.000003   \n",
      "\n",
      "                       allocentric  \n",
      "#1                        0.000009  \n",
      "#10                       0.000003  \n",
      "#100                      0.000003  \n",
      "#10000                    0.000003  \n",
      "#1000rzeczymniejw2020     0.000003  \n",
      "...                            ...  \n",
      "Å¼Å‚obka                    0.000011  \n",
      "Å¼Å‚obkach                  0.000003  \n",
      "Å¼Å‚obki                    0.000006  \n",
      "Å¼Å‚obku                    0.000006  \n",
      "Å¼Å‚obkÃ³w                   0.000003  \n",
      "\n",
      "[96175 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(word_df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word_df to .csv and to pickle\n",
    "word_df_norm.to_csv(\"word_df_normalized.csv\")\n",
    "\n",
    "with open(\"word_df_normalized.pickle\", \"wb\") as f:\n",
    "    pickle.dump(word_df_norm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00292215481590789\n"
     ]
    }
   ],
   "source": [
    "print(max(word_df_norm[\"innocent\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for node in node_list:\n",
    "    print(\"#1\" in node.hashtags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
