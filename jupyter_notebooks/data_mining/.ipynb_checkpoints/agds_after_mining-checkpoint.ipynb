{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an AGDS after mining all the data from the current dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from text_cleaner import *\n",
    "import nltk\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>artist</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>everyman</th>\n",
       "      <th>explorer</th>\n",
       "      <th>guru</th>\n",
       "      <th>hero</th>\n",
       "      <th>innocent</th>\n",
       "      <th>jester</th>\n",
       "      <th>magician</th>\n",
       "      <th>rebel</th>\n",
       "      <th>ruler</th>\n",
       "      <th>seducer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['aaron']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['abbie']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ability']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012334</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['able', 'able']</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['able', 'access']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pattern    artist  caregiver  everyman  explorer      guru  \\\n",
       "0           ['aaron']  0.000000        0.0       0.0  0.009045  0.000000   \n",
       "1           ['abbie']  0.000000        0.0       0.0  0.000000  0.000000   \n",
       "2         ['ability']  0.000000        0.0       0.0  0.012334  0.009126   \n",
       "3    ['able', 'able']  0.000486        0.0       0.0  0.000000  0.000000   \n",
       "4  ['able', 'access']  0.000000        0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "       hero  innocent  jester  magician     rebel  ruler  seducer  \n",
       "0  0.007510       0.0     0.0  0.000000  0.000000    0.0      0.0  \n",
       "1  0.000000       0.0     0.0  0.041686  0.000000    0.0      0.0  \n",
       "2  0.020027       0.0     0.0  0.000000  0.011175    0.0      0.0  \n",
       "3  0.000000       0.0     0.0  0.000000  0.000000    0.0      0.0  \n",
       "4  0.000136       0.0     0.0  0.000000  0.000000    0.0      0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the phrase frequency file\n",
    "freq_df = pd.read_csv(\"sequence_files_bak/phrase_frequency_with_df.csv\", index_col=0)\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary that links the terms with a given archetype\n",
    "term_to_archetype = {}\n",
    "\n",
    "for i, row in freq_df.iterrows():\n",
    "    \n",
    "    term_to_archetype[tuple(row[\"pattern\"])] = {\n",
    "        \"artist\": row[\"artist\"],\n",
    "        \"caregiver\": row[\"caregiver\"],\n",
    "        \"everyman\": row[\"everyman\"],\n",
    "        \"explorer\": row[\"explorer\"],\n",
    "        \"guru\": row[\"guru\"],\n",
    "        \"hero\": row[\"hero\"],\n",
    "        \"innocent\": row[\"innocent\"],\n",
    "        \"jester\": row[\"jester\"],\n",
    "        \"magician\": row[\"magician\"],\n",
    "        \"rebel\": row[\"rebel\"],\n",
    "        \"ruler\": row[\"ruler\"],\n",
    "        \"seducer\": row[\"seducer\"]\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGDS representation size:  10485856\n",
      "Matrix representation size:  57380352\n",
      "AGDS needs ~ 5.47 times less space than standard matrix representation.\n"
     ]
    }
   ],
   "source": [
    "# Check if AGDS is more memory-efficient than a standard DataFrame\n",
    "from sys import getsizeof\n",
    "print(\"AGDS representation size: \", getsizeof(term_to_archetype))\n",
    "print(\"Matrix representation size: \", getsizeof(freq_df))\n",
    "print(\"AGDS needs ~\", round(getsizeof(freq_df)/getsizeof(term_to_archetype), 2), \"times less space than standard matrix representation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for Tweet end-to-end processing\n",
    "# From tokenization to class assignment\n",
    "class SingleTweet(object):\n",
    "    def __init__(self, text):\n",
    "        self._raw_text = text\n",
    "        self._cleaned_text = self._clean_text()\n",
    "        self._all_terms = self._tokenize_and_permute()\n",
    "        self._class_description = {\n",
    "        \"artist\": 0.0,\n",
    "        \"caregiver\": 0.0,\n",
    "        \"everyman\": 0.0,\n",
    "        \"explorer\": 0.0,\n",
    "        \"guru\": 0.0,\n",
    "        \"hero\": 0.0,\n",
    "        \"innocent\": 0.0,\n",
    "        \"jester\": 0.0,\n",
    "        \"magician\": 0.0,\n",
    "        \"rebel\": 0.0,\n",
    "        \"ruler\": 0.0,\n",
    "        \"seducer\": 0.0\n",
    "        } \n",
    "        self._key_list = list(self._class_description)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self._class_description}\"\n",
    "        \n",
    "    def _clean_text(self):\n",
    "        return clean_up_text(self._raw_text)\n",
    "        \n",
    "    def _tokenize_and_permute(self):\n",
    "        terms = []\n",
    "        # Tokenize the Tweet\n",
    "        words = nltk.word_tokenize(self._cleaned_text)\n",
    "        terms = np.unique(words).tolist()\n",
    "        \n",
    "        # Get all two-word and three-word phrases\n",
    "        terms.append(itertools.permutations(words, 2))\n",
    "        terms.append(itertools.permutations(words, 3))\n",
    "        return terms\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    \n",
    "    def classify_tweet(self, structure):\n",
    "        for term in self._all_terms:\n",
    "            tuple_term = tuple(term)\n",
    "            if tuple_term in structure.keys():\n",
    "                for k, v in structure[tuple_term]:\n",
    "                    self._class_description[k] += v\n",
    "        val_list = list(self._class_description.values())\n",
    "        outs = self._softmax(val_list)\n",
    "        \n",
    "        return self._key_list[np.argmax(outs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@dizunatsu ðŸ˜€ðŸ˜€\n"
     ]
    }
   ],
   "source": [
    "# Testing the implementation on Twitter set (accuracy can be verified)\n",
    "twitter_df = pd.read_csv(\"tweets_06_03_2021.csv\", index_col=0)\n",
    "\n",
    "# Select a sample Tweet\n",
    "sample_text = twitter_df.iloc[4].tweet_text\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_softmax() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7bba166f9c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Classify the tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_to_archetype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-d00b88776993>\u001b[0m in \u001b[0;36mclassify_tweet\u001b[0;34m(self, structure)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_description\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_description\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _softmax() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Create instance of SingleTweet\n",
    "tweet = SingleTweet(sample_text)\n",
    "\n",
    "# Classify the tweet\n",
    "res = tweet.classify_tweet(term_to_archetype)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109053it [05:35, 325.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AGDS: 0.11295425160243185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the AGDS accuracy\n",
    "import operator\n",
    "\n",
    "acc = 0\n",
    "for _, row in tqdm(twitter_df.iterrows()):\n",
    "    result = SingleTweet(row.tweet_text).classify_tweet(term_to_archetype)\n",
    "    pred = max(result.items(), key=operator.itemgetter(1))[0]\n",
    "    if pred == row.archetype:\n",
    "        acc += 1\n",
    "\n",
    "# Show the real accuracy\n",
    "print(f\"Accuracy of AGDS: {acc / len(twitter_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the real accuracy\n",
    "print(f\"Accuracy of AGDS: {acc / len(twitter_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
