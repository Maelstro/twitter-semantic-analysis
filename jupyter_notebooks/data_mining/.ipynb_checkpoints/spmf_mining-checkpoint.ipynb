{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPMF - try to get most occurring sequences\n",
    "from spmf import Spmf\n",
    "import pandas as pd\n",
    "from text_cleaner import *\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>archetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cef</td>\n",
       "      <td>@eliostruyf So exciting, have fun!¬†üòä</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 18:23:50.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f9f1c36b38e10f823bf2ce7</td>\n",
       "      <td>These Brick-O-Lanterns are certainly all treat...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-31 09:00:28.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f9f1c36b38e10f823bf2d0a</td>\n",
       "      <td>@dentistescabri Nous prenons la s√©curit√© de no...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 12:07:58.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cf5</td>\n",
       "      <td>@Jasmin80212446 üòçüéÑü•∞</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 16:35:39.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5f9f1c36b38e10f823bf2d07</td>\n",
       "      <td>@ashleydrixey Sounds like a perfect fit for th...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 13:09:14.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5f9f1c36b38e10f823bf2cef   \n",
       "1  5f9f1c36b38e10f823bf2ce7   \n",
       "2  5f9f1c36b38e10f823bf2d0a   \n",
       "3  5f9f1c36b38e10f823bf2cf5   \n",
       "4  5f9f1c36b38e10f823bf2d07   \n",
       "\n",
       "                                          tweet_text    username  \\\n",
       "0               @eliostruyf So exciting, have fun!¬†üòä  LEGO_Group   \n",
       "1  These Brick-O-Lanterns are certainly all treat...  LEGO_Group   \n",
       "2  @dentistescabri Nous prenons la s√©curit√© de no...  LEGO_Group   \n",
       "3                                @Jasmin80212446 üòçüéÑü•∞  LEGO_Group   \n",
       "4  @ashleydrixey Sounds like a perfect fit for th...  LEGO_Group   \n",
       "\n",
       "                created_at timestamp archetype  \n",
       "0  2020-10-30 18:23:50.000       NaN    artist  \n",
       "1  2020-10-31 09:00:28.000       NaN    artist  \n",
       "2  2020-10-30 12:07:58.000       NaN    artist  \n",
       "3  2020-10-30 16:35:39.000       NaN    artist  \n",
       "4  2020-10-30 13:09:14.000       NaN    artist  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Twitter dataset\n",
    "twitter_df = pd.read_csv('tweets_28_02_2021.csv', index_col=0)\n",
    "\n",
    "# Print the head of the loaded dataset\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>archetype</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cef</td>\n",
       "      <td>@eliostruyf So exciting, have fun!¬†üòä</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 18:23:50.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[exciting, fun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f9f1c36b38e10f823bf2ce7</td>\n",
       "      <td>These Brick-O-Lanterns are certainly all treat...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-31 09:00:28.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[brick, lanterns, certainly, treat, trick, get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f9f1c36b38e10f823bf2d0a</td>\n",
       "      <td>@dentistescabri Nous prenons la s√©curit√© de no...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 12:07:58.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[nous, prenons, la, curit, de, nos, fans, tr, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5f9f1c36b38e10f823bf2d07</td>\n",
       "      <td>@ashleydrixey Sounds like a perfect fit for th...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 13:09:14.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[sounds, like, perfect, fit, aspiring, young, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5f9f1c36b38e10f823bf2d08</td>\n",
       "      <td>@irgator04 What a perfect way to start¬†your we...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-30 12:49:37.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[perfect, way, start, weekend]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5f9f1c36b38e10f823bf2cef   \n",
       "1  5f9f1c36b38e10f823bf2ce7   \n",
       "2  5f9f1c36b38e10f823bf2d0a   \n",
       "4  5f9f1c36b38e10f823bf2d07   \n",
       "5  5f9f1c36b38e10f823bf2d08   \n",
       "\n",
       "                                          tweet_text    username  \\\n",
       "0               @eliostruyf So exciting, have fun!¬†üòä  LEGO_Group   \n",
       "1  These Brick-O-Lanterns are certainly all treat...  LEGO_Group   \n",
       "2  @dentistescabri Nous prenons la s√©curit√© de no...  LEGO_Group   \n",
       "4  @ashleydrixey Sounds like a perfect fit for th...  LEGO_Group   \n",
       "5  @irgator04 What a perfect way to start¬†your we...  LEGO_Group   \n",
       "\n",
       "                created_at timestamp archetype  \\\n",
       "0  2020-10-30 18:23:50.000       NaN    artist   \n",
       "1  2020-10-31 09:00:28.000       NaN    artist   \n",
       "2  2020-10-30 12:07:58.000       NaN    artist   \n",
       "4  2020-10-30 13:09:14.000       NaN    artist   \n",
       "5  2020-10-30 12:49:37.000       NaN    artist   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                                    [exciting, fun]  \n",
       "1  [brick, lanterns, certainly, treat, trick, get...  \n",
       "2  [nous, prenons, la, curit, de, nos, fans, tr, ...  \n",
       "4  [sounds, like, perfect, fit, aspiring, young, ...  \n",
       "5                     [perfect, way, start, weekend]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean-up the texts\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"tweet_text\"].apply(lambda x: clean_up_text(x))\n",
    "\n",
    "# Tokenize the cleaned texts\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"cleaned_text\"].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "# Remove the stopwords\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"cleaned_text\"].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Drop the rows with empty 'cleaned_text' field\n",
    "twitter_df = twitter_df.drop(twitter_df[twitter_df['cleaned_text'].map(len) < 1].index)\n",
    "\n",
    "# Print the new head of the dataset\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing SPMF on 'artist' archetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [exciting, fun]\n",
       "1    [brick, lanterns, certainly, treat, trick, get...\n",
       "2    [nous, prenons, la, curit, de, nos, fans, tr, ...\n",
       "3    [sounds, like, perfect, fit, aspiring, young, ...\n",
       "4                       [perfect, way, start, weekend]\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - try to get the most occurring words in the 'artist' archetype subset\n",
    "# Extract all the tweets for the 'artist' archetype\n",
    "artist_df = twitter_df.cleaned_text[twitter_df[\"archetype\"] == \"artist\"]\n",
    "\n",
    "# Reset the index of the subset\n",
    "artist_df = artist_df.reset_index(drop=True)\n",
    "\n",
    "# Print the head of the subset\n",
    "artist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of sentences\n",
    "artist_list = [\" \".join(row) for row in artist_df.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 328 ms\n",
      " Frequent sequences count : 13662\n",
      " Max memory (mb) : 126.75393676757812\n",
      " minsup = 12 sequences.\n",
      " Pattern count : 13662\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                   pattern  sup\n",
      "0               [exciting]   46\n",
      "1                    [fun]  171\n",
      "2               [fun, get]   14\n",
      "3          [fun, building]   20\n",
      "4         [fun, available]   12\n",
      "...                    ...  ...\n",
      "13657       [lunarnewyear]   13\n",
      "13658  [blackhistorymonth]   12\n",
      "13659       [goldenglobes]   14\n",
      "13660     [nintendodirect]   62\n",
      "13661             [sinnoh]   12\n",
      "\n",
      "[13662 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# SPMF - get the most frequent sequences\n",
    "spmf = Spmf(\"PrefixSpan\", input_direct=artist_list,\n",
    "            output_filename=\"output.txt\", arguments=[0.001, 3], input_type=\"text\")\n",
    "spmf.run()\n",
    "print(spmf.to_pandas_dataframe(pickle=True))\n",
    "spmf.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating most frequent sequences for all of the archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      "  8%|‚ñä         | 1/12 [00:13<02:33, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 288 ms\n",
      " Frequent sequences count : 13662\n",
      " Max memory (mb) : 126.65481567382812\n",
      " minsup = 12 sequences.\n",
      " Pattern count : 13662\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                   pattern       sup\n",
      "0               [exciting]  0.004242\n",
      "1                    [fun]  0.015768\n",
      "2               [fun, get]  0.000018\n",
      "3          [fun, building]  0.000026\n",
      "4         [fun, available]  0.000015\n",
      "...                    ...       ...\n",
      "13657       [lunarnewyear]  0.001199\n",
      "13658  [blackhistorymonth]  0.001107\n",
      "13659       [goldenglobes]  0.001291\n",
      "13660     [nintendodirect]  0.005717\n",
      "13661             [sinnoh]  0.001107\n",
      "\n",
      "[13662 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 279 ms\n",
      " Frequent sequences count : 47064\n",
      " Max memory (mb) : 80.16118621826172\n",
      " minsup = 7 sequences.\n",
      " Pattern count : 47064\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 17%|‚ñà‚ñã        | 2/12 [00:26<02:11, 13.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pattern           sup\n",
      "0                   [great]  1.425055e-02\n",
      "1             [great, news]  1.833057e-05\n",
      "2               [great, us]  3.462442e-05\n",
      "3           [great, us, us]  6.287541e-07\n",
      "4         [great, us, form]  6.287541e-07\n",
      "...                     ...           ...\n",
      "47059               [korea]  1.036404e-03\n",
      "47060            [eritrean]  1.813706e-03\n",
      "47061  [eritrean, soldiers]  1.425711e-05\n",
      "47062                [view]  1.036404e-03\n",
      "47063                [axum]  1.165954e-03\n",
      "\n",
      "[47064 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 222 ms\n",
      " Frequent sequences count : 23948\n",
      " Max memory (mb) : 100.57962799072266\n",
      " minsup = 9 sequences.\n",
      " Pattern count : 23948\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 25%|‚ñà‚ñà‚ñå       | 3/12 [00:34<01:37, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                pattern           sup\n",
      "0                               [hello]  4.234621e-02\n",
      "1                    [hello, apologize]  1.192696e-04\n",
      "2         [hello, apologize, confusion]  1.968917e-06\n",
      "3             [hello, apologize, tweet]  1.968917e-06\n",
      "4      [hello, apologize, accidentally]  1.968917e-06\n",
      "...                                 ...           ...\n",
      "23943                  [frisco, tx, tx]  9.844584e-07\n",
      "23944                         [houston]  1.287554e-03\n",
      "23945                     [houston, tx]  2.190666e-05\n",
      "23946                         [prairie]  1.430615e-03\n",
      "23947                     [prairie, tx]  2.434073e-05\n",
      "\n",
      "[23948 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:45<01:28, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 285 ms\n",
      " Frequent sequences count : 15553\n",
      " Max memory (mb) : 111.60638427734375\n",
      " minsup = 11 sequences.\n",
      " Pattern count : 15553\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                              pattern           sup\n",
      "0                            [crisis]  2.357648e-03\n",
      "1                           [reaches]  7.858827e-04\n",
      "2                             [point]  1.571765e-03\n",
      "3                              [team]  4.500964e-02\n",
      "4                        [team, team]  1.634964e-05\n",
      "...                               ...           ...\n",
      "15548      [depict, including, upper]  9.614844e-07\n",
      "15549    [depict, including, friends]  9.614844e-07\n",
      "15550  [depict, including, peninsula]  9.614844e-07\n",
      "15551     [depict, including, family]  9.614844e-07\n",
      "15552                     [peninsula]  1.500321e-03\n",
      "\n",
      "[15553 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 350 ms\n",
      " Frequent sequences count : 13352\n",
      " Max memory (mb) : 121.29603576660156\n",
      " minsup = 12 sequences.\n",
      " Pattern count : 13352\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [01:04<01:35, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     pattern       sup\n",
      "0                [thousands]  0.003294\n",
      "1                    [covid]  0.043062\n",
      "2            [covid, around]  0.000010\n",
      "3           [covid, country]  0.000010\n",
      "4              [covid, even]  0.000013\n",
      "...                      ...       ...\n",
      "13347             [gamestop]  0.002684\n",
      "13348               [reddit]  0.000854\n",
      "13349         [perseverance]  0.000976\n",
      "13350   [perseverance, mars]  0.000012\n",
      "13351  [perseverance, rover]  0.000010\n",
      "\n",
      "[13352 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 241 ms\n",
      " Frequent sequences count : 45434\n",
      " Max memory (mb) : 114.45025634765625\n",
      " minsup = 6 sequences.\n",
      " Pattern count : 45434\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [01:19<01:24, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              pattern           sup\n",
      "0                               [hey]  9.787928e-03\n",
      "1                           [hey, tu]  5.081370e-05\n",
      "2                    [hey, tu, venir]  8.182311e-07\n",
      "3                       [hey, tu, en]  1.338924e-06\n",
      "4                       [hey, tu, dm]  1.190154e-06\n",
      "...                               ...           ...\n",
      "45429       [management, visit, find]  8.926158e-07\n",
      "45430  [management, visit, emergency]  9.670004e-07\n",
      "45431       [management, visit, near]  4.463079e-07\n",
      "45432                        [storms]  7.612833e-04\n",
      "45433                          [weso]  7.612833e-04\n",
      "\n",
      "[45434 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 246 ms\n",
      " Frequent sequences count : 37534\n",
      " Max memory (mb) : 118.01627349853516\n",
      " minsup = 8 sequences.\n",
      " Pattern count : 37534\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7/12 [01:30<01:06, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       pattern           sup\n",
      "0                        [due]  9.835025e-03\n",
      "1                  [due, high]  7.821054e-05\n",
      "2      [due, high, prioritize]  7.558529e-07\n",
      "3          [due, high, demand]  3.359346e-06\n",
      "4         [due, high, certain]  3.359346e-06\n",
      "...                        ...           ...\n",
      "37529         [valentine, day]  2.234587e-05\n",
      "37530                [tagging]  1.586294e-03\n",
      "37531            [tagging, us]  2.793234e-05\n",
      "37532      [tagging, us, find]  7.558529e-07\n",
      "37533          [tagging, find]  1.675940e-05\n",
      "\n",
      "[37534 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 245 ms\n",
      " Frequent sequences count : 28097\n",
      " Max memory (mb) : 114.41995239257812\n",
      " minsup = 11 sequences.\n",
      " Pattern count : 28097\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                 pattern       sup\n",
      "0               [people]  0.014386\n",
      "1       [people, people]  0.000025\n",
      "2      [people, ecuador]  0.000021\n",
      "3               [united]  0.002728\n",
      "4       [united, states]  0.000030\n",
      "...                  ...       ...\n",
      "28092      [eva, illouz]  0.000019\n",
      "28093           [illouz]  0.000909\n",
      "28094           [slavoj]  0.000909\n",
      "28095      [convenience]  0.001075\n",
      "28096     [fightthedebt]  0.000909\n",
      "\n",
      "[28097 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [01:41<00:49, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 378 ms\n",
      " Frequent sequences count : 30194\n",
      " Max memory (mb) : 125.59005737304688\n",
      " minsup = 12 sequences.\n",
      " Pattern count : 30194\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [01:56<00:39, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pattern           sup\n",
      "0                  [offer]  7.573263e-03\n",
      "1            [offer, food]  2.013247e-05\n",
      "2                   [food]  1.275930e-02\n",
      "3             [food, food]  3.523183e-05\n",
      "4       [food, food, open]  6.099919e-07\n",
      "...                    ...           ...\n",
      "30189            [healthy]  1.152453e-03\n",
      "30190             [amends]  1.564043e-03\n",
      "30191     [amends, policy]  2.264903e-05\n",
      "30192              [jenny]  9.878169e-04\n",
      "30193  [blackhistorymonth]  1.070135e-03\n",
      "\n",
      "[30194 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [02:06<00:24, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 194 ms\n",
      " Frequent sequences count : 18563\n",
      " Max memory (mb) : 88.94873046875\n",
      " minsup = 6 sequences.\n",
      " Pattern count : 18563\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                 pattern       sup\n",
      "0              [mission]  0.003156\n",
      "1                 [need]  0.010438\n",
      "2           [need, help]  0.000029\n",
      "3             [need, us]  0.000015\n",
      "4            [need, new]  0.000021\n",
      "...                  ...       ...\n",
      "18558    [valentinesday]  0.000728\n",
      "18559      [bankbalance]  0.010074\n",
      "18560               [vh]  0.000728\n",
      "18561            [fauci]  0.001456\n",
      "18562  [fauci, whataday]  0.000017\n",
      "\n",
      "[18563 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 257 ms\n",
      " Frequent sequences count : 16649\n",
      " Max memory (mb) : 101.14139556884766\n",
      " minsup = 10 sequences.\n",
      " Pattern count : 16649\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [02:17<00:11, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pattern           sup\n",
      "0                           [aww]  9.980040e-04\n",
      "1                         [thank]  3.629105e-02\n",
      "2                   [thank, much]  3.595630e-05\n",
      "3               [thank, much, us]  7.855333e-07\n",
      "4                   [thank, kind]  1.926231e-05\n",
      "...                           ...           ...\n",
      "16644  [blackhistorymonth, black]  1.284154e-05\n",
      "16645               [mckinseybhm]  1.542370e-03\n",
      "16646                       [bhm]  9.072764e-04\n",
      "16647                 [valentine]  1.179459e-03\n",
      "16648             [valentinesday]  1.088732e-03\n",
      "\n",
      "[16649 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 255 ms\n",
      " Frequent sequences count : 71403\n",
      " Max memory (mb) : 104.82957458496094\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 71403\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-1751e09f43bc>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             pattern           sup\n",
      "0                            [story]  7.396915e-03\n",
      "1                       [story, kim]  1.126215e-05\n",
      "2                [story, kim, jones]  4.750281e-07\n",
      "3                     [story, jones]  1.126215e-05\n",
      "4                        [story, us]  1.970876e-05\n",
      "...                              ...           ...\n",
      "71398  [beauvais, arthur, kersauson]  4.750281e-07\n",
      "71399         [beauvais, arthur, de]  4.750281e-07\n",
      "71400          [beauvais, kersauson]  1.126215e-05\n",
      "71401                 [beauvais, de]  1.126215e-05\n",
      "71402      [beauvais, de, kersauson]  4.750281e-07\n",
      "\n",
      "[71403 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [02:27<00:00, 12.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generating \n",
    "archetype_list = ['artist',\n",
    "                 'caregiver',\n",
    "                 'everyman',\n",
    "                 'explorer',\n",
    "                 'guru',\n",
    "                 'hero',\n",
    "                 'innocent',\n",
    "                 'jester',\n",
    "                 'magician',\n",
    "                 'rebel',\n",
    "                 'ruler',\n",
    "                 'seducer']\n",
    "\n",
    "full_df = pd.DataFrame(columns=['chunk'] + archetype_list)\n",
    "\n",
    "# Iterate over archetypes\n",
    "for archetype in tqdm(archetype_list):\n",
    "    # Extract all the tweets for the 'artist' archetype\n",
    "    tmp_df = twitter_df.cleaned_text[twitter_df[\"archetype\"] == archetype]\n",
    "\n",
    "    # Reset the index of the subset\n",
    "    tmp_df = tmp_df.reset_index(drop=True)\n",
    "    \n",
    "    # Calculate number of words, number of two-word and three-word combinations\n",
    "    unique_words = set()\n",
    "    unique_two_words = set()\n",
    "    unique_three_words = set()\n",
    "    \n",
    "    for row in tmp_df.tolist():\n",
    "        unique_words.update(row)\n",
    "        unique_two_words.update(itertools.permutations(row, 2))\n",
    "        unique_three_words.update(itertools.permutations(row, 3))\n",
    "    \n",
    "    cnt_single_word = len(unique_words)\n",
    "    cnt_two_words = len(unique_two_words)\n",
    "    cnt_three_words = len(unique_three_words)\n",
    "    \n",
    "    # Create a list of sentences\n",
    "    tmp_list = [\" \".join(row) for row in tmp_df.tolist()]\n",
    "    \n",
    "    # SPMF - get the most frequent sequences\n",
    "    spmf = Spmf(\"PrefixSpan\", input_direct=tmp_list,\n",
    "                output_filename=f\"sequence_files/output_{archetype}.txt\", arguments=[0.001, 3], input_type=\"text\")\n",
    "    spmf.run()\n",
    "    \n",
    "    spmf = spmf.to_pandas_dataframe(pickle=True)\n",
    "    \n",
    "    # Get the TF\n",
    "    spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
    "    spmf.sup[spmf.pattern.map(len) == 2] = spmf.sup[spmf.pattern.map(len) == 2].apply(lambda x: float(x / cnt_two_words)) \n",
    "    spmf.sup[spmf.pattern.map(len) == 3] = spmf.sup[spmf.pattern.map(len) == 3].apply(lambda x: float(x / cnt_three_words)) \n",
    "    \n",
    "    print(spmf)\n",
    "    spmf.to_csv(f\"sequence_files/output_{archetype}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 12.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Merge all files into a single dataframe\n",
    "total_df = pd.DataFrame(columns=[\"pattern\"] + archetype_list)\n",
    "for archetype in tqdm(archetype_list):\n",
    "    # Read file\n",
    "    new_df = pd.read_csv(f\"sequence_files/output_{archetype}.csv\", sep=\",\", index_col=0)\n",
    "    new_df = new_df.rename(columns={\"sup\": archetype})\n",
    "    \n",
    "    # Merge it with the other ones\n",
    "    frames = [total_df, new_df]\n",
    "    total_df = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>artist</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>everyman</th>\n",
       "      <th>explorer</th>\n",
       "      <th>guru</th>\n",
       "      <th>hero</th>\n",
       "      <th>innocent</th>\n",
       "      <th>jester</th>\n",
       "      <th>magician</th>\n",
       "      <th>rebel</th>\n",
       "      <th>ruler</th>\n",
       "      <th>seducer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['exciting']</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['fun']</td>\n",
       "      <td>0.015768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['fun', 'get']</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['fun', 'building']</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['fun', 'available']</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361448</th>\n",
       "      <td>['beauvais', 'arthur', 'kersauson']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.75028e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361449</th>\n",
       "      <td>['beauvais', 'arthur', 'de']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.75028e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361450</th>\n",
       "      <td>['beauvais', 'kersauson']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.12621e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361451</th>\n",
       "      <td>['beauvais', 'de']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.12621e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361452</th>\n",
       "      <td>['beauvais', 'de', 'kersauson']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.75028e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361453 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    pattern    artist caregiver everyman  \\\n",
       "0                              ['exciting']  0.004242       NaN      NaN   \n",
       "1                                   ['fun']  0.015768       NaN      NaN   \n",
       "2                            ['fun', 'get']  0.000018       NaN      NaN   \n",
       "3                       ['fun', 'building']  0.000026       NaN      NaN   \n",
       "4                      ['fun', 'available']  0.000015       NaN      NaN   \n",
       "...                                     ...       ...       ...      ...   \n",
       "361448  ['beauvais', 'arthur', 'kersauson']       NaN       NaN      NaN   \n",
       "361449         ['beauvais', 'arthur', 'de']       NaN       NaN      NaN   \n",
       "361450            ['beauvais', 'kersauson']       NaN       NaN      NaN   \n",
       "361451                   ['beauvais', 'de']       NaN       NaN      NaN   \n",
       "361452      ['beauvais', 'de', 'kersauson']       NaN       NaN      NaN   \n",
       "\n",
       "       explorer guru hero innocent jester magician rebel ruler      seducer  \n",
       "0           NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "1           NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "2           NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "3           NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "4           NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "...         ...  ...  ...      ...    ...      ...   ...   ...          ...  \n",
       "361448      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  4.75028e-07  \n",
       "361449      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  4.75028e-07  \n",
       "361450      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  1.12621e-05  \n",
       "361451      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  1.12621e-05  \n",
       "361452      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  4.75028e-07  \n",
       "\n",
       "[361453 rows x 13 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataframe\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_func = {\n",
    "    \"pattern\": \"first\",\n",
    "    \"artist\": \"sum\",\n",
    "    \"caregiver\": \"sum\",\n",
    "    \"everyman\": \"sum\",\n",
    "    \"explorer\": \"sum\",\n",
    "    \"guru\": \"sum\",\n",
    "    \"hero\": \"sum\",\n",
    "    \"innocent\": \"sum\",\n",
    "    \"jester\": \"sum\",\n",
    "    \"magician\": \"sum\",\n",
    "    \"rebel\": \"sum\",\n",
    "    \"ruler\": \"sum\",\n",
    "    \"seducer\": \"sum\"\n",
    "}\n",
    "total_df = total_df.groupby(\"pattern\").aggregate(aggregate_func)\n",
    "total_df = total_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>artist</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>everyman</th>\n",
       "      <th>explorer</th>\n",
       "      <th>guru</th>\n",
       "      <th>hero</th>\n",
       "      <th>innocent</th>\n",
       "      <th>jester</th>\n",
       "      <th>magician</th>\n",
       "      <th>rebel</th>\n",
       "      <th>ruler</th>\n",
       "      <th>seducer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['aaron']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['abbie']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ability']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['able', 'able']</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['able', 'access']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305816</th>\n",
       "      <td>['zip']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305817</th>\n",
       "      <td>['zone']</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305818</th>\n",
       "      <td>['zoom']</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305819</th>\n",
       "      <td>['zu']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305820</th>\n",
       "      <td>['zum']</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305821 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pattern    artist  caregiver  everyman  explorer      guru  \\\n",
       "0                ['aaron']  0.000000   0.000000       0.0  0.000786  0.000000   \n",
       "1                ['abbie']  0.000000   0.000000       0.0  0.000000  0.000000   \n",
       "2              ['ability']  0.000000   0.000000       0.0  0.001072  0.000793   \n",
       "3         ['able', 'able']  0.000042   0.000000       0.0  0.000000  0.000000   \n",
       "4       ['able', 'access']  0.000000   0.000000       0.0  0.000000  0.000000   \n",
       "...                    ...       ...        ...       ...       ...       ...   \n",
       "305816             ['zip']  0.000000   0.003239       0.0  0.000000  0.000000   \n",
       "305817            ['zone']  0.001107   0.000000       0.0  0.000000  0.000000   \n",
       "305818            ['zoom']  0.002029   0.000000       0.0  0.000000  0.001220   \n",
       "305819              ['zu']  0.000000   0.000000       0.0  0.000000  0.000000   \n",
       "305820             ['zum']  0.000000   0.000000       0.0  0.000000  0.000000   \n",
       "\n",
       "            hero  innocent    jester  magician     rebel     ruler  seducer  \n",
       "0       0.000653  0.000000  0.000000  0.000000  0.000000  0.000000      0.0  \n",
       "1       0.000000  0.000000  0.000000  0.003622  0.000000  0.000000      0.0  \n",
       "2       0.001740  0.000000  0.000000  0.000000  0.000971  0.000000      0.0  \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      0.0  \n",
       "4       0.000012  0.000000  0.000000  0.000000  0.000000  0.000000      0.0  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "305816  0.003045  0.000000  0.000000  0.000000  0.000728  0.000000      0.0  \n",
       "305817  0.000870  0.000000  0.000000  0.000000  0.000000  0.000998      0.0  \n",
       "305818  0.000000  0.000000  0.001406  0.000000  0.000000  0.000000      0.0  \n",
       "305819  0.000000  0.001904  0.000000  0.000000  0.000000  0.000000      0.0  \n",
       "305820  0.000000  0.001058  0.000000  0.000000  0.000000  0.000000      0.0  \n",
       "\n",
       "[305821 rows x 13 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the full DataFrame\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current DataFrame\n",
    "total_df.to_csv(\"phrase_frequency_no_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Calculate document frequency for every archetype\n",
    "import math\n",
    "\n",
    "total_df = pd.read_csv(\"phrase_frequency_no_df.csv\", index_col=0)\n",
    "\n",
    "for archetype in archetype_list:\n",
    "    print(f\"Archetype {archetype}:\")\n",
    "    \n",
    "    twitter_subset = twitter_df.cleaned_text[twitter_df[\"archetype\"] == archetype]\n",
    "    \n",
    "    # Select non-zero elements and calculate DF for every element\n",
    "    for _, row in tqdm(total_df.iterrows()):\n",
    "        if row[archetype] > 0.0:\n",
    "            phrase = row[archetype]\n",
    "            phrase_cnt = 0\n",
    "            for line in twitter_subset:\n",
    "                if phrase in line:\n",
    "                    phrase_cnt += 1\n",
    "\n",
    "            row[archetype] = row[archetype] * math.log(len(twitter_df) / (phrase_cnt + 1))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
