{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ee3de9-07e0-42f1-bf3d-437a5e6e9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate words with archetypes/character traits as intermediate layer\n",
    "# and with influencer as the \"last\" layer\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os\n",
    "import toml\n",
    "import re\n",
    "import itertools\n",
    "from text_cleaner import *\n",
    "import operator\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def extract_hashtags(post_text):\n",
    "    HASH_RE = re.compile(r\"\\#\\w+\")\n",
    "    out_list = re.findall(HASH_RE, post_text)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179b142-6956-4509-bb67-60a0faca4c06",
   "metadata": {},
   "source": [
    "## AGDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab12087-2935-47e5-a341-35f63de4a316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['innocent', 'sage', 'explorer', 'outlaw', 'magician', 'hero', 'lover', 'jester', 'everyman', 'caregiver', 'ruler', 'creator', 'dominant', 'submissive', 'maximalist', 'minimalist', 'inspiring', 'systematic', 'discovering', 'conservative', 'verifying', 'overlooking', 'sharpening', 'harmonic', 'empathic', 'matter_of_fact', 'brave', 'protective', 'generous', 'thrifty', 'favourable', 'balanced', 'sensuality', 'intelligent', 'believe', 'egocentric', 'allocentric']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marek_grodzki</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vege_style_life</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliwka__2007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_przestrzeni_serca</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaradne_warsztaty</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "id                                                                             \n",
       "marek_grodzki             0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "vege_style_life           0.0   0.0       4.0     0.0       0.0   0.0    0.0   \n",
       "oliwka__2007              0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "z_przestrzeni_serca       4.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "zaradne_warsztaty         3.0   0.0       0.0     0.0       3.0   0.0    0.0   \n",
       "\n",
       "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
       "id                                                ...                         \n",
       "marek_grodzki           4.0       0.0        0.0  ...         2.0       3.0   \n",
       "vege_style_life         0.0       0.0        0.0  ...         4.0       4.0   \n",
       "oliwka__2007            0.0       4.0        0.0  ...         2.0       2.0   \n",
       "z_przestrzeni_serca     0.0       0.0        0.0  ...         4.0       3.0   \n",
       "zaradne_warsztaty       2.0       3.0        4.0  ...         3.0       4.0   \n",
       "\n",
       "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "id                                                                            \n",
       "marek_grodzki            4.0         4.0       3.0         4.0          4.0   \n",
       "vege_style_life          4.0         4.0       3.0         3.0          3.0   \n",
       "oliwka__2007             0.0         3.0       1.0         2.0          4.0   \n",
       "z_przestrzeni_serca      0.0         4.0       4.0         3.0          4.0   \n",
       "zaradne_warsztaty        0.0         2.0       2.0         4.0          2.0   \n",
       "\n",
       "                     believe  egocentric  allocentric  \n",
       "id                                                     \n",
       "marek_grodzki            3.0         0.0          0.0  \n",
       "vege_style_life          2.0         0.0          3.0  \n",
       "oliwka__2007             1.0         0.0          3.0  \n",
       "z_przestrzeni_serca      4.0         0.0          1.0  \n",
       "zaradne_warsztaty        3.0         1.0          3.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .csv with archetypes\n",
    "arch_df = pd.read_csv('archetypes_pl.csv', index_col=0)\n",
    "\n",
    "# Save the order of columns\n",
    "trait_list = arch_df.columns.tolist()\n",
    "\n",
    "# Show the table header and column list\n",
    "print(trait_list)\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5bd1d1-123d-4fce-b6dd-b73ba640467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marek_grodzki</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vege_style_life</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliwka__2007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_przestrzeni_serca</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaradne_warsztaty</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "id                                                                             \n",
       "marek_grodzki             0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "vege_style_life           0.0   0.0       4.0     0.0       0.0   0.0    0.0   \n",
       "oliwka__2007              0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "z_przestrzeni_serca       4.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "zaradne_warsztaty         3.0   0.0       0.0     0.0       3.0   0.0    0.0   \n",
       "\n",
       "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
       "id                                                ...                         \n",
       "marek_grodzki           4.0       0.0        0.0  ...         2.0       3.0   \n",
       "vege_style_life         0.0       0.0        0.0  ...         4.0       4.0   \n",
       "oliwka__2007            0.0       4.0        0.0  ...         2.0       2.0   \n",
       "z_przestrzeni_serca     0.0       0.0        0.0  ...         4.0       3.0   \n",
       "zaradne_warsztaty       2.0       3.0        4.0  ...         3.0       4.0   \n",
       "\n",
       "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "id                                                                            \n",
       "marek_grodzki            4.0         4.0       3.0         4.0          4.0   \n",
       "vege_style_life          4.0         4.0       3.0         3.0          3.0   \n",
       "oliwka__2007             0.0         3.0       1.0         2.0          4.0   \n",
       "z_przestrzeni_serca      0.0         4.0       4.0         3.0          4.0   \n",
       "zaradne_warsztaty        0.0         2.0       2.0         4.0          2.0   \n",
       "\n",
       "                     believe  egocentric  allocentric  \n",
       "id                                                     \n",
       "marek_grodzki            3.0         0.0          0.0  \n",
       "vege_style_life          2.0         0.0          3.0  \n",
       "oliwka__2007             1.0         0.0          3.0  \n",
       "z_przestrzeni_serca      4.0         0.0          1.0  \n",
       "zaradne_warsztaty        3.0         1.0          3.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table preprocessing - replace all NaN with 2 (Unrelated/Don't know class), replace 0-5 values with the ones in range -1.0 - 1.0\n",
    "arch_df = arch_df.fillna(2)\n",
    "\n",
    "# Remove duplicated annotations, to exclude conflicting entries\n",
    "arch_df = arch_df[~arch_df.index.duplicated(keep='first')]\n",
    "\n",
    "# Print the head of the dataset after modification\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01998992-e9e8-4233-a3bf-7f6b04558db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [00:11, 43.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Check if a user has a non-empty directory in the dataset, otherwise delete the user from the list\n",
    "available_arch_df = copy.deepcopy(arch_df)\n",
    "posts = []\n",
    "\n",
    "BASE_DIR = \"instagram_cleared\"\n",
    "\n",
    "# Iterate over whole DataFrame\n",
    "for i, row in tqdm(arch_df.iterrows()):\n",
    "    profile_posts = []\n",
    "    profile_hashtags = []\n",
    "    \n",
    "    # Get all posts per profile\n",
    "    profile_path = os.path.join(BASE_DIR, i)\n",
    "    for file in os.listdir(profile_path):\n",
    "        if not file.endswith(\".toml\"):\n",
    "            with open(os.path.join(profile_path, file), \"r\") as post_f:\n",
    "                read_text = post_f.read()\n",
    "                profile_posts.append(remove_stopwords(clean_up_text(read_text)))\n",
    "                profile_hashtags.append(extract_hashtags(read_text))\n",
    "\n",
    "    # Merge lists - a single list for a single influencer\n",
    "    profile_hashtags = list(itertools.chain.from_iterable(profile_hashtags))\n",
    "    posts.append(list(itertools.chain.from_iterable([profile_posts, [profile_hashtags]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a0c480-f0cc-4417-83df-f3e65a99b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map usernames to indices\n",
    "users = list(arch_df.index.values)\n",
    "user_indices = {k: users.index(k) for k in users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26abf97e-122c-48f5-b75c-1e595687cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required pickles\n",
    "with open(\"softmax_word_trait_array.pickle\", \"rb\") as f:\n",
    "    word_df = pickle.load(f)\n",
    "\n",
    "# Word map - to easily create output vectors\n",
    "word_map = word_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5861f97-8a8b-4845-82cf-2d41d47a7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def get_trait_dot_product(post_text: str, word_map: list, word_dataframe: pd.DataFrame) -> list:\n",
    "    # Filter out the text\n",
    "    filtered_post = remove_stopwords(clean_up_text(post_text))\n",
    "    filtered_post += extract_hashtags(post_text)\n",
    "    \n",
    "    # Create a vector for dot product vector\n",
    "    post_vector = [0] * len(word_map)\n",
    "    \n",
    "    # Calculate word occurrences\n",
    "    word_ctr = Counter(filtered_post)\n",
    "    \n",
    "    for word, freq in word_ctr.items():\n",
    "        if word in word_map:\n",
    "            post_vector[word_map.index(word)] = freq\n",
    "    \n",
    "    # Calculate dot product for a given text\n",
    "    word_dot = word_dataframe.dot(post_vector)\n",
    "    \n",
    "    out_vec = pd.Series()\n",
    "    for trait in trait_list:\n",
    "        out_vec = out_vec.append(pd.Series([np.argmax(softmax(word_dot.loc[trait]))], index=[trait]))\n",
    "    \n",
    "    return out_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cea5222-df85-425e-9d5d-3cc1ee1716f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the table from file\n",
    "new_arch_df = pd.read_csv(\"influencer_recalc.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64252d33-1596-4cca-8a8e-e66be8babb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating the dot product of trait <-> influencer relation\n",
    "def get_influencer_dot_product(trait_output: list, influencer_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    return influencer_dataframe.dot(trait_output)\n",
    "\n",
    "# Method for calculating the similarity\n",
    "def calculate_similarity(post_text: str, \n",
    "                         word_map: list, \n",
    "                         word_dataframe: pd.DataFrame,\n",
    "                         influencer_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Calculate word-trait dot product\n",
    "    post_result = get_trait_dot_product(post_text, word_map, word_dataframe)\n",
    "    \n",
    "    # Calculate trait-influencer dot product\n",
    "    inf_dot_product = get_influencer_dot_product(post_result, influencer_dataframe)\n",
    "\n",
    "    # Get the sum of influencer traits\n",
    "    influencer_sum = influencer_dataframe.sum(axis=1)\n",
    "    \n",
    "    # Normalize the results\n",
    "    inf_dot_product = inf_dot_product.divide(influencer_sum)\n",
    "    \n",
    "    # Generate new dataframe - one row per influencer\n",
    "    inf_df = pd.Series(index=influencer_dataframe.index)\n",
    "    \n",
    "    # Replace all data in temporary df with calculated post result\n",
    "    for idx in inf_df.index:\n",
    "        inf_df.loc[idx] = np.linalg.norm(influencer_dataframe.loc[idx] - post_result)\n",
    "    \n",
    "    return inf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1d904e-17fe-4403-a727-141af464d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trait accuracy - round the results\n",
    "def natural_round(x: float) -> int:\n",
    "    out = int(x // 1)\n",
    "    return out + 1 if (x - out) >= 0.5 else out\n",
    "\n",
    "def accuracy_per_trait(input_vector: pd.Series, annotated_vector: pd.Series) -> np.array:\n",
    "    out_array = np.array([0] * 37, dtype=np.int)\n",
    "    for i in range(len(out_array)):\n",
    "        if natural_round(input_vector[i]) == annotated_vector[i]:\n",
    "            out_array[i] = 1\n",
    "    return out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b88d0d-1932-4594-a0ca-69146fa4435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]<ipython-input-7-8fb06d5113f2>:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  out_vec = pd.Series()\n",
      "Average accuracy: 49.56: : 508it [13:31,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(arch_df.iterrows())\n",
    "accuracy = 0\n",
    "\n",
    "# Out accuracy vector\n",
    "total_accuracy = np.array([0] * 37, dtype=np.int)\n",
    "\n",
    "for idx, row in pbar:\n",
    "    user_text = list(itertools.chain.from_iterable(posts[users.index(idx)]))\n",
    "    user_text = \" \".join(user_text)\n",
    "    sim_output = get_trait_dot_product(user_text, word_map, word_df)\n",
    "    user_accuracy = accuracy_per_trait(sim_output, row)\n",
    "    total_accuracy += user_accuracy\n",
    "    pbar.set_description(f\"Average accuracy: {round(np.mean(np.divide(total_accuracy, users.index(idx)+1))*100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5876adbd-7002-4d5e-939d-70c74290bc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ACCURACY ON TRAINING DATASET ---\n",
      "Average accuracy: 49.56%\n",
      "Accuracy per trait:\n",
      "innocent: 47.05%\n",
      "sage: 44.49%\n",
      "explorer: 43.7%\n",
      "outlaw: 43.11%\n",
      "magician: 37.2%\n",
      "hero: 49.8%\n",
      "lover: 57.48%\n",
      "jester: 49.41%\n",
      "everyman: 27.17%\n",
      "caregiver: 46.26%\n",
      "ruler: 48.23%\n",
      "creator: 40.55%\n",
      "dominant: 53.54%\n",
      "submissive: 58.86%\n",
      "maximalist: 42.13%\n",
      "minimalist: 54.33%\n",
      "inspiring: 42.32%\n",
      "systematic: 54.92%\n",
      "discovering: 54.92%\n",
      "conservative: 46.65%\n",
      "verifying: 42.91%\n",
      "overlooking: 44.09%\n",
      "sharpening: 68.9%\n",
      "harmonic: 51.18%\n",
      "empathic: 49.02%\n",
      "matter_of_fact: 54.92%\n",
      "brave: 68.5%\n",
      "protective: 61.61%\n",
      "generous: 34.45%\n",
      "thrifty: 66.93%\n",
      "favourable: 69.09%\n",
      "balanced: 40.75%\n",
      "sensuality: 48.23%\n",
      "intelligent: 36.22%\n",
      "believe: 56.69%\n",
      "egocentric: 51.18%\n",
      "allocentric: 47.05%\n"
     ]
    }
   ],
   "source": [
    "# Show total accuracy\n",
    "scaled_accuracy = np.divide(total_accuracy, len(arch_df))\n",
    "avg_accuracy = np.mean(scaled_accuracy)\n",
    "\n",
    "print(\"--- ACCURACY ON TRAINING DATASET ---\")\n",
    "\n",
    "print(f\"Average accuracy: {round(avg_accuracy*100, 2)}%\")\n",
    "print(\"Accuracy per trait:\")\n",
    "for i in range(len(trait_list)):\n",
    "    print(f\"{trait_list[i]}: {round(scaled_accuracy[i] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97623efe-073d-4ac9-ab66-4824a9d8362a",
   "metadata": {},
   "source": [
    "## AGDS - accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a78d1c-d6d7-4f39-b463-75d78e785bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 35.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['innocent', 'sage', 'explorer', 'outlaw', 'magician', 'hero', 'lover', 'jester', 'everyman', 'caregiver', 'ruler', 'creator', 'dominant', 'submissive', 'maximalist', 'minimalist', 'inspiring', 'systematic', 'discovering', 'conservative', 'verifying', 'overlooking', 'sharpening', 'harmonic', 'empathic', 'matter_of_fact', 'brave', 'protective', 'generous', 'thrifty', 'favourable', 'balanced', 'sensuality', 'intelligent', 'believe', 'egocentric', 'allocentric']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "177it [00:04, 42.56it/s]\n",
      "0it [00:00, ?it/s]<ipython-input-7-8fb06d5113f2>:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  out_vec = pd.Series()\n",
      "Average test dataset accuracy: 17.12: : 177it [05:06,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ACCURACY ON TESTING DATASET ---\n",
      "Average test dataset accuracy: 17.12%\n",
      "Accuracy per trait:\n",
      "innocent: 19.77%\n",
      "sage: 18.64%\n",
      "explorer: 12.43%\n",
      "outlaw: 11.3%\n",
      "magician: 13.56%\n",
      "hero: 29.38%\n",
      "lover: 22.03%\n",
      "jester: 27.68%\n",
      "everyman: 13.56%\n",
      "caregiver: 12.43%\n",
      "ruler: 23.16%\n",
      "creator: 14.12%\n",
      "dominant: 7.91%\n",
      "submissive: 9.6%\n",
      "maximalist: 9.04%\n",
      "minimalist: 6.78%\n",
      "inspiring: 12.43%\n",
      "systematic: 18.64%\n",
      "discovering: 26.55%\n",
      "conservative: 15.25%\n",
      "verifying: 7.91%\n",
      "overlooking: 5.08%\n",
      "sharpening: 22.03%\n",
      "harmonic: 17.51%\n",
      "empathic: 24.86%\n",
      "matter_of_fact: 19.77%\n",
      "brave: 44.07%\n",
      "protective: 12.99%\n",
      "generous: 16.38%\n",
      "thrifty: 30.51%\n",
      "favourable: 21.47%\n",
      "balanced: 11.3%\n",
      "sensuality: 15.82%\n",
      "intelligent: 11.86%\n",
      "believe: 22.6%\n",
      "egocentric: 14.12%\n",
      "allocentric: 10.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the .csv with archetypes\n",
    "arch_df = pd.read_csv('test_archetypes_pl.csv', index_col=0)\n",
    "\n",
    "# Save the order of columns\n",
    "trait_list = arch_df.columns.tolist()\n",
    "\n",
    "# Show the table header and column list\n",
    "print(trait_list)\n",
    "arch_df.head()\n",
    "\n",
    "# Table preprocessing - replace all NaN with 2 (Unrelated/Don't know class), replace 0-5 values with the ones in range -1.0 - 1.0\n",
    "arch_df = arch_df.fillna(2)\n",
    "\n",
    "# Remove duplicated annotations, to exclude conflicting entries\n",
    "arch_df = arch_df[~arch_df.index.duplicated(keep='first')]\n",
    "\n",
    "# Print the head of the dataset after modification\n",
    "arch_df.head()\n",
    "\n",
    "# Check if a user has a non-empty directory in the dataset, otherwise delete the user from the list\n",
    "available_arch_df = copy.deepcopy(arch_df)\n",
    "posts = []\n",
    "\n",
    "BASE_DIR = \"instagram_cleared\"\n",
    "\n",
    "# Iterate over whole DataFrame\n",
    "for i, row in tqdm(arch_df.iterrows()):\n",
    "    profile_posts = []\n",
    "    profile_hashtags = []\n",
    "    \n",
    "    # Get all posts per profile\n",
    "    profile_path = os.path.join(BASE_DIR, i)\n",
    "    for file in os.listdir(profile_path):\n",
    "        if not file.endswith(\".toml\"):\n",
    "            with open(os.path.join(profile_path, file), \"r\") as post_f:\n",
    "                read_text = post_f.read()\n",
    "                profile_posts.append(remove_stopwords(clean_up_text(read_text)))\n",
    "                profile_hashtags.append(extract_hashtags(read_text))\n",
    "\n",
    "    # Merge lists - a single list for a single influencer\n",
    "    profile_hashtags = list(itertools.chain.from_iterable(profile_hashtags))\n",
    "    posts.append(list(itertools.chain.from_iterable([profile_posts, [profile_hashtags]])))\n",
    "    \n",
    "# Map usernames to indices\n",
    "users = list(arch_df.index.values)\n",
    "user_indices = {k: users.index(k) for k in users}\n",
    "\n",
    "pbar = tqdm(arch_df.iterrows())\n",
    "accuracy = 0\n",
    "\n",
    "# Out accuracy vector\n",
    "test_total_accuracy = np.array([0] * 37, dtype=np.int)\n",
    "\n",
    "for idx, row in pbar:\n",
    "    user_text = list(itertools.chain.from_iterable(posts[users.index(idx)]))\n",
    "    user_text = \" \".join(user_text)\n",
    "    sim_output = get_trait_dot_product(user_text, word_map, word_df)\n",
    "    user_accuracy = accuracy_per_trait(sim_output, row)\n",
    "    test_total_accuracy += user_accuracy\n",
    "    pbar.set_description(f\"Average test dataset accuracy: {round(np.mean(np.divide(test_total_accuracy, users.index(idx)+1))*100, 2)}\")\n",
    "    \n",
    "# Show total accuracy\n",
    "scaled_test_accuracy = np.divide(test_total_accuracy, len(arch_df))\n",
    "avg_test_accuracy = np.mean(scaled_test_accuracy)\n",
    "\n",
    "print(\"--- ACCURACY ON TESTING DATASET ---\")\n",
    "\n",
    "print(f\"Average test dataset accuracy: {round(avg_test_accuracy*100, 2)}%\")\n",
    "print(\"Accuracy per trait:\")\n",
    "for i in range(len(trait_list)):\n",
    "    print(f\"{trait_list[i]}: {round(scaled_test_accuracy[i] * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a48f92-b5d4-458d-b104-ce4fc750a081",
   "metadata": {},
   "source": [
    "## AI - Recurrent Neural Network (LSTM) - accuracy on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80273560-6c36-4819-80e9-73133832dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI model comparison\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    \n",
    "# Dataset preparation + text preprocessing\n",
    "def clean_post(src_text: str) -> str:\n",
    "    # Extract posts and hashtags\n",
    "    extracted_text = remove_stopwords(clean_up_text(src_text))\n",
    "    extracted_hashtags = extract_hashtags(src_text)\n",
    "    return extracted_text + extracted_hashtags\n",
    "\n",
    "def generate_dataset(dataset_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out_dataset = pd.DataFrame(columns=[\"text\"] + list(dataset_df.columns))\n",
    "    # Iterate over whole DataFrame\n",
    "    for i, row in tqdm(dataset_df.iterrows()):\n",
    "        trait_row = copy.deepcopy(row)\n",
    "        profile_posts = []\n",
    "\n",
    "        # Get all posts per profile\n",
    "        profile_path = os.path.join(BASE_DIR, i)\n",
    "        for file in os.listdir(profile_path):\n",
    "            if not file.endswith(\".toml\"):\n",
    "                with open(os.path.join(profile_path, file), \"r\") as post_f:\n",
    "                    read_text = post_f.read()\n",
    "                    profile_posts.extend(clean_post(read_text))\n",
    "        trait_row[\"text\"] = \" \".join(profile_posts)\n",
    "        out_dataset = out_dataset.append(trait_row)\n",
    "    out_dataset = out_dataset.reset_index(drop=True)\n",
    "    return out_dataset\n",
    "\n",
    "def format_labels(data_set):\n",
    "    return (tf.keras.utils.to_categorical(np.array(data_set.pop(\"innocent\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"sage\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"explorer\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"outlaw\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"magician\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"hero\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"lover\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"jester\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"everyman\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"caregiver\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"ruler\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"creator\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"dominant\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"submissive\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"maximalist\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"minimalist\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"inspiring\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"systematic\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"discovering\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"conservative\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"verifying\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"overlooking\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"sharpening\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"harmonic\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"empathic\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"matter_of_fact\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"brave\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"protective\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"generous\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"thrifty\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"favourable\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"balanced\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"sensuality\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"intelligent\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"believe\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"egocentric\")), num_classes=5),\n",
    "    tf.keras.utils.to_categorical(np.array(data_set.pop(\"allocentric\")), num_classes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e0ccb6-c769-44f1-b0d4-5e58a119565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 32.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['innocent', 'sage', 'explorer', 'outlaw', 'magician', 'hero', 'lover', 'jester', 'everyman', 'caregiver', 'ruler', 'creator', 'dominant', 'submissive', 'maximalist', 'minimalist', 'inspiring', 'systematic', 'discovering', 'conservative', 'verifying', 'overlooking', 'sharpening', 'harmonic', 'empathic', 'matter_of_fact', 'brave', 'protective', 'generous', 'thrifty', 'favourable', 'balanced', 'sensuality', 'intelligent', 'believe', 'egocentric', 'allocentric']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [00:14, 34.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "\n",
    "# Load the .csv with archetypes\n",
    "arch_df = pd.read_csv('archetypes_pl.csv', index_col=0)\n",
    "\n",
    "# Save the order of columns\n",
    "trait_list = arch_df.columns.tolist()\n",
    "\n",
    "# Show the table header and column list\n",
    "print(trait_list)\n",
    "arch_df.head()\n",
    "\n",
    "# Table preprocessing - replace all NaN with 2 (Unrelated/Don't know class), replace 0-5 values with the ones in range -1.0 - 1.0\n",
    "arch_df = arch_df.fillna(2.0)\n",
    "\n",
    "# Remove duplicated annotations, to exclude conflicting entries\n",
    "arch_df = arch_df[~arch_df.index.duplicated(keep='first')]\n",
    "\n",
    "# Print the head of the dataset after modification\n",
    "arch_df.head()\n",
    "\n",
    "# Create pandas-like dataset\n",
    "BASE_DIR = \"instagram_cleared\"\n",
    "\n",
    "# Initialize text dataset DataFrames\n",
    "train_dataset = generate_dataset(arch_df)\n",
    "\n",
    "# Create X,y sets\n",
    "X_train = train_dataset.pop(\"text\")\n",
    "y_train = format_labels(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a760bb12-888b-4819-a439-e7a293dd7906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 6s 130ms/step - loss: 49.3094 - innocent_out_loss: 1.1105 - sage_out_loss: 1.2853 - explorer_out_loss: 1.4117 - outlaw_out_loss: 1.2711 - magician_out_loss: 1.1620 - hero_out_loss: 1.2414 - lover_out_loss: 1.3988 - jester_out_loss: 1.2898 - everyman_out_loss: 1.1806 - caregiver_out_loss: 1.3274 - ruler_out_loss: 1.3043 - creator_out_loss: 1.2838 - dominant_out_loss: 1.4798 - submissive_out_loss: 1.4107 - maximalist_out_loss: 1.2838 - minimalist_out_loss: 1.4295 - inspiring_out_loss: 1.1710 - systematic_out_loss: 1.4243 - discovering_out_loss: 1.2853 - conservative_out_loss: 1.3898 - verifying_out_loss: 1.2470 - overlooking_out_loss: 1.4476 - sharpening_out_loss: 1.5199 - harmonic_out_loss: 1.1734 - empathic_out_loss: 1.1892 - matter_of_fact_out_loss: 1.4526 - brave_out_loss: 1.5141 - protective_out_loss: 1.5033 - generous_out_loss: 1.0480 - thrifty_out_loss: 1.4513 - favourable_out_loss: 1.5153 - balanced_out_loss: 1.2248 - sensuality_out_loss: 1.3541 - intelligent_out_loss: 1.3474 - believe_out_loss: 1.4344 - egocentric_out_loss: 1.3977 - allocentric_out_loss: 1.3483 - innocent_out_accuracy: 0.5374 - sage_out_accuracy: 0.4193 - explorer_out_accuracy: 0.4094 - outlaw_out_accuracy: 0.4803 - magician_out_accuracy: 0.5079 - hero_out_accuracy: 0.5020 - lover_out_accuracy: 0.3878 - jester_out_accuracy: 0.4606 - everyman_out_accuracy: 0.5177 - caregiver_out_accuracy: 0.4193 - ruler_out_accuracy: 0.5059 - creator_out_accuracy: 0.4252 - dominant_out_accuracy: 0.4173 - submissive_out_accuracy: 0.3307 - maximalist_out_accuracy: 0.5177 - minimalist_out_accuracy: 0.4134 - inspiring_out_accuracy: 0.5374 - systematic_out_accuracy: 0.4409 - discovering_out_accuracy: 0.5335 - conservative_out_accuracy: 0.4449 - verifying_out_accuracy: 0.5492 - overlooking_out_accuracy: 0.3957 - sharpening_out_accuracy: 0.3268 - harmonic_out_accuracy: 0.5945 - empathic_out_accuracy: 0.4567 - matter_of_fact_out_accuracy: 0.3898 - brave_out_accuracy: 0.2953 - protective_out_accuracy: 0.3248 - generous_out_accuracy: 0.5965 - thrifty_out_accuracy: 0.3465 - favourable_out_accuracy: 0.3602 - balanced_out_accuracy: 0.5433 - sensuality_out_accuracy: 0.4626 - intelligent_out_accuracy: 0.4213 - believe_out_accuracy: 0.3976 - egocentric_out_accuracy: 0.3661 - allocentric_out_accuracy: 0.4291\n",
      "--- ACCURACY ON TRAINING DATASET ---\n",
      "Average accuracy on training set - loaded model: 0.444988293422235\n"
     ]
    }
   ],
   "source": [
    "test_model = tf.keras.models.load_model(\"train_test_instagram/\")\n",
    "new_train_results = test_model.evaluate(X_train, y_train)\n",
    "\n",
    "print(\"--- ACCURACY ON TRAINING DATASET ---\")\n",
    "\n",
    "print('Average accuracy on training set - loaded model:', np.mean(new_train_results[-37:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846d342-0976-40a1-8b48-07459ea1e8ae",
   "metadata": {},
   "source": [
    "## AI - Recurrent Neural Network (LSTM) - accuracy on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a33ecf-dfb3-439f-bb49-0f4177c0ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['innocent', 'sage', 'explorer', 'outlaw', 'magician', 'hero', 'lover', 'jester', 'everyman', 'caregiver', 'ruler', 'creator', 'dominant', 'submissive', 'maximalist', 'minimalist', 'inspiring', 'systematic', 'discovering', 'conservative', 'verifying', 'overlooking', 'sharpening', 'harmonic', 'empathic', 'matter_of_fact', 'brave', 'protective', 'generous', 'thrifty', 'favourable', 'balanced', 'sensuality', 'intelligent', 'believe', 'egocentric', 'allocentric']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "177it [00:05, 33.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the .csv with archetypes\n",
    "arch_df = pd.read_csv('test_archetypes_pl.csv', index_col=0)\n",
    "\n",
    "# Save the order of columns\n",
    "trait_list = arch_df.columns.tolist()\n",
    "\n",
    "# Show the table header and column list\n",
    "print(trait_list)\n",
    "arch_df.head()\n",
    "\n",
    "# Table preprocessing - replace all NaN with 2 (Unrelated/Don't know class), replace 0-5 values with the ones in range -1.0 - 1.0\n",
    "arch_df = arch_df.fillna(2.0)\n",
    "\n",
    "# Remove duplicated annotations, to exclude conflicting entries\n",
    "arch_df = arch_df[~arch_df.index.duplicated(keep='first')]\n",
    "\n",
    "# Print the head of the dataset after modification\n",
    "arch_df.head()\n",
    "\n",
    "# Create pandas-like dataset\n",
    "BASE_DIR = \"instagram_cleared\"\n",
    "\n",
    "# Initialize text dataset DataFrames\n",
    "test_dataset = generate_dataset(arch_df)\n",
    "\n",
    "# Create X,y sets\n",
    "X_test = test_dataset.pop(\"text\")\n",
    "y_test = format_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb60c6d6-7d7d-48a2-9366-a3fd8d79326f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 115ms/step - loss: 49.5537 - innocent_out_loss: 1.0187 - sage_out_loss: 1.3885 - explorer_out_loss: 1.6411 - outlaw_out_loss: 1.4663 - magician_out_loss: 1.5193 - hero_out_loss: 1.6101 - lover_out_loss: 1.6924 - jester_out_loss: 1.5528 - everyman_out_loss: 1.1351 - caregiver_out_loss: 1.5793 - ruler_out_loss: 1.7106 - creator_out_loss: 1.4347 - dominant_out_loss: 1.2575 - submissive_out_loss: 1.3354 - maximalist_out_loss: 1.0453 - minimalist_out_loss: 1.1695 - inspiring_out_loss: 1.1904 - systematic_out_loss: 1.2106 - discovering_out_loss: 1.2775 - conservative_out_loss: 1.4470 - verifying_out_loss: 1.0010 - overlooking_out_loss: 1.2285 - sharpening_out_loss: 1.3955 - harmonic_out_loss: 1.0531 - empathic_out_loss: 1.4315 - matter_of_fact_out_loss: 1.3649 - brave_out_loss: 1.4069 - protective_out_loss: 1.4184 - generous_out_loss: 0.8620 - thrifty_out_loss: 1.2680 - favourable_out_loss: 1.6082 - balanced_out_loss: 1.2233 - sensuality_out_loss: 1.2239 - intelligent_out_loss: 1.2087 - believe_out_loss: 1.2958 - egocentric_out_loss: 1.5343 - allocentric_out_loss: 1.3473 - innocent_out_accuracy: 0.8418 - sage_out_accuracy: 0.0960 - explorer_out_accuracy: 0.1073 - outlaw_out_accuracy: 0.0960 - magician_out_accuracy: 0.1073 - hero_out_accuracy: 0.1073 - lover_out_accuracy: 0.0960 - jester_out_accuracy: 0.0904 - everyman_out_accuracy: 0.7401 - caregiver_out_accuracy: 0.1130 - ruler_out_accuracy: 0.1130 - creator_out_accuracy: 0.0960 - dominant_out_accuracy: 0.8305 - submissive_out_accuracy: 0.5763 - maximalist_out_accuracy: 0.8870 - minimalist_out_accuracy: 0.8870 - inspiring_out_accuracy: 0.7175 - systematic_out_accuracy: 0.7797 - discovering_out_accuracy: 0.6102 - conservative_out_accuracy: 0.4689 - verifying_out_accuracy: 0.8870 - overlooking_out_accuracy: 0.8814 - sharpening_out_accuracy: 0.7458 - harmonic_out_accuracy: 0.7910 - empathic_out_accuracy: 0.5706 - matter_of_fact_out_accuracy: 0.5763 - brave_out_accuracy: 0.5763 - protective_out_accuracy: 0.1921 - generous_out_accuracy: 0.8870 - thrifty_out_accuracy: 0.8927 - favourable_out_accuracy: 0.3616 - balanced_out_accuracy: 0.5706 - sensuality_out_accuracy: 0.7966 - intelligent_out_accuracy: 0.7627 - believe_out_accuracy: 0.7062 - egocentric_out_accuracy: 0.0000e+00 - allocentric_out_accuracy: 0.5593\n",
      "--- ACCURACY ON TEST DATASET ---\n",
      "Average accuracy on test dataset - loaded model: 0.5167201066742072\n"
     ]
    }
   ],
   "source": [
    "new_test_results = test_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"--- ACCURACY ON TEST DATASET ---\")\n",
    "\n",
    "print('Average accuracy on test dataset - loaded model:', np.mean(new_test_results[-37:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285f58b-dbc1-470e-8d7b-7f56bc1b5976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
