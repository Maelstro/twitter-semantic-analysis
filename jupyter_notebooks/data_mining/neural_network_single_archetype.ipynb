{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network for \n",
    "import pandas as pd\n",
    "from text_cleaner import *\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "mapping = {\n",
    "    \"artist\": 0,\n",
    "    \"caregiver\": 1,\n",
    "    \"everyman\": 2,\n",
    "    \"explorer\": 3,\n",
    "    \"guru\": 4,\n",
    "    \"hero\": 5,\n",
    "    \"innocent\": 6,\n",
    "    \"jester\": 7,\n",
    "    \"magician\": 8,\n",
    "    \"rebel\": 9,\n",
    "    \"ruler\": 10,\n",
    "    \"seducer\": 11\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        _id  \\\n",
       "0  5f9f1c36b38e10f823bf2cdc   \n",
       "1  5f9f1c36b38e10f823bf2cdd   \n",
       "2  5f9f1c36b38e10f823bf2cde   \n",
       "3  5f9f1c36b38e10f823bf2cdf   \n",
       "6  5f9f1c36b38e10f823bf2ce2   \n",
       "\n",
       "                                          tweet_text    username  \\\n",
       "0  @AndruEdwards The hard work has paid off, this...  LEGO_Group   \n",
       "1  @soosupersam A great way to surprise your love...  LEGO_Group   \n",
       "2  You can now just bring the fun home, and reliv...  LEGO_Group   \n",
       "3  @at_knb Happy birthday to the master builder! ...  LEGO_Group   \n",
       "6                        @Ranchie This is the way! ðŸ˜€  LEGO_Group   \n",
       "\n",
       "                created_at timestamp archetype  \\\n",
       "0  2020-11-01 19:32:05.000       NaN    artist   \n",
       "1  2020-11-01 19:09:40.000       NaN    artist   \n",
       "2  2020-11-01 14:00:36.000       NaN    artist   \n",
       "3  2020-10-31 17:16:57.000       NaN    artist   \n",
       "6  2020-10-31 15:16:26.000       NaN    artist   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                        [hard, work, paid, awesome]  \n",
       "1                 [great, way, surprise, loved, one]  \n",
       "2  [bring, fun, home, relive, favorite, childhood...  \n",
       "3  [happy, birthday, master, builder, hope, magic...  \n",
       "6                                              [way]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>tweet_text</th>\n      <th>username</th>\n      <th>created_at</th>\n      <th>timestamp</th>\n      <th>archetype</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5f9f1c36b38e10f823bf2cdc</td>\n      <td>@AndruEdwards The hard work has paid off, this...</td>\n      <td>LEGO_Group</td>\n      <td>2020-11-01 19:32:05.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[hard, work, paid, awesome]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5f9f1c36b38e10f823bf2cdd</td>\n      <td>@soosupersam A great way to surprise your love...</td>\n      <td>LEGO_Group</td>\n      <td>2020-11-01 19:09:40.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[great, way, surprise, loved, one]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5f9f1c36b38e10f823bf2cde</td>\n      <td>You can now just bring the fun home, and reliv...</td>\n      <td>LEGO_Group</td>\n      <td>2020-11-01 14:00:36.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[bring, fun, home, relive, favorite, childhood...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5f9f1c36b38e10f823bf2cdf</td>\n      <td>@at_knb Happy birthday to the master builder! ...</td>\n      <td>LEGO_Group</td>\n      <td>2020-10-31 17:16:57.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[happy, birthday, master, builder, hope, magic...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5f9f1c36b38e10f823bf2ce2</td>\n      <td>@Ranchie This is the way! ðŸ˜€</td>\n      <td>LEGO_Group</td>\n      <td>2020-10-31 15:16:26.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[way]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Load the Twitter dataset\n",
    "twitter_df = pd.read_csv('tweets_14_03_2021.csv', index_col=0)\n",
    "\n",
    "# Print the head of the loaded dataset\n",
    "twitter_df.head()\n",
    "\n",
    "# Clean-up the texts\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"tweet_text\"].apply(lambda x: clean_up_text(x))\n",
    "\n",
    "# Tokenize the cleaned texts\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"cleaned_text\"].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "# Remove the stopwords\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"cleaned_text\"].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Drop the rows with empty 'cleaned_text' field\n",
    "twitter_df = twitter_df.drop(twitter_df[twitter_df['cleaned_text'].map(len) < 1].index)\n",
    "\n",
    "# Print the new head of the dataset\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        _id  \\\n",
       "0  5f9f1c36b38e10f823bf2cdc   \n",
       "1  5f9f1c36b38e10f823bf2cdd   \n",
       "2  5f9f1c36b38e10f823bf2cde   \n",
       "3  5f9f1c36b38e10f823bf2cdf   \n",
       "6  5f9f1c36b38e10f823bf2ce2   \n",
       "\n",
       "                                          tweet_text    username  \\\n",
       "0  @AndruEdwards The hard work has paid off, this...  LEGO_Group   \n",
       "1  @soosupersam A great way to surprise your love...  LEGO_Group   \n",
       "2  You can now just bring the fun home, and reliv...  LEGO_Group   \n",
       "3  @at_knb Happy birthday to the master builder! ...  LEGO_Group   \n",
       "6                        @Ranchie This is the way! ðŸ˜€  LEGO_Group   \n",
       "\n",
       "                created_at timestamp archetype  \\\n",
       "0  2020-11-01 19:32:05.000       NaN    artist   \n",
       "1  2020-11-01 19:09:40.000       NaN    artist   \n",
       "2  2020-11-01 14:00:36.000       NaN    artist   \n",
       "3  2020-10-31 17:16:57.000       NaN    artist   \n",
       "6  2020-10-31 15:16:26.000       NaN    artist   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                        [hard, work, paid, awesome]   \n",
       "1                 [great, way, surprise, loved, one]   \n",
       "2  [bring, fun, home, relive, favorite, childhood...   \n",
       "3  [happy, birthday, master, builder, hope, magic...   \n",
       "6                                              [way]   \n",
       "\n",
       "                                       full_sentence  \n",
       "0                             hard work paid awesome  \n",
       "1                       great way surprise loved one  \n",
       "2  bring fun home relive favorite childhood memor...  \n",
       "3     happy birthday master builder hope magical day  \n",
       "6                                                way  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>tweet_text</th>\n      <th>username</th>\n      <th>created_at</th>\n      <th>timestamp</th>\n      <th>archetype</th>\n      <th>cleaned_text</th>\n      <th>full_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5f9f1c36b38e10f823bf2cdc</td>\n      <td>@AndruEdwards The hard work has paid off, this...</td>\n      <td>LEGO_Group</td>\n      <td>2020-11-01 19:32:05.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[hard, work, paid, awesome]</td>\n      <td>hard work paid awesome</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5f9f1c36b38e10f823bf2cdd</td>\n      <td>@soosupersam A great way to surprise your love...</td>\n      <td>LEGO_Group</td>\n      <td>2020-11-01 19:09:40.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[great, way, surprise, loved, one]</td>\n      <td>great way surprise loved one</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5f9f1c36b38e10f823bf2cde</td>\n      <td>You can now just bring the fun home, and reliv...</td>\n      <td>LEGO_Group</td>\n      <td>2020-11-01 14:00:36.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[bring, fun, home, relive, favorite, childhood...</td>\n      <td>bring fun home relive favorite childhood memor...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5f9f1c36b38e10f823bf2cdf</td>\n      <td>@at_knb Happy birthday to the master builder! ...</td>\n      <td>LEGO_Group</td>\n      <td>2020-10-31 17:16:57.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[happy, birthday, master, builder, hope, magic...</td>\n      <td>happy birthday master builder hope magical day</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5f9f1c36b38e10f823bf2ce2</td>\n      <td>@Ranchie This is the way! ðŸ˜€</td>\n      <td>LEGO_Group</td>\n      <td>2020-10-31 15:16:26.000</td>\n      <td>NaN</td>\n      <td>artist</td>\n      <td>[way]</td>\n      <td>way</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Create full sentence out of the cleaned_text - detokenize\n",
    "twitter_df[\"full_sentence\"] = twitter_df[\"cleaned_text\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Print the new head\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PyTorch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to numerical\n",
    "twitter_df[\"archetype_num\"] = twitter_df[\"archetype\"]\n",
    "\n",
    "# Extract the crucial columns and print dataframe head\n",
    "df = twitter_df[[\"archetype_num\", \"full_sentence\"]]\n",
    "\n",
    "# Replace string labels with numbers, drop NAN\n",
    "df = df.replace({\"archetype_num\": mapping})\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(df[\"archetype_num\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a list of tuples, as iterator\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.text_list = dataframe.to_records(index=False)\n",
    "        self.list_iterator = iter(list(self.text_list))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.text_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "# Tokenize the data\n",
    "dataset_full = TextDataset(df)\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for (label, line) in dataset_full:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define processing pipelines\n",
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collation function and create a DataLoader object\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)    \n",
    "\n",
    "dataset_full = TextDataset(df)\n",
    "data_loader = DataLoader(dataset_full, batch_size=16, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "dataset_full = TextDataset(df)\n",
    "num_class = len(set([label for (label, text) in dataset_full]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| epoch   1 |   500/ 2085 batches | accuracy    0.304\n",
      "| epoch   1 |  1000/ 2085 batches | accuracy    0.462\n",
      "| epoch   1 |  1500/ 2085 batches | accuracy    0.522\n",
      "| epoch   1 |  2000/ 2085 batches | accuracy    0.557\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  4.62s | valid accuracy    0.485 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 2085 batches | accuracy    0.638\n",
      "| epoch   2 |  1000/ 2085 batches | accuracy    0.633\n",
      "| epoch   2 |  1500/ 2085 batches | accuracy    0.640\n",
      "| epoch   2 |  2000/ 2085 batches | accuracy    0.652\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  4.30s | valid accuracy    0.506 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 2085 batches | accuracy    0.710\n",
      "| epoch   3 |  1000/ 2085 batches | accuracy    0.689\n",
      "| epoch   3 |  1500/ 2085 batches | accuracy    0.698\n",
      "| epoch   3 |  2000/ 2085 batches | accuracy    0.692\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  4.35s | valid accuracy    0.623 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 2085 batches | accuracy    0.743\n",
      "| epoch   4 |  1000/ 2085 batches | accuracy    0.733\n",
      "| epoch   4 |  1500/ 2085 batches | accuracy    0.727\n",
      "| epoch   4 |  2000/ 2085 batches | accuracy    0.725\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  4.28s | valid accuracy    0.554 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 2085 batches | accuracy    0.783\n",
      "| epoch   5 |  1000/ 2085 batches | accuracy    0.799\n",
      "| epoch   5 |  1500/ 2085 batches | accuracy    0.807\n",
      "| epoch   5 |  2000/ 2085 batches | accuracy    0.801\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  4.35s | valid accuracy    0.665 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 2085 batches | accuracy    0.816\n",
      "| epoch   6 |  1000/ 2085 batches | accuracy    0.808\n",
      "| epoch   6 |  1500/ 2085 batches | accuracy    0.815\n",
      "| epoch   6 |  2000/ 2085 batches | accuracy    0.814\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  4.39s | valid accuracy    0.667 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 2085 batches | accuracy    0.820\n",
      "| epoch   7 |  1000/ 2085 batches | accuracy    0.820\n",
      "| epoch   7 |  1500/ 2085 batches | accuracy    0.820\n",
      "| epoch   7 |  2000/ 2085 batches | accuracy    0.819\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  4.29s | valid accuracy    0.668 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 2085 batches | accuracy    0.822\n",
      "| epoch   8 |  1000/ 2085 batches | accuracy    0.827\n",
      "| epoch   8 |  1500/ 2085 batches | accuracy    0.822\n",
      "| epoch   8 |  2000/ 2085 batches | accuracy    0.820\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  4.40s | valid accuracy    0.670 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 2085 batches | accuracy    0.837\n",
      "| epoch   9 |  1000/ 2085 batches | accuracy    0.824\n",
      "| epoch   9 |  1500/ 2085 batches | accuracy    0.826\n",
      "| epoch   9 |  2000/ 2085 batches | accuracy    0.823\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  4.36s | valid accuracy    0.673 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 2085 batches | accuracy    0.836\n",
      "| epoch  10 |  1000/ 2085 batches | accuracy    0.833\n",
      "| epoch  10 |  1500/ 2085 batches | accuracy    0.830\n",
      "| epoch  10 |  2000/ 2085 batches | accuracy    0.827\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  4.50s | valid accuracy    0.671 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 32 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "dataset_iter = TextDataset(df)\n",
    "train_dataset = list(dataset_iter)\n",
    "num_train = int(len(train_dataset) * 0.8)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "num_train = int(len(split_train_) * 0.75)\n",
    "\n",
    "split_train_, test_dataset = \\\n",
    "    random_split(split_train_, [num_train, len(split_train_) - num_train])\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.669\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  }
 ]
}