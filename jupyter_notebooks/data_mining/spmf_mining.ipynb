{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPMF - try to get most occurring sequences\n",
    "from spmf import Spmf\n",
    "import pandas as pd\n",
    "from text_cleaner import *\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "archetype_list = ['artist',\n",
    "                 'caregiver',\n",
    "                 'everyman',\n",
    "                 'explorer',\n",
    "                 'guru',\n",
    "                 'hero',\n",
    "                 'innocent',\n",
    "                 'jester',\n",
    "                 'magician',\n",
    "                 'rebel',\n",
    "                 'ruler',\n",
    "                 'seducer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>archetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cdc</td>\n",
       "      <td>@AndruEdwards The hard work has paid off, this...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-11-01 19:32:05.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cdd</td>\n",
       "      <td>@soosupersam A great way to surprise your love...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-11-01 19:09:40.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cde</td>\n",
       "      <td>You can now just bring the fun home, and reliv...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-11-01 14:00:36.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cdf</td>\n",
       "      <td>@at_knb Happy birthday to the master builder! ...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-31 17:16:57.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5f9f1c36b38e10f823bf2ce0</td>\n",
       "      <td>@dizunatsu üòÄüòÄ</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-31 15:18:50.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5f9f1c36b38e10f823bf2cdc   \n",
       "1  5f9f1c36b38e10f823bf2cdd   \n",
       "2  5f9f1c36b38e10f823bf2cde   \n",
       "3  5f9f1c36b38e10f823bf2cdf   \n",
       "4  5f9f1c36b38e10f823bf2ce0   \n",
       "\n",
       "                                          tweet_text    username  \\\n",
       "0  @AndruEdwards The hard work has paid off, this...  LEGO_Group   \n",
       "1  @soosupersam A great way to surprise your love...  LEGO_Group   \n",
       "2  You can now just bring the fun home, and reliv...  LEGO_Group   \n",
       "3  @at_knb Happy birthday to the master builder! ...  LEGO_Group   \n",
       "4                                      @dizunatsu üòÄüòÄ  LEGO_Group   \n",
       "\n",
       "                created_at timestamp archetype  \n",
       "0  2020-11-01 19:32:05.000       NaN    artist  \n",
       "1  2020-11-01 19:09:40.000       NaN    artist  \n",
       "2  2020-11-01 14:00:36.000       NaN    artist  \n",
       "3  2020-10-31 17:16:57.000       NaN    artist  \n",
       "4  2020-10-31 15:18:50.000       NaN    artist  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Twitter dataset\n",
    "twitter_df = pd.read_csv('tweets_06_03_2021.csv', index_col=0)\n",
    "\n",
    "# Print the head of the loaded dataset\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>archetype</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cdc</td>\n",
       "      <td>@AndruEdwards The hard work has paid off, this...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-11-01 19:32:05.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[hard, work, paid, awesome]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cdd</td>\n",
       "      <td>@soosupersam A great way to surprise your love...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-11-01 19:09:40.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[great, way, surprise, loved, one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cde</td>\n",
       "      <td>You can now just bring the fun home, and reliv...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-11-01 14:00:36.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[bring, fun, home, relive, favorite, childhood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f9f1c36b38e10f823bf2cdf</td>\n",
       "      <td>@at_knb Happy birthday to the master builder! ...</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-31 17:16:57.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[happy, birthday, master, builder, hope, magic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5f9f1c36b38e10f823bf2ce2</td>\n",
       "      <td>@Ranchie This is the way! üòÄ</td>\n",
       "      <td>LEGO_Group</td>\n",
       "      <td>2020-10-31 15:16:26.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artist</td>\n",
       "      <td>[way]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5f9f1c36b38e10f823bf2cdc   \n",
       "1  5f9f1c36b38e10f823bf2cdd   \n",
       "2  5f9f1c36b38e10f823bf2cde   \n",
       "3  5f9f1c36b38e10f823bf2cdf   \n",
       "6  5f9f1c36b38e10f823bf2ce2   \n",
       "\n",
       "                                          tweet_text    username  \\\n",
       "0  @AndruEdwards The hard work has paid off, this...  LEGO_Group   \n",
       "1  @soosupersam A great way to surprise your love...  LEGO_Group   \n",
       "2  You can now just bring the fun home, and reliv...  LEGO_Group   \n",
       "3  @at_knb Happy birthday to the master builder! ...  LEGO_Group   \n",
       "6                        @Ranchie This is the way! üòÄ  LEGO_Group   \n",
       "\n",
       "                created_at timestamp archetype  \\\n",
       "0  2020-11-01 19:32:05.000       NaN    artist   \n",
       "1  2020-11-01 19:09:40.000       NaN    artist   \n",
       "2  2020-11-01 14:00:36.000       NaN    artist   \n",
       "3  2020-10-31 17:16:57.000       NaN    artist   \n",
       "6  2020-10-31 15:16:26.000       NaN    artist   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                        [hard, work, paid, awesome]  \n",
       "1                 [great, way, surprise, loved, one]  \n",
       "2  [bring, fun, home, relive, favorite, childhood...  \n",
       "3  [happy, birthday, master, builder, hope, magic...  \n",
       "6                                              [way]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean-up the texts\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"tweet_text\"].apply(lambda x: clean_up_text(x))\n",
    "\n",
    "# Tokenize the cleaned texts\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"cleaned_text\"].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "# Remove the stopwords\n",
    "twitter_df[\"cleaned_text\"] = twitter_df[\"cleaned_text\"].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Drop the rows with empty 'cleaned_text' field\n",
    "twitter_df = twitter_df.drop(twitter_df[twitter_df['cleaned_text'].map(len) < 1].index)\n",
    "\n",
    "# Print the new head of the dataset\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing SPMF on 'artist' archetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          [hard, work, paid, awesome]\n",
       "1                   [great, way, surprise, loved, one]\n",
       "2    [bring, fun, home, relive, favorite, childhood...\n",
       "3    [happy, birthday, master, builder, hope, magic...\n",
       "4                                                [way]\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - try to get the most occurring words in the 'artist' archetype subset\n",
    "# Extract all the tweets for the 'artist' archetype\n",
    "artist_df = twitter_df.cleaned_text[twitter_df[\"archetype\"] == \"artist\"]\n",
    "\n",
    "# Reset the index of the subset\n",
    "artist_df = artist_df.reset_index(drop=True)\n",
    "\n",
    "# Print the head of the subset\n",
    "artist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of sentences\n",
    "artist_list = [\" \".join(row) for row in artist_df.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 524 ms\n",
      " Frequent sequences count : 219786\n",
      " Max memory (mb) : 139.26904296875\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 219786\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                              pattern  sup\n",
      "0                              [hard]  137\n",
      "1                      [hard, placed]    5\n",
      "2                        [hard, work]   18\n",
      "3                 [hard, work, every]    4\n",
      "4              [hard, work, everyone]    4\n",
      "...                               ...  ...\n",
      "219781              [ds, later, year]    4\n",
      "219782                     [ds, year]    4\n",
      "219783                  [swatchxmoma]    6\n",
      "219784  [swatchxmoma, swatchlovesart]    6\n",
      "219785                           [bp]    4\n",
      "\n",
      "[219786 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# SPMF - get the most frequent sequences\n",
    "spmf = Spmf(\"PrefixSpan\", input_direct=artist_list,\n",
    "            output_filename=\"output.txt\", arguments=[0.0003, 3], input_type=\"text\")\n",
    "spmf.run()\n",
    "print(spmf.to_pandas_dataframe(pickle=True))\n",
    "spmf.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating most frequent sequences for all of the archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 461 ms\n",
      " Frequent sequences count : 219786\n",
      " Max memory (mb) : 183.41357421875\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 219786\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              pattern           sup\n",
      "0                              [hard]  1.221796e-02\n",
      "1                      [hard, placed]  6.083746e-06\n",
      "2                        [hard, work]  2.190149e-05\n",
      "3                 [hard, work, every]  2.133147e-07\n",
      "4              [hard, work, everyone]  2.133147e-07\n",
      "...                               ...           ...\n",
      "219781              [ds, later, year]  2.133147e-07\n",
      "219782                     [ds, year]  4.866997e-06\n",
      "219783                  [swatchxmoma]  5.350932e-04\n",
      "219784  [swatchxmoma, swatchlovesart]  7.300496e-06\n",
      "219785                           [bp]  3.567288e-04\n",
      "\n",
      "[219786 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 1/12 [00:12<02:20, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 654 ms\n",
      " Frequent sequences count : 920767\n",
      " Max memory (mb) : 214.2587890625\n",
      " minsup = 2 sequences.\n",
      " Pattern count : 920767\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               pattern           sup\n",
      "0                              [sorry]  1.504348e-01\n",
      "1                        [sorry, hear]  2.143125e-03\n",
      "2                  [sorry, hear, hear]  2.496816e-07\n",
      "3                   [sorry, hear, amy]  3.329088e-07\n",
      "4                [sorry, hear, moment]  9.987263e-07\n",
      "...                                ...           ...\n",
      "920762   [academics, diluting, rights]  1.664544e-07\n",
      "920763                        [accord]  2.484472e-04\n",
      "920764        [accord, humanrightsact]  3.789788e-06\n",
      "920765  [accord, humanrightsact, read]  1.664544e-07\n",
      "920766                  [accord, read]  3.789788e-06\n",
      "\n",
      "[920767 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 2/12 [00:37<03:18, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 309 ms\n",
      " Frequent sequences count : 147306\n",
      " Max memory (mb) : 106.28164672851562\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 147306\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 pattern           sup\n",
      "0                                  [bud]  1.337979e-02\n",
      "1                             [bud, bud]  1.399012e-05\n",
      "2                            [bud, wait]  9.326749e-06\n",
      "3                           [bud, happy]  6.995061e-06\n",
      "4                              [bud, us]  9.326749e-06\n",
      "...                                  ...           ...\n",
      "147301       [praised, emissions, point]  3.123981e-07\n",
      "147302       [praised, emissions, price]  3.123981e-07\n",
      "147303  [praised, emissions, accessible]  3.123981e-07\n",
      "147304               [praised, electric]  6.995061e-06\n",
      "147305                         [talents]  4.181185e-04\n",
      "\n",
      "[147306 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 3/12 [00:46<02:15, 15.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 405 ms\n",
      " Frequent sequences count : 90588\n",
      " Max memory (mb) : 140.56525421142578\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 90588\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        pattern           sup\n",
      "0                      [maggie]  3.452562e-04\n",
      "1           [maggie, continues]  3.640242e-06\n",
      "2      [maggie, continues, sun]  1.726970e-07\n",
      "3        [maggie, continues, c]  1.726970e-07\n",
      "4       [maggie, maggiecolepbs]  4.550303e-06\n",
      "...                         ...           ...\n",
      "90583                 [finance]  2.762049e-04\n",
      "90584               [codedgaze]  2.762049e-04\n",
      "90585      [womenshistorymonth]  4.143074e-04\n",
      "90586        [worldwildlifeday]  3.452562e-04\n",
      "90587                     [wwd]  6.214611e-04\n",
      "\n",
      "[90588 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:59<01:53, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 432 ms\n",
      " Frequent sequences count : 64913\n",
      " Max memory (mb) : 212.9957275390625\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 64913\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [01:17<01:49, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          pattern           sup\n",
      "0                          [crew]  5.885150e-03\n",
      "1                    [crew, crew]  1.296159e-05\n",
      "2           [crew, crew, mission]  1.871370e-07\n",
      "3                 [crew, crew, p]  2.994193e-07\n",
      "4                [crew, crew, et]  2.245644e-07\n",
      "...                           ...           ...\n",
      "64908     [garde, explore, klein]  1.497096e-07\n",
      "64909                  [sorrenti]  2.377839e-04\n",
      "64910            [sorrenti, shop]  3.049787e-06\n",
      "64911  [sorrenti, shop, campaign]  1.497096e-07\n",
      "64912        [sorrenti, campaign]  3.049787e-06\n",
      "\n",
      "[64913 rows x 2 columns]\n",
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 494 ms\n",
      " Frequent sequences count : 837069\n",
      " Max memory (mb) : 161.158203125\n",
      " minsup = 2 sequences.\n",
      " Pattern count : 837069\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             pattern           sup\n",
      "0                               [hi]  3.294492e-02\n",
      "1                        [hi, sorry]  1.098232e-04\n",
      "2                  [hi, sorry, tell]  1.413449e-07\n",
      "3                  [hi, sorry, feel]  1.413449e-07\n",
      "4                   [hi, sorry, way]  2.826899e-07\n",
      "...                              ...           ...\n",
      "837064              [peacecorpsweek]  2.118644e-04\n",
      "837065         [peacecorpsweek, amp]  3.230094e-06\n",
      "837066    [peacecorpsweek, amp, amp]  1.413449e-07\n",
      "837067  [peacecorpsweek, amp, learn]  1.413449e-07\n",
      "837068       [peacecorpsweek, learn]  3.230094e-06\n",
      "\n",
      "[837069 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [01:43<01:54, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 396 ms\n",
      " Frequent sequences count : 146492\n",
      " Max memory (mb) : 210.5414810180664\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 146492\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 pattern           sup\n",
      "0                           [appreciate]  2.982474e-02\n",
      "1                  [appreciate, loyalty]  2.192555e-04\n",
      "2           [appreciate, loyalty, order]  2.583632e-06\n",
      "3            [appreciate, loyalty, meet]  6.419935e-06\n",
      "4       [appreciate, loyalty, extremely]  6.263351e-06\n",
      "...                                  ...           ...\n",
      "146487            [salary, hint, people]  2.348757e-07\n",
      "146488            [salary, hint, reckon]  2.348757e-07\n",
      "146489           [salary, hint, similar]  2.348757e-07\n",
      "146490             [salary, hint, share]  2.348757e-07\n",
      "146491            [salary, hint, though]  2.348757e-07\n",
      "\n",
      "[146492 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7/12 [01:55<01:22, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 312 ms\n",
      " Frequent sequences count : 111339\n",
      " Max memory (mb) : 126.9611587524414\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 111339\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                pattern           sup\n",
      "0                               [thank]  7.427204e-02\n",
      "1                        [thank, thank]  9.997317e-06\n",
      "2                      [thank, support]  7.164744e-05\n",
      "3              [thank, support, global]  3.547882e-07\n",
      "4                        [thank, store]  1.666220e-05\n",
      "...                                 ...           ...\n",
      "111334  [nationalpeanutbutterloversday]  3.191065e-04\n",
      "111335                   [fallonvision]  3.191065e-04\n",
      "111336                          [stout]  3.191065e-04\n",
      "111337                   [stout, march]  6.664878e-06\n",
      "111338            [foodwasteactionweek]  3.988831e-04\n",
      "\n",
      "[111339 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [02:06<01:00, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 484 ms\n",
      " Frequent sequences count : 183911\n",
      " Max memory (mb) : 178.09271240234375\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 183911\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pattern           sup\n",
      "0                   [sorry]  9.451978e-02\n",
      "1            [sorry, helps]  4.831379e-06\n",
      "2            [sorry, sorry]  9.662758e-06\n",
      "3             [sorry, hear]  6.099616e-04\n",
      "4       [sorry, hear, hear]  1.942611e-07\n",
      "...                     ...           ...\n",
      "183906           [worklife]  6.419000e-04\n",
      "183907              [audio]  7.221375e-04\n",
      "183908       [audio, start]  4.831379e-06\n",
      "183909  [audio, collective]  6.039224e-06\n",
      "183910            [tedpods]  8.023750e-04\n",
      "\n",
      "[183911 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [02:21<00:45, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 415 ms\n",
      " Frequent sequences count : 571047\n",
      " Max memory (mb) : 225.21741485595703\n",
      " minsup = 2 sequences.\n",
      " Pattern count : 571047\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     pattern           sup\n",
      "0                    [fiery]  2.349348e-04\n",
      "1              [fiery, warm]  3.989890e-06\n",
      "2       [fiery, warm, tones]  1.979696e-07\n",
      "3       [fiery, warm, drawn]  1.979696e-07\n",
      "4       [fiery, warm, every]  1.979696e-07\n",
      "...                      ...           ...\n",
      "571042                  [ge]  2.349348e-04\n",
      "571043            [ge, heme]  3.989890e-06\n",
      "571044           [ge, yeast]  3.989890e-06\n",
      "571045         [ge, produce]  3.989890e-06\n",
      "571046   [ge, produce, heme]  1.979696e-07\n",
      "\n",
      "[571047 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [02:40<00:32, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 414 ms\n",
      " Frequent sequences count : 316796\n",
      " Max memory (mb) : 178.33123779296875\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 316796\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 pattern           sup\n",
      "0                                 [join]  1.136163e-02\n",
      "1                        [join, tonight]  4.896626e-06\n",
      "2                    [join, tonight, pm]  2.292151e-07\n",
      "3                             [join, pm]  1.591403e-05\n",
      "4                         [join, pm, et]  1.719113e-07\n",
      "...                                  ...           ...\n",
      "316791             [virtuallearning, us]  3.672470e-06\n",
      "316792         [virtuallearning, around]  3.672470e-06\n",
      "316793  [virtuallearning, around, world]  1.719113e-07\n",
      "316794   [virtuallearning, around, told]  1.719113e-07\n",
      "316795     [virtuallearning, around, us]  1.719113e-07\n",
      "\n",
      "[316796 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [02:55<00:15, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/mnt/HDD_Linux/Praca_magisterska/jupyter_notebooks/data_mining/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 384 ms\n",
      " Frequent sequences count : 540601\n",
      " Max memory (mb) : 114.53091430664062\n",
      " minsup = 2 sequences.\n",
      " Pattern count : 540601\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-336d2b54d506>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                pattern           sup\n",
      "0                             [holiday]  1.682073e-02\n",
      "1                    [holiday, holiday]  2.112038e-05\n",
      "2             [holiday, holiday, boxes]  2.199042e-07\n",
      "3               [holiday, holiday, box]  2.199042e-07\n",
      "4            [holiday, holiday, spirit]  2.199042e-07\n",
      "...                                 ...           ...\n",
      "540596         [galgadot, tiffanyandco]  5.280096e-06\n",
      "540597                [tiffanybluebook]  3.030762e-04\n",
      "540598  [tiffanybluebook, tiffanyandco]  5.280096e-06\n",
      "540599                   [goldenglobes]  6.061524e-04\n",
      "540600     [goldenglobes, tiffanyandco]  7.920144e-06\n",
      "\n",
      "[540601 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [03:14<00:00, 16.17s/it]\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.DataFrame(columns=['chunk'] + archetype_list)\n",
    "\n",
    "# Iterate over archetypes\n",
    "for archetype in tqdm(archetype_list):\n",
    "    # Extract all the tweets for the 'artist' archetype\n",
    "    tmp_df = twitter_df.cleaned_text[twitter_df[\"archetype\"] == archetype]\n",
    "\n",
    "    # Reset the index of the subset\n",
    "    tmp_df = tmp_df.reset_index(drop=True)\n",
    "    \n",
    "    # Calculate number of words, number of two-word and three-word combinations\n",
    "    unique_words = set()\n",
    "    unique_two_words = set()\n",
    "    unique_three_words = set()\n",
    "    \n",
    "    for row in tmp_df.tolist():\n",
    "        unique_words.update(row)\n",
    "        unique_two_words.update(itertools.permutations(row, 2))\n",
    "        unique_three_words.update(itertools.permutations(row, 3))\n",
    "    \n",
    "    cnt_single_word = len(unique_words)\n",
    "    cnt_two_words = len(unique_two_words)\n",
    "    cnt_three_words = len(unique_three_words)\n",
    "    \n",
    "    # Create a list of sentences\n",
    "    tmp_list = [\" \".join(row) for row in tmp_df.tolist()]\n",
    "    \n",
    "    # SPMF - get the most frequent sequences\n",
    "    spmf = Spmf(\"PrefixSpan\", input_direct=tmp_list,\n",
    "                output_filename=f\"sequence_files_four/output_{archetype}.txt\", arguments=[0.0003, 3], input_type=\"text\")\n",
    "    spmf.run()\n",
    "    \n",
    "    spmf = spmf.to_pandas_dataframe(pickle=True)\n",
    "    \n",
    "    # Get the TF\n",
    "    spmf.sup[spmf.pattern.map(len) == 1] = spmf.sup[spmf.pattern.map(len) == 1].apply(lambda x: float(x / cnt_single_word))\n",
    "    spmf.sup[spmf.pattern.map(len) == 2] = spmf.sup[spmf.pattern.map(len) == 2].apply(lambda x: float(x / cnt_two_words)) \n",
    "    spmf.sup[spmf.pattern.map(len) == 3] = spmf.sup[spmf.pattern.map(len) == 3].apply(lambda x: float(x / cnt_three_words)) \n",
    "    \n",
    "    print(spmf)\n",
    "    spmf.to_csv(f\"sequence_files/output_{archetype}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:14<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Merge all files into a single dataframe\n",
    "total_df = pd.DataFrame(columns=[\"pattern\"] + archetype_list)\n",
    "for archetype in tqdm(archetype_list):    \n",
    "    # Read file and merge it with the other ones\n",
    "    total_df = pd.concat([total_df, pd.read_csv(f\"sequence_files/output_{archetype}.csv\", sep=\",\", index_col=0).rename(columns={\"sup\": archetype})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>artist</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>everyman</th>\n",
       "      <th>explorer</th>\n",
       "      <th>guru</th>\n",
       "      <th>hero</th>\n",
       "      <th>innocent</th>\n",
       "      <th>jester</th>\n",
       "      <th>magician</th>\n",
       "      <th>rebel</th>\n",
       "      <th>ruler</th>\n",
       "      <th>seducer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['hard']</td>\n",
       "      <td>1.221796e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['hard', 'placed']</td>\n",
       "      <td>6.083746e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['hard', 'work']</td>\n",
       "      <td>2.190149e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['hard', 'work', 'every']</td>\n",
       "      <td>2.133147e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['hard', 'work', 'everyone']</td>\n",
       "      <td>2.133147e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150610</th>\n",
       "      <td>['galgadot', 'tiffanyandco']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2801e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150611</th>\n",
       "      <td>['tiffanybluebook']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000303076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150612</th>\n",
       "      <td>['tiffanybluebook', 'tiffanyandco']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2801e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150613</th>\n",
       "      <td>['goldenglobes']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000606152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150614</th>\n",
       "      <td>['goldenglobes', 'tiffanyandco']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.92014e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4150615 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     pattern        artist caregiver everyman  \\\n",
       "0                                   ['hard']  1.221796e-02       NaN      NaN   \n",
       "1                         ['hard', 'placed']  6.083746e-06       NaN      NaN   \n",
       "2                           ['hard', 'work']  2.190149e-05       NaN      NaN   \n",
       "3                  ['hard', 'work', 'every']  2.133147e-07       NaN      NaN   \n",
       "4               ['hard', 'work', 'everyone']  2.133147e-07       NaN      NaN   \n",
       "...                                      ...           ...       ...      ...   \n",
       "4150610         ['galgadot', 'tiffanyandco']           NaN       NaN      NaN   \n",
       "4150611                  ['tiffanybluebook']           NaN       NaN      NaN   \n",
       "4150612  ['tiffanybluebook', 'tiffanyandco']           NaN       NaN      NaN   \n",
       "4150613                     ['goldenglobes']           NaN       NaN      NaN   \n",
       "4150614     ['goldenglobes', 'tiffanyandco']           NaN       NaN      NaN   \n",
       "\n",
       "        explorer guru hero innocent jester magician rebel ruler      seducer  \n",
       "0            NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "1            NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "2            NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "3            NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "4            NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN          NaN  \n",
       "...          ...  ...  ...      ...    ...      ...   ...   ...          ...  \n",
       "4150610      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN   5.2801e-06  \n",
       "4150611      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  0.000303076  \n",
       "4150612      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN   5.2801e-06  \n",
       "4150613      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  0.000606152  \n",
       "4150614      NaN  NaN  NaN      NaN    NaN      NaN   NaN   NaN  7.92014e-06  \n",
       "\n",
       "[4150615 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataframe\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-14d8e4dfd6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"seducer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtotal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregate_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtotal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_agg_1dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_agg\u001b[0;34m(arg, func)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_how\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_how\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_agg_1dim\u001b[0;34m(name, how, subset)\u001b[0m\n\u001b[1;32m    368\u001b[0m                         \u001b[0;34m\"nested dictionary is ambiguous in aggregation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                     )\n\u001b[0;32m--> 370\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcolg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_agg_2dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 \u001b[0;31m# apply a non-cython aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;31m# TODO: KeyError is raised in _python_agg_general,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                 \u001b[0;31m# if this function is invalid for this dtype, we will ignore it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_series_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Function does not reduce\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_aggregate_series_fast\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mgroup_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mgrouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeriesGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.SeriesGrouper.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction._BaseGrouper._apply_to_group\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_builtin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;31m# iterate through \"columns\" ex exclusions to populate output dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m                 \u001b[0;31m# apply a non-cython aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2248\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11161\u001b[0m     ):\n\u001b[1;32m  11162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11163\u001b[0;31m             \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11164\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"prod\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11165\u001b[0m             \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/compat/numpy/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, args, kwargs, fname, max_fname_arg_count, method)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"both\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 validate_args_and_kwargs(\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fname_arg_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/util/_validators.py\u001b[0m in \u001b[0;36mvalidate_args_and_kwargs\u001b[0;34m(fname, args, kwargs, max_fname_arg_count, compat_args)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# Check there is no overlap with the positional and keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# arguments, similar to what is done in actual Python functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0margs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aggregate_func = {\n",
    "    \"pattern\": \"first\",\n",
    "    \"artist\": \"sum\",\n",
    "    \"caregiver\": \"sum\",\n",
    "    \"everyman\": \"sum\",\n",
    "    \"explorer\": \"sum\",\n",
    "    \"guru\": \"sum\",\n",
    "    \"hero\": \"sum\",\n",
    "    \"innocent\": \"sum\",\n",
    "    \"jester\": \"sum\",\n",
    "    \"magician\": \"sum\",\n",
    "    \"rebel\": \"sum\",\n",
    "    \"ruler\": \"sum\",\n",
    "    \"seducer\": \"sum\"\n",
    "}\n",
    "total_df = total_df.groupby(\"pattern\").aggregate(aggregate_func)\n",
    "total_df = total_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the full DataFrame\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current DataFrame\n",
    "total_df.to_csv(\"sequence_files_four/phrase_frequency_no_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetype artist:\n",
      "[########################################] | 100% Completed | 15min 32.3s\n",
      "Archetype caregiver:\n",
      "[###########                             ] | 28% Completed | 11min 44.1s"
     ]
    }
   ],
   "source": [
    "# Calculate document frequency for every archetype\n",
    "import math\n",
    "import ast\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "def get_doc_freq(phrase, sup, dataset):\n",
    "    phrase_cnt = 0\n",
    "    for line in dataset:\n",
    "        if tuple(phrase) in line:\n",
    "            phrase_cnt += 1\n",
    "    return sup * math.log(len(dataset) / (phrase_cnt + 1))\n",
    "    \n",
    "\n",
    "for archetype in archetype_list:\n",
    "    print(f\"Archetype {archetype}:\")\n",
    "    tmp_df = pd.read_csv(f\"sequence_files/output_{archetype}.csv\").set_index(\"Unnamed: 0\")\n",
    "    tmp_df[\"pattern\"] = tmp_df[\"pattern\"].apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    tmp_df = dd.from_pandas(tmp_df, 10000)\n",
    "    \n",
    "    twitter_subset = twitter_df.cleaned_text[twitter_df[\"archetype\"] == archetype]\n",
    "    \n",
    "    # Select non-zero elements and calculate DF for every element\n",
    "    with ProgressBar():\n",
    "        tmp_df[\"sup\"] = tmp_df.apply(lambda row: get_doc_freq(row[\"pattern\"], row[\"sup\"], twitter_subset), axis=1, meta=(float)).compute()\n",
    "\n",
    "    tmp_df.to_csv(f\"sequence_files_four/output_{archetype}_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with document frequency calculated\n",
    "total_df.to_csv(\"sequence_files/phrase_frequency_with_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the new DataFrame\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
