{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classifier - neural network edition\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79279 files belonging to 2 classes.\n",
      "Using 63424 files for training.\n",
      "Found 79279 files belonging to 2 classes.\n",
      "Using 15855 files for validation.\n",
      "Number of batches in raw_train_ds: 991\n",
      "Number of batches in raw_val_ds: 248\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"datasets/artist\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"datasets/artist\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Number of batches in raw_train_ds: %d\"\n",
    "    % tf.data.experimental.cardinality(raw_train_ds)\n",
    ")\n",
    "print(\n",
    "    \"Number of batches in raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 15855\n",
      "    Positive: 1805 (11.38% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract labels from tf.data.Dataset\n",
    "y_val = np.concatenate([y for _, y in val_vec], axis=0)\n",
    "\n",
    "neg, pos = np.bincount(y_val)\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0520618]\n"
     ]
    }
   ],
   "source": [
    "# Set up initial bias\n",
    "initial_bias=np.log([pos/neg])\n",
    "print(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constants\n",
    "max_features = 500000\n",
    "embedding_dim = 128\n",
    "sequence_length = 50\n",
    "\n",
    "# Vectorization layer\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Function to vectorize text\n",
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def create_model(metrics=METRICS, output_bias=None):\n",
    "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "    # Add an Embedding layer\n",
    "    x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Add Conv1D + global max pooling\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # Hidden layer\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Prediction layer\n",
    "    predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\", bias_initializer=output_bias)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=METRICS)\n",
    "    \n",
    "    # Show model summary\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize datasets\n",
    "train_vec = raw_train_ds.map(vectorize_text)\n",
    "val_vec = raw_val_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, None, 128)         64000000  \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 128)         114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 64,246,273\n",
      "Trainable params: 64,246,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "991/991 [==============================] - 503s 506ms/step - loss: 0.3559 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 28152.8861 - fn: 3623.0494 - accuracy: 0.8855 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5153 - val_loss: 0.3515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14050.0000 - val_fn: 1805.0000 - val_accuracy: 0.8862 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5686\n",
      "Epoch 2/3\n",
      "991/991 [==============================] - 496s 500ms/step - loss: 0.3539 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 28152.7298 - fn: 3623.2056 - accuracy: 0.8855 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5500 - val_loss: 0.3515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14050.0000 - val_fn: 1805.0000 - val_accuracy: 0.8862 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5691\n",
      "Epoch 3/3\n",
      "991/991 [==============================] - 483s 488ms/step - loss: 0.3542 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 28152.5756 - fn: 3623.3599 - accuracy: 0.8852 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5559 - val_loss: 0.3512 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 14050.0000 - val_fn: 1805.0000 - val_accuracy: 0.8862 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd94c498ee0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 3\n",
    "\n",
    "# Call create_model\n",
    "model = create_model(output_bias=keras.initializers.Constant(initial_bias[0]))\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(train_vec, validation_data=val_vec, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09630746]\n"
     ]
    }
   ],
   "source": [
    "# Print max_value of predictions\n",
    "print(min(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampled model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
