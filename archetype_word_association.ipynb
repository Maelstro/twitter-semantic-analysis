{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to check out the acquired text\n",
    "# and try to associate the texts with \n",
    "# the brand archetypes\n",
    "\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used in the notebook\n",
    "def mongo_connect(server_name: str) -> MongoClient:\n",
    "    \"\"\"Creates connection to the MongoDB database with given server name.\"\"\"\n",
    "    client = MongoClient(server_name)\n",
    "    db = client.twitter_db\n",
    "    return db\n",
    "\n",
    "word_lemm = WordNetLemmatizer()\n",
    "\n",
    "# Tweet preprocessing\n",
    "def preprocess_texts(text_list: pd.DataFrame):\n",
    "    \"\"\"Processes text to remove all unwanted words and symbols.\"\"\"\n",
    "\n",
    "    # Lowercase the tweets\n",
    "    text_list['processed_tweet'] = text_list['tweet_text'].str.lower()\n",
    "\n",
    "    # Regex patterns\n",
    "    url_pattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    user_pattern       = '@[^\\s]+'\n",
    "    alpha_pattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequence_pattern   = r\"(.)\\1\\1+\"\n",
    "    seq_replace_pattern = r\"\\1\\1\"\n",
    "\n",
    "    # Remove URLs from the tweet text\n",
    "    text_list['processed_tweet'] = [re.sub(url_pattern, ' ', str(x))\n",
    "                                    for x in text_list['processed_tweet']]\n",
    "    # Remove username from the tweet text\n",
    "    text_list['processed_tweet'] = [re.sub(user_pattern, ' ', str(x))\n",
    "                                    for x in text_list['processed_tweet']]\n",
    "    # Remove all non-alphanumeric symbols\n",
    "    text_list['processed_tweet'] = [re.sub(alpha_pattern, ' ', str(x))\n",
    "                                    for x in text_list['processed_tweet']]\n",
    "    # Replace all 3 or more consecutive letters with 2 letters\n",
    "    text_list['processed_tweet'] = [re.sub(sequence_pattern, seq_replace_pattern, str(x))\n",
    "                                    for x in text_list['processed_tweet']]\n",
    "\n",
    "    full_tweet = ''\n",
    "    full_tweet_list = []\n",
    "    for x in text_list['processed_tweet']:\n",
    "        for word in x.split():\n",
    "            if word not in stopwords.words('english'):\n",
    "                if len(word) > 1:\n",
    "                    word = word_lemm.lemmatize(word)\n",
    "                    full_tweet += (word + ' ')\n",
    "        full_tweet_list.append(full_tweet)\n",
    "\n",
    "    text_list['processed_tweet'] = full_tweet_list\n",
    "\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to local database\n",
    "db = mongo_connect('localhost')\n",
    "\n",
    "# Cursor for acquiring all posts\n",
    "cursor = db.twitter_posts.find()\n",
    "\n",
    "df = pd.DataFrame(list(cursor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5f8972f59848a997cb675eb9</td>\n",
       "      <td>They worked with youth climate activists in th...</td>\n",
       "      <td>Virgin</td>\n",
       "      <td>2020-10-16 09:57:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f8972f59848a997cb675eba</td>\n",
       "      <td>.@EnvisionVirgin signing the framework further...</td>\n",
       "      <td>Virgin</td>\n",
       "      <td>2020-10-16 09:57:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5f8972f59848a997cb675ebb</td>\n",
       "      <td>The framework calls on sporting organisations ...</td>\n",
       "      <td>Virgin</td>\n",
       "      <td>2020-10-16 09:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f8972f59848a997cb675ebc</td>\n",
       "      <td>.@HollyBranson and CEO of @BransonCentreCA Lau...</td>\n",
       "      <td>Virgin</td>\n",
       "      <td>2020-10-15 18:30:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5f8972f59848a997cb675ebd</td>\n",
       "      <td>“50 years eh? Who’d have thought........Actual...</td>\n",
       "      <td>Virgin</td>\n",
       "      <td>2020-10-15 16:42:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5f8972f59848a997cb675eb9   \n",
       "1  5f8972f59848a997cb675eba   \n",
       "2  5f8972f59848a997cb675ebb   \n",
       "3  5f8972f59848a997cb675ebc   \n",
       "4  5f8972f59848a997cb675ebd   \n",
       "\n",
       "                                          tweet_text username  \\\n",
       "0  They worked with youth climate activists in th...   Virgin   \n",
       "1  .@EnvisionVirgin signing the framework further...   Virgin   \n",
       "2  The framework calls on sporting organisations ...   Virgin   \n",
       "3  .@HollyBranson and CEO of @BransonCentreCA Lau...   Virgin   \n",
       "4  “50 years eh? Who’d have thought........Actual...   Virgin   \n",
       "\n",
       "           created_at  \n",
       "0 2020-10-16 09:57:21  \n",
       "1 2020-10-16 09:57:21  \n",
       "2 2020-10-16 09:57:19  \n",
       "3 2020-10-15 18:30:29  \n",
       "4 2020-10-15 16:42:17  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fitting ended in 10 seconds\n",
      "Number of feature_words: 16197\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "df_processed = preprocess_texts(df)\n",
    "\n",
    "# TF-IDF Vectorization - CountVectorize (Bag of Words), and then apply IF-IDF Transformer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=800000)\n",
    "start = time.time()\n",
    "vectorizer.fit(df_processed['processed_tweet'])\n",
    "print(f'Vectorizer fitting ended in {round(time.time()-start)} seconds')\n",
    "print(f'Number of feature_words: {len(vectorizer.get_feature_names())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " dm\n",
      " please\n",
      " hi\n",
      " thanks\n",
      " done without\n",
      " davidson apolitical\n",
      " image projected\n",
      " consent harley\n",
      " without consent\n",
      " harley\n",
      " harley davidson\n",
      " apolitical\n",
      " projected\n",
      " projected museum\n",
      " davidson\n",
      " museum done\n",
      " consent\n",
      " help\n",
      " address\n",
      " number\n",
      "Cluster 1:\n",
      " team\n",
      " help\n",
      " chanel\n",
      " thanks\n",
      " please\n",
      " hi\n",
      " dm\n",
      " new\n",
      " look\n",
      " time\n",
      " hear\n",
      " year\n",
      " like\n",
      " one\n",
      " amp\n",
      " sorry\n",
      " experience\n",
      " see\n",
      " latest\n",
      " collection\n",
      "Cluster 2:\n",
      " hi\n",
      " done without\n",
      " without consent\n",
      " image projected\n",
      " consent\n",
      " apolitical\n",
      " davidson\n",
      " projected\n",
      " projected museum\n",
      " harley davidson\n",
      " consent harley\n",
      " harley\n",
      " davidson apolitical\n",
      " museum done\n",
      " image\n",
      " without\n",
      " museum\n",
      " done\n",
      " apolitical image\n",
      " thanks\n",
      "Cluster 3:\n",
      " team\n",
      " year\n",
      " disneyplus\n",
      " please\n",
      " number\n",
      " first\n",
      " dm\n",
      " dyson\n",
      " change\n",
      " hi\n",
      " streaming\n",
      " new\n",
      " look\n",
      " real\n",
      " know\n",
      " great\n",
      " thanks\n",
      " hey\n",
      " 20\n",
      " one\n",
      "Cluster 4:\n",
      " chanel\n",
      " team\n",
      " dm\n",
      " please\n",
      " experience\n",
      " help\n",
      " year\n",
      " sorry\n",
      " learn\n",
      " new\n",
      " thanks\n",
      " look\n",
      " hear\n",
      " number\n",
      " gabrielle\n",
      " gabrielle chanel\n",
      " great\n",
      " latest\n",
      " time\n",
      " life\n",
      "Cluster 5:\n",
      " please\n",
      " dm\n",
      " hi\n",
      " thanks\n",
      " help\n",
      " sorry\n",
      " team\n",
      " hear\n",
      " address\n",
      " look\n",
      " number\n",
      " like\n",
      " new\n",
      " email\n",
      " done without\n",
      " consent\n",
      " projected\n",
      " projected museum\n",
      " consent harley\n",
      " without consent\n",
      "Cluster 6:\n",
      " team\n",
      " climate\n",
      " change\n",
      " event\n",
      " year\n",
      " greenest\n",
      " framework\n",
      " climate change\n",
      " signing\n",
      " programme\n",
      " video event\n",
      " worked youth\n",
      " worked\n",
      " watch video\n",
      " raceagainstclimatechange\n",
      " live\n",
      " raceagainstclimatechange live\n",
      " youth climate\n",
      " watch\n",
      " youth\n",
      "Cluster 7:\n",
      " hi\n",
      " dm\n",
      " please\n",
      " thanks\n",
      " done without\n",
      " davidson\n",
      " without consent\n",
      " projected museum\n",
      " consent\n",
      " projected\n",
      " davidson apolitical\n",
      " image projected\n",
      " apolitical\n",
      " museum done\n",
      " harley\n",
      " harley davidson\n",
      " consent harley\n",
      " image\n",
      " without\n",
      " museum\n",
      "Cluster 8:\n",
      " done without\n",
      " without consent\n",
      " davidson\n",
      " harley davidson\n",
      " harley\n",
      " apolitical\n",
      " image projected\n",
      " museum done\n",
      " davidson apolitical\n",
      " projected\n",
      " projected museum\n",
      " consent\n",
      " consent harley\n",
      " image\n",
      " without\n",
      " museum\n",
      " done\n",
      " hi\n",
      " apolitical image\n",
      " team\n",
      "Cluster 9:\n",
      " dm\n",
      " please\n",
      " hi\n",
      " thanks\n",
      " help\n",
      " address\n",
      " sorry\n",
      " number\n",
      " done without\n",
      " museum done\n",
      " davidson\n",
      " harley davidson\n",
      " harley\n",
      " projected\n",
      " apolitical\n",
      " projected museum\n",
      " davidson apolitical\n",
      " without consent\n",
      " image projected\n",
      " consent harley\n",
      "Cluster 10:\n",
      " chanel\n",
      " team\n",
      " dm\n",
      " please\n",
      " thanks\n",
      " new\n",
      " look\n",
      " latest\n",
      " like\n",
      " time\n",
      " experience\n",
      " help\n",
      " collection\n",
      " hear\n",
      " learn\n",
      " year\n",
      " sorry\n",
      " ikea\n",
      " hi\n",
      " life\n",
      "Cluster 11:\n",
      " team\n",
      " number\n",
      " year\n",
      " please\n",
      " one\n",
      " 800\n",
      " customer\n",
      " call\n",
      " change\n",
      " climate\n",
      " watch\n",
      " hear\n",
      " help\n",
      " longwayup\n",
      " hey\n",
      " hi\n",
      " hello\n",
      " check\n",
      " see\n",
      " happy\n"
     ]
    }
   ],
   "source": [
    "NUM_CLUSTERS = 12\n",
    "\n",
    "transformed_tweets = vectorizer.transform(df_processed['processed_tweet'])\n",
    "\n",
    "kmpp_model = KMeans(n_clusters=NUM_CLUSTERS, init='k-means++', n_init=1, max_iter=1000, tol=1e-5,\n",
    "                    random_state=2200)\n",
    "kmpp_model.fit(transformed_tweets)\n",
    "\n",
    "def show_training_results(model, n_clusters):\n",
    "    order_centroids = model.cluster_centers_.argsort()[:,::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        term_list = terms[]\n",
    "        print(\"Cluster %d:\" % i)\n",
    "        for ind in order_centroids[i, :20]:\n",
    "            print(' %s' % terms[ind])\n",
    "\n",
    "show_training_results(kmpp_model, NUM_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (frapol)",
   "language": "python",
   "name": "frapol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
