{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec90f85-4653-428a-9a77-1eeddd32d7a3",
   "metadata": {},
   "source": [
    "## Keras layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40dfba25-a44b-4b75-b2d6-2bc53b28b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Class representing AGDS\n",
    "class SparseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super(SparseLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[1], self.output_dim), \n",
    "            initializer='random_normal',\n",
    "            trainable=True)\n",
    "        super(SparseLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_data):\n",
    "        multi_kernel = K.expand_dims(self.kernel, 0)\n",
    "        coeffs = tf.keras.layers.Dot(axes=(1, 1))([input_data, multi_kernel])\n",
    "        return tf.keras.activations.softmax(coeffs)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"output_dimension\": self.output_dim}\n",
    "\n",
    "\n",
    "# Class for AGDS Word2BoW processing\n",
    "class AGDSVectorization(tf.keras.layers.Layer):\n",
    "    def __init__(self, word_map, **kwargs):\n",
    "        self.word_map = word_map\n",
    "        super(AGDSVectorization, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_data):\n",
    "        post_vector = [0] * len(self.word_map)\n",
    "\n",
    "        # Calculate word occurrences\n",
    "        word_ctr = Counter(input_data)\n",
    "\n",
    "        for word, freq in word_ctr.items():\n",
    "            if word in self.word_map:\n",
    "                post_vector[self.word_map.index(word)] = freq\n",
    "        return post_vector\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], len(self.word_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2741c76-b4cd-4740-8064-bdc384828d1c",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e04e53c-c51e-497c-93c5-b765d111ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate words with archetypes/character traits as intermediate layer\n",
    "# and with influencer as the \"last\" layer\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import copy\n",
    "import os\n",
    "import toml\n",
    "import re\n",
    "import itertools\n",
    "from text_cleaner import *\n",
    "import operator\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def extract_hashtags(post_text):\n",
    "    HASH_RE = re.compile(r\"\\#\\w+\")\n",
    "    out_list = re.findall(HASH_RE, post_text)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33cdc0ed-2acc-4e9a-bcd6-d9bc541a068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['innocent', 'sage', 'explorer', 'outlaw', 'magician', 'hero', 'lover', 'jester', 'everyman', 'caregiver', 'ruler', 'creator', 'dominant', 'submissive', 'maximalist', 'minimalist', 'inspiring', 'systematic', 'discovering', 'conservative', 'verifying', 'overlooking', 'sharpening', 'harmonic', 'empathic', 'matter_of_fact', 'brave', 'protective', 'generous', 'thrifty', 'favourable', 'balanced', 'sensuality', 'intelligent', 'believe', 'egocentric', 'allocentric']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marek_grodzki</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vege_style_life</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliwka__2007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_przestrzeni_serca</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaradne_warsztaty</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "id                                                                             \n",
       "marek_grodzki             0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "vege_style_life           0.0   0.0       4.0     0.0       0.0   0.0    0.0   \n",
       "oliwka__2007              0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "z_przestrzeni_serca       4.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "zaradne_warsztaty         3.0   0.0       0.0     0.0       3.0   0.0    0.0   \n",
       "\n",
       "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
       "id                                                ...                         \n",
       "marek_grodzki           4.0       0.0        0.0  ...         2.0       3.0   \n",
       "vege_style_life         0.0       0.0        0.0  ...         4.0       4.0   \n",
       "oliwka__2007            0.0       4.0        0.0  ...         2.0       2.0   \n",
       "z_przestrzeni_serca     0.0       0.0        0.0  ...         4.0       3.0   \n",
       "zaradne_warsztaty       2.0       3.0        4.0  ...         3.0       4.0   \n",
       "\n",
       "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "id                                                                            \n",
       "marek_grodzki            4.0         4.0       3.0         4.0          4.0   \n",
       "vege_style_life          4.0         4.0       3.0         3.0          3.0   \n",
       "oliwka__2007             0.0         3.0       1.0         2.0          4.0   \n",
       "z_przestrzeni_serca      0.0         4.0       4.0         3.0          4.0   \n",
       "zaradne_warsztaty        0.0         2.0       2.0         4.0          2.0   \n",
       "\n",
       "                     believe  egocentric  allocentric  \n",
       "id                                                     \n",
       "marek_grodzki            3.0         0.0          0.0  \n",
       "vege_style_life          2.0         0.0          3.0  \n",
       "oliwka__2007             1.0         0.0          3.0  \n",
       "z_przestrzeni_serca      4.0         0.0          1.0  \n",
       "zaradne_warsztaty        3.0         1.0          3.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .csv with archetypes\n",
    "arch_df = pd.read_csv('archetypes_pl_new.csv', index_col=0)\n",
    "\n",
    "# Save the order of columns\n",
    "trait_list = arch_df.columns.tolist()\n",
    "\n",
    "# Show the table header and column list\n",
    "print(trait_list)\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c769705a-c54c-49de-8fd9-f699a358940b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>morning</th>\n",
       "      <th>wish</th>\n",
       "      <th>you</th>\n",
       "      <th>nice</th>\n",
       "      <th>relaxing</th>\n",
       "      <th>thursday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>friday</th>\n",
       "      <th>start</th>\n",
       "      <th>...</th>\n",
       "      <th>#uÅ¼ywane</th>\n",
       "      <th>#podzielnia</th>\n",
       "      <th>#ekobiuro</th>\n",
       "      <th>#goHi2020</th>\n",
       "      <th>#hackaton</th>\n",
       "      <th>#jachranka</th>\n",
       "      <th>#greenladies</th>\n",
       "      <th>#greenguys</th>\n",
       "      <th>#polishheroes</th>\n",
       "      <th>#bestgifts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">innocent</th>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164918</td>\n",
       "      <td>0.363648</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059452</td>\n",
       "      <td>0.032827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885980</td>\n",
       "      <td>0.026943</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097603</td>\n",
       "      <td>0.325299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053402</td>\n",
       "      <td>0.063776</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.250463</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.062854</td>\n",
       "      <td>0.216949</td>\n",
       "      <td>0.151777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 211596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                good   morning      wish       you      nice  relaxing  \\\n",
       "innocent 0  1.000000  1.000000  1.000000  0.985589  1.000000  1.000000   \n",
       "         1  0.164918  0.363648  0.005689  1.000000  0.000000  0.000000   \n",
       "         2  0.059452  0.032827  0.000000  0.885980  0.026943  0.003168   \n",
       "         3  0.053402  0.063776  0.003512  0.250463  0.024454  0.000000   \n",
       "         4  0.000000  0.000000  0.000000  0.000000  0.013889  0.000000   \n",
       "\n",
       "            thursday  saturday    friday     start  ...  #uÅ¼ywane  \\\n",
       "innocent 0  1.000000  1.000000  0.579753  1.000000  ...       0.0   \n",
       "         1  0.000000  0.000000  1.000000  0.437572  ...       0.0   \n",
       "         2  0.000000  0.000000  0.097603  0.325299  ...       0.0   \n",
       "         3  0.021592  0.062854  0.216949  0.151777  ...       0.0   \n",
       "         4  0.000000  0.000000  0.000000  0.000000  ...       0.0   \n",
       "\n",
       "            #podzielnia  #ekobiuro  #goHi2020  #hackaton  #jachranka  \\\n",
       "innocent 0          0.0        0.0        0.0        0.0         0.0   \n",
       "         1          0.0        0.0        0.0        0.0         0.0   \n",
       "         2          0.0        0.0        0.0        0.0         0.0   \n",
       "         3          0.0        0.0        0.0        0.0         0.0   \n",
       "         4          0.0        0.0        0.0        0.0         0.0   \n",
       "\n",
       "            #greenladies  #greenguys  #polishheroes  #bestgifts  \n",
       "innocent 0           0.0         0.0            0.0         0.0  \n",
       "         1           0.0         0.0            0.0         0.0  \n",
       "         2           0.0         0.0            0.0         0.0  \n",
       "         3           0.0         0.0            0.0         0.0  \n",
       "         4           0.0         0.0            0.0         0.0  \n",
       "\n",
       "[5 rows x 211596 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(\"agds_structures/train_90.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"agds_structures/test_10.csv\", index_col=0)\n",
    "\n",
    "with open(\"agds_structures/vectorized_test_90.pickle\", \"rb\") as f:\n",
    "    test_vectorized = pickle.load(f)\n",
    "    \n",
    "with open(\"agds_structures/vectorized_train_90.pickle\", \"rb\") as f:\n",
    "    train_vectorized = pickle.load(f)\n",
    "    \n",
    "# Load structure\n",
    "with open(\"agds_structures/normalized_s90_10_word_trait_array.pickle\", \"rb\") as f:\n",
    "    softmax_word_df = pickle.load(f)\n",
    "\n",
    "# Extract word map\n",
    "softmax_word_map = softmax_word_df.columns.tolist()\n",
    "    \n",
    "# Show array head\n",
    "softmax_word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f92fce-fc6c-40f1-80ce-b995e438ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "X_train = np.array(train_vectorized)\n",
    "print(len(X_train))\n",
    "\n",
    "# Prepare validation/test dataset\n",
    "X_val = np.array(test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69d22b3-323e-4ce1-9d58-5eed60c801f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "def build_model():\n",
    "    inputs = tf.keras.Input(shape=(len(softmax_word_map), ), name=\"input_layer\")\n",
    "    x = SparseLayer(5, name=\"AGDS_weight_layer\")(inputs)\n",
    "    outputs = tf.keras.activations.softmax(x)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=[outputs]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs_agds_model\")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n",
    "                              patience=5, min_lr=1e-7, verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', min_delta=0, patience=20, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85e6308-faf8-4a04-a60e-8f8057c7f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trait_training_pipeline(trait_list):\n",
    "    for trait in tqdm(trait_list):\n",
    "        # Prepare labels\n",
    "        y_train = tf.keras.utils.to_categorical(np.array(train_df[trait]), num_classes=5)\n",
    "        y_val = tf.keras.utils.to_categorical(np.array(test_df[trait]), num_classes=5)\n",
    "\n",
    "        # Create model\n",
    "        test_model = build_model()\n",
    "\n",
    "        test_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-2),\n",
    "                       loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                       metrics=[\"accuracy\"])\n",
    "\n",
    "        # Set callbacks\n",
    "        model_save_callback = tf.keras.callbacks.ModelCheckpoint(\"./agds_structures/weight_finetuning/\"+trait+\"-saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\", \n",
    "                                                              monitor='val_accuracy', \n",
    "                                                              verbose=1, save_best_only=True, save_weights_only=True, \n",
    "                                                              mode='max')\n",
    "        \n",
    "\n",
    "        # Train the model\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            out = test_model.fit(X_train, \n",
    "                                 y_train,\n",
    "                                 batch_size=10,\n",
    "                                 validation_data=(X_val, y_val),\n",
    "                                 epochs=100,\n",
    "                                 callbacks=[model_save_callback, tensorboard_callback, reduce_lr, early_stop])\n",
    "\n",
    "        weights_tmp = test_model.get_layer(\"AGDS_weight_layer\").get_weights()[0]\n",
    "        softmax_word_df.loc[trait] = weights_tmp.T\n",
    "        \n",
    "        del y_train\n",
    "        del y_val\n",
    "        del test_model\n",
    "        del out\n",
    "        del weights_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b939c850-0808-40f4-b848-5e224b691ff6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be05be10bb96495e8bdcc9e4f9f74397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 3s 18ms/step - loss: 1.3657 - accuracy: 0.5373 - val_loss: 1.2835 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62319, saving model to ./agds_structures/weight_finetuning/innocent-saved-model-01-0.62.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2753 - accuracy: 0.6266 - val_loss: 1.3065 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62319\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2628 - accuracy: 0.6429 - val_loss: 1.3128 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62319\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2181 - accuracy: 0.6851 - val_loss: 1.3344 - val_accuracy: 0.5652\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62319\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2075 - accuracy: 0.6964 - val_loss: 1.3112 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62319\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1996 - accuracy: 0.7062 - val_loss: 1.2933 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1758 - accuracy: 0.7289 - val_loss: 1.2994 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.62319\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1717 - accuracy: 0.7338 - val_loss: 1.3029 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.62319\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1693 - accuracy: 0.7354 - val_loss: 1.3060 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.62319\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1694 - accuracy: 0.7354 - val_loss: 1.3067 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.62319\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1694 - accuracy: 0.7354 - val_loss: 1.3195 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1662 - accuracy: 0.7386 - val_loss: 1.3193 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.62319\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1661 - accuracy: 0.7386 - val_loss: 1.3191 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.62319\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.1660 - accuracy: 0.7386 - val_loss: 1.3195 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.62319\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1660 - accuracy: 0.7386 - val_loss: 1.3167 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.62319\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1660 - accuracy: 0.7386 - val_loss: 1.3164 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1660 - accuracy: 0.7386 - val_loss: 1.3150 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.62319\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1660 - accuracy: 0.7386 - val_loss: 1.3140 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.62319\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1659 - accuracy: 0.7386 - val_loss: 1.3121 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.62319\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1659 - accuracy: 0.7386 - val_loss: 1.3107 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.62319\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1659 - accuracy: 0.7386 - val_loss: 1.3090 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5142 - accuracy: 0.3847 - val_loss: 1.4822 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.42029, saving model to ./agds_structures/weight_finetuning/sage-saved-model-01-0.42.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3881 - accuracy: 0.5162 - val_loss: 1.4791 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.42029\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3453 - accuracy: 0.5584 - val_loss: 1.4459 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.42029 to 0.44928, saving model to ./agds_structures/weight_finetuning/sage-saved-model-03-0.45.hdf5\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3170 - accuracy: 0.5860 - val_loss: 1.4597 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.44928\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3151 - accuracy: 0.5893 - val_loss: 1.5493 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.44928\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2934 - accuracy: 0.6104 - val_loss: 1.4696 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.44928\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2680 - accuracy: 0.6364 - val_loss: 1.4384 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.44928\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.2613 - accuracy: 0.6429 - val_loss: 1.4145 - val_accuracy: 0.4783\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.44928 to 0.47826, saving model to ./agds_structures/weight_finetuning/sage-saved-model-08-0.48.hdf5\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2477 - accuracy: 0.6575 - val_loss: 1.4505 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.47826\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2429 - accuracy: 0.6623 - val_loss: 1.4773 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.47826\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2299 - accuracy: 0.6753 - val_loss: 1.4648 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.47826\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2307 - accuracy: 0.6737 - val_loss: 1.4067 - val_accuracy: 0.5072\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.47826 to 0.50725, saving model to ./agds_structures/weight_finetuning/sage-saved-model-12-0.51.hdf5\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2262 - accuracy: 0.6786 - val_loss: 1.4821 - val_accuracy: 0.4058\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.50725\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2274 - accuracy: 0.6769 - val_loss: 1.4233 - val_accuracy: 0.4783\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.50725\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2128 - accuracy: 0.6932 - val_loss: 1.4245 - val_accuracy: 0.4783\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.50725\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.2092 - accuracy: 0.6948 - val_loss: 1.4271 - val_accuracy: 0.4638\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.50725\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2033 - accuracy: 0.7013 - val_loss: 1.4944 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.50725\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1998 - accuracy: 0.7045 - val_loss: 1.5162 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.50725\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1938 - accuracy: 0.7110 - val_loss: 1.5228 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.50725\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1890 - accuracy: 0.7159 - val_loss: 1.5207 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.50725\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1889 - accuracy: 0.7159 - val_loss: 1.4711 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.50725\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1889 - accuracy: 0.7159 - val_loss: 1.5005 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.50725\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1872 - accuracy: 0.7175 - val_loss: 1.5139 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.50725\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1873 - accuracy: 0.7175 - val_loss: 1.5126 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.50725\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1872 - accuracy: 0.7175 - val_loss: 1.5183 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.50725\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1873 - accuracy: 0.7175 - val_loss: 1.5197 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.50725\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1872 - accuracy: 0.7175 - val_loss: 1.5240 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.50725\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1872 - accuracy: 0.7175 - val_loss: 1.5244 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.50725\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1872 - accuracy: 0.7175 - val_loss: 1.5249 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.50725\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1872 - accuracy: 0.7175 - val_loss: 1.5242 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.50725\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1871 - accuracy: 0.7175 - val_loss: 1.5246 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.50725\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.1871 - accuracy: 0.7175 - val_loss: 1.5239 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.50725\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.6123 - accuracy: 0.2825 - val_loss: 1.5907 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.31884, saving model to ./agds_structures/weight_finetuning/explorer-saved-model-01-0.32.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4851 - accuracy: 0.4172 - val_loss: 1.5962 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.31884\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3933 - accuracy: 0.5097 - val_loss: 1.5693 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.31884 to 0.34783, saving model to ./agds_structures/weight_finetuning/explorer-saved-model-03-0.35.hdf5\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3478 - accuracy: 0.5552 - val_loss: 1.5872 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.34783\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3057 - accuracy: 0.5974 - val_loss: 1.5796 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.34783\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2683 - accuracy: 0.6347 - val_loss: 1.5766 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.34783\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2599 - accuracy: 0.6445 - val_loss: 1.6066 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.34783\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2329 - accuracy: 0.6721 - val_loss: 1.5945 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.34783\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2135 - accuracy: 0.6916 - val_loss: 1.5892 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.34783\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2052 - accuracy: 0.6997 - val_loss: 1.5935 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.34783\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2020 - accuracy: 0.7029 - val_loss: 1.5831 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.34783\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1990 - accuracy: 0.7062 - val_loss: 1.5857 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.34783\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1923 - accuracy: 0.7127 - val_loss: 1.5880 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.34783\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1905 - accuracy: 0.7143 - val_loss: 1.5880 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.34783\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1905 - accuracy: 0.7143 - val_loss: 1.5880 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.34783\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1903 - accuracy: 0.7143 - val_loss: 1.5881 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.34783\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1904 - accuracy: 0.7143 - val_loss: 1.5875 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.34783\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1903 - accuracy: 0.7143 - val_loss: 1.5878 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.34783\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1901 - accuracy: 0.7143 - val_loss: 1.5874 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.34783\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1898 - accuracy: 0.7143 - val_loss: 1.5870 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.34783\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1895 - accuracy: 0.7143 - val_loss: 1.5866 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.34783\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1892 - accuracy: 0.7159 - val_loss: 1.5865 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.34783\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1889 - accuracy: 0.7159 - val_loss: 1.5862 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.34783\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5496 - accuracy: 0.3490 - val_loss: 1.5681 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.31884, saving model to ./agds_structures/weight_finetuning/outlaw-saved-model-01-0.32.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4053 - accuracy: 0.4984 - val_loss: 1.5908 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.31884\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3654 - accuracy: 0.5390 - val_loss: 1.5373 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.31884 to 0.37681, saving model to ./agds_structures/weight_finetuning/outlaw-saved-model-03-0.38.hdf5\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2977 - accuracy: 0.6039 - val_loss: 1.5803 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.37681\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2883 - accuracy: 0.6169 - val_loss: 1.5704 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.37681\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2694 - accuracy: 0.6347 - val_loss: 1.5249 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.37681\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2630 - accuracy: 0.6412 - val_loss: 1.5154 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.37681 to 0.39130, saving model to ./agds_structures/weight_finetuning/outlaw-saved-model-07-0.39.hdf5\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2587 - accuracy: 0.6445 - val_loss: 1.5706 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.39130\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2570 - accuracy: 0.6477 - val_loss: 1.5639 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.39130\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2556 - accuracy: 0.6494 - val_loss: 1.5538 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.39130\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2522 - accuracy: 0.6526 - val_loss: 1.5537 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.39130\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2536 - accuracy: 0.6510 - val_loss: 1.5285 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.39130\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2506 - accuracy: 0.6542 - val_loss: 1.5387 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.39130\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2472 - accuracy: 0.6575 - val_loss: 1.5384 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.39130\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2408 - accuracy: 0.6640 - val_loss: 1.5358 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.39130\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2374 - accuracy: 0.6672 - val_loss: 1.5427 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.39130\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2360 - accuracy: 0.6688 - val_loss: 1.5339 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.39130\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2360 - accuracy: 0.6688 - val_loss: 1.5349 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.39130\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2360 - accuracy: 0.6688 - val_loss: 1.5359 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.39130\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2360 - accuracy: 0.6688 - val_loss: 1.5368 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.39130\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2359 - accuracy: 0.6688 - val_loss: 1.5355 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.39130\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2360 - accuracy: 0.6688 - val_loss: 1.5365 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.39130\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2359 - accuracy: 0.6688 - val_loss: 1.5363 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.39130\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2359 - accuracy: 0.6688 - val_loss: 1.5365 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.39130\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2359 - accuracy: 0.6688 - val_loss: 1.5363 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.39130\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2359 - accuracy: 0.6688 - val_loss: 1.5366 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.39130\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2359 - accuracy: 0.6688 - val_loss: 1.5364 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.39130\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.5269 - accuracy: 0.3734 - val_loss: 1.5650 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33333, saving model to ./agds_structures/weight_finetuning/magician-saved-model-01-0.33.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4229 - accuracy: 0.4805 - val_loss: 1.5726 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.33333\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3964 - accuracy: 0.5081 - val_loss: 1.6009 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.33333\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3859 - accuracy: 0.5179 - val_loss: 1.6115 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.33333\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3650 - accuracy: 0.5406 - val_loss: 1.6129 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.33333\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3381 - accuracy: 0.5666 - val_loss: 1.5903 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.33333\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3230 - accuracy: 0.5812 - val_loss: 1.6060 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.33333\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3044 - accuracy: 0.6006 - val_loss: 1.6108 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.33333\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3013 - accuracy: 0.6023 - val_loss: 1.5857 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.33333\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2835 - accuracy: 0.6201 - val_loss: 1.5960 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.33333\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2712 - accuracy: 0.6347 - val_loss: 1.6254 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.33333\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2582 - accuracy: 0.6461 - val_loss: 1.6240 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.33333\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2566 - accuracy: 0.6477 - val_loss: 1.6265 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.33333\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2561 - accuracy: 0.6477 - val_loss: 1.6086 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.33333\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2543 - accuracy: 0.6494 - val_loss: 1.6132 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.33333\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2515 - accuracy: 0.6526 - val_loss: 1.6039 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.33333\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2496 - accuracy: 0.6542 - val_loss: 1.6041 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.33333\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2490 - accuracy: 0.6542 - val_loss: 1.6054 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.33333\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2483 - accuracy: 0.6558 - val_loss: 1.6069 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.33333\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2478 - accuracy: 0.6558 - val_loss: 1.6082 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.33333\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2473 - accuracy: 0.6558 - val_loss: 1.6083 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.33333\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5302 - accuracy: 0.3669 - val_loss: 1.5085 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.39130, saving model to ./agds_structures/weight_finetuning/hero-saved-model-01-0.39.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3941 - accuracy: 0.5114 - val_loss: 1.5199 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.39130\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3522 - accuracy: 0.5519 - val_loss: 1.5118 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.39130\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3342 - accuracy: 0.5682 - val_loss: 1.5231 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.39130\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3208 - accuracy: 0.5828 - val_loss: 1.5337 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.39130\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3152 - accuracy: 0.5893 - val_loss: 1.5004 - val_accuracy: 0.4058\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.39130 to 0.40580, saving model to ./agds_structures/weight_finetuning/hero-saved-model-06-0.41.hdf5\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3123 - accuracy: 0.5925 - val_loss: 1.5275 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.40580\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3107 - accuracy: 0.5942 - val_loss: 1.5124 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.40580\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3106 - accuracy: 0.5942 - val_loss: 1.5227 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.40580\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.2931 - accuracy: 0.6104 - val_loss: 1.5038 - val_accuracy: 0.4058\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.40580\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2664 - accuracy: 0.6380 - val_loss: 1.5254 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.40580\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2566 - accuracy: 0.6461 - val_loss: 1.5940 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.40580\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2370 - accuracy: 0.6656 - val_loss: 1.6145 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.40580\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2043 - accuracy: 0.7013 - val_loss: 1.6159 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.40580\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1905 - accuracy: 0.7143 - val_loss: 1.6028 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.40580\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1815 - accuracy: 0.7224 - val_loss: 1.5988 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.40580\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1761 - accuracy: 0.7289 - val_loss: 1.5994 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.40580\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1743 - accuracy: 0.7305 - val_loss: 1.5977 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.40580\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1741 - accuracy: 0.7305 - val_loss: 1.6017 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.40580\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1734 - accuracy: 0.7305 - val_loss: 1.5931 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.40580\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1722 - accuracy: 0.7321 - val_loss: 1.5914 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.40580\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1722 - accuracy: 0.7321 - val_loss: 1.5911 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.40580\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1719 - accuracy: 0.7321 - val_loss: 1.5910 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.40580\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1718 - accuracy: 0.7321 - val_loss: 1.5907 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.40580\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1716 - accuracy: 0.7321 - val_loss: 1.5911 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.40580\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1716 - accuracy: 0.7321 - val_loss: 1.5905 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.40580\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.6351 - accuracy: 0.2614 - val_loss: 1.5806 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.31884, saving model to ./agds_structures/weight_finetuning/lover-saved-model-01-0.32.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4521 - accuracy: 0.4448 - val_loss: 1.5499 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.31884 to 0.36232, saving model to ./agds_structures/weight_finetuning/lover-saved-model-02-0.36.hdf5\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3761 - accuracy: 0.5292 - val_loss: 1.5434 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.36232\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3469 - accuracy: 0.5568 - val_loss: 1.5080 - val_accuracy: 0.3913\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.36232 to 0.39130, saving model to ./agds_structures/weight_finetuning/lover-saved-model-04-0.39.hdf5\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3128 - accuracy: 0.5909 - val_loss: 1.5305 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.39130\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2779 - accuracy: 0.6266 - val_loss: 1.4967 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.39130 to 0.42029, saving model to ./agds_structures/weight_finetuning/lover-saved-model-06-0.42.hdf5\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2619 - accuracy: 0.6412 - val_loss: 1.4791 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.42029\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2546 - accuracy: 0.6494 - val_loss: 1.4458 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.42029 to 0.44928, saving model to ./agds_structures/weight_finetuning/lover-saved-model-08-0.45.hdf5\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2445 - accuracy: 0.6591 - val_loss: 1.5049 - val_accuracy: 0.4058\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.44928\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2372 - accuracy: 0.6672 - val_loss: 1.4772 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.44928\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2312 - accuracy: 0.6737 - val_loss: 1.4552 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.44928\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2285 - accuracy: 0.6769 - val_loss: 1.4678 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.44928\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2195 - accuracy: 0.6851 - val_loss: 1.4555 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.44928\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2199 - accuracy: 0.6851 - val_loss: 1.4694 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.44928\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2165 - accuracy: 0.6883 - val_loss: 1.4628 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.44928\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2146 - accuracy: 0.6899 - val_loss: 1.4861 - val_accuracy: 0.4203\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.44928\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2147 - accuracy: 0.6899 - val_loss: 1.4856 - val_accuracy: 0.4058\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.44928\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2148 - accuracy: 0.6899 - val_loss: 1.4654 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.44928\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2147 - accuracy: 0.6899 - val_loss: 1.4627 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.44928\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2136 - accuracy: 0.6916 - val_loss: 1.4591 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.44928\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2131 - accuracy: 0.6916 - val_loss: 1.4569 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.44928\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2130 - accuracy: 0.6916 - val_loss: 1.4537 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.44928\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2130 - accuracy: 0.6916 - val_loss: 1.4518 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.44928\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2130 - accuracy: 0.6916 - val_loss: 1.4514 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.44928\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2129 - accuracy: 0.6916 - val_loss: 1.4510 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.44928\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2129 - accuracy: 0.6916 - val_loss: 1.4508 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.44928\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2129 - accuracy: 0.6916 - val_loss: 1.4504 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.44928\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2129 - accuracy: 0.6916 - val_loss: 1.4502 - val_accuracy: 0.4493\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.44928\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5830 - accuracy: 0.3149 - val_loss: 1.6160 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.27536, saving model to ./agds_structures/weight_finetuning/jester-saved-model-01-0.28.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4407 - accuracy: 0.4610 - val_loss: 1.6081 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.27536 to 0.28986, saving model to ./agds_structures/weight_finetuning/jester-saved-model-02-0.29.hdf5\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4104 - accuracy: 0.4935 - val_loss: 1.6073 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.28986\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3811 - accuracy: 0.5227 - val_loss: 1.5872 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.28986 to 0.30435, saving model to ./agds_structures/weight_finetuning/jester-saved-model-04-0.30.hdf5\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3706 - accuracy: 0.5341 - val_loss: 1.5895 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.30435\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3554 - accuracy: 0.5487 - val_loss: 1.6245 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.30435\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3494 - accuracy: 0.5552 - val_loss: 1.6528 - val_accuracy: 0.2464\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.30435\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3390 - accuracy: 0.5649 - val_loss: 1.6008 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.30435\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3374 - accuracy: 0.5666 - val_loss: 1.6069 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.30435\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3346 - accuracy: 0.5698 - val_loss: 1.6050 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.30435\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3302 - accuracy: 0.5747 - val_loss: 1.6075 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.30435\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3285 - accuracy: 0.5763 - val_loss: 1.6109 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.30435\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3255 - accuracy: 0.5795 - val_loss: 1.6327 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.30435\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3253 - accuracy: 0.5795 - val_loss: 1.6214 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.30435\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3253 - accuracy: 0.5795 - val_loss: 1.6212 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.30435\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3253 - accuracy: 0.5795 - val_loss: 1.6210 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.30435\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3251 - accuracy: 0.5795 - val_loss: 1.6200 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.30435\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3247 - accuracy: 0.5795 - val_loss: 1.6211 - val_accuracy: 0.2754\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.30435\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3220 - accuracy: 0.5828 - val_loss: 1.6240 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.30435\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3214 - accuracy: 0.5828 - val_loss: 1.6240 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.30435\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3209 - accuracy: 0.5844 - val_loss: 1.6238 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.30435\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3205 - accuracy: 0.5844 - val_loss: 1.6233 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.30435\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3203 - accuracy: 0.5844 - val_loss: 1.6223 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.30435\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3202 - accuracy: 0.5844 - val_loss: 1.6217 - val_accuracy: 0.2609\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.30435\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3487 - accuracy: 0.5552 - val_loss: 1.2926 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60870, saving model to ./agds_structures/weight_finetuning/everyman-saved-model-01-0.61.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3131 - accuracy: 0.5925 - val_loss: 1.3194 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.60870\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2948 - accuracy: 0.6088 - val_loss: 1.2893 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.60870 to 0.62319, saving model to ./agds_structures/weight_finetuning/everyman-saved-model-03-0.62.hdf5\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2777 - accuracy: 0.6266 - val_loss: 1.2832 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62319\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2717 - accuracy: 0.6331 - val_loss: 1.2809 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62319\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2635 - accuracy: 0.6412 - val_loss: 1.2939 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.62319\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2636 - accuracy: 0.6412 - val_loss: 1.2849 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.62319\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2636 - accuracy: 0.6412 - val_loss: 1.2800 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2799 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.62319\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2799 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.62319\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2798 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.62319\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2798 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.62319\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2798 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.62319\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.62319\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.62319\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.62319\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.62319\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.62319\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.62319\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.62319\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2620 - accuracy: 0.6429 - val_loss: 1.2797 - val_accuracy: 0.6232\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.62319\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 20ms/step - loss: 1.6544 - accuracy: 0.2484 - val_loss: 1.5923 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.28986, saving model to ./agds_structures/weight_finetuning/caregiver-saved-model-01-0.29.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4803 - accuracy: 0.4221 - val_loss: 1.5591 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.28986 to 0.36232, saving model to ./agds_structures/weight_finetuning/caregiver-saved-model-02-0.36.hdf5\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3807 - accuracy: 0.5195 - val_loss: 1.5407 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.36232\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3243 - accuracy: 0.5795 - val_loss: 1.5792 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.36232\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2885 - accuracy: 0.6153 - val_loss: 1.5494 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.36232\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2741 - accuracy: 0.6282 - val_loss: 1.6092 - val_accuracy: 0.2899\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.36232\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2346 - accuracy: 0.6705 - val_loss: 1.5484 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.36232\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2170 - accuracy: 0.6867 - val_loss: 1.5701 - val_accuracy: 0.3188\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.36232\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2013 - accuracy: 0.7029 - val_loss: 1.5757 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.36232\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1943 - accuracy: 0.7110 - val_loss: 1.5504 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.36232\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1904 - accuracy: 0.7143 - val_loss: 1.5349 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.36232 to 0.37681, saving model to ./agds_structures/weight_finetuning/caregiver-saved-model-11-0.38.hdf5\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1839 - accuracy: 0.7208 - val_loss: 1.5602 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.37681\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1782 - accuracy: 0.7256 - val_loss: 1.5711 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.37681\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1733 - accuracy: 0.7305 - val_loss: 1.5589 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.37681\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1706 - accuracy: 0.7338 - val_loss: 1.5540 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.37681\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1693 - accuracy: 0.7354 - val_loss: 1.5657 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.37681\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1660 - accuracy: 0.7386 - val_loss: 1.5494 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.37681\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1644 - accuracy: 0.7403 - val_loss: 1.5456 - val_accuracy: 0.3768\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.37681\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1625 - accuracy: 0.7419 - val_loss: 1.5472 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.37681\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1624 - accuracy: 0.7419 - val_loss: 1.5493 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.37681\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1610 - accuracy: 0.7435 - val_loss: 1.5466 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.37681\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1608 - accuracy: 0.7435 - val_loss: 1.5477 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.37681\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1607 - accuracy: 0.7435 - val_loss: 1.5476 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.37681\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1606 - accuracy: 0.7435 - val_loss: 1.5495 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.37681\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1606 - accuracy: 0.7435 - val_loss: 1.5481 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.37681\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1605 - accuracy: 0.7435 - val_loss: 1.5498 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.37681\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1605 - accuracy: 0.7435 - val_loss: 1.5495 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.37681\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1605 - accuracy: 0.7435 - val_loss: 1.5491 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.37681\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1605 - accuracy: 0.7435 - val_loss: 1.5489 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.37681\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1604 - accuracy: 0.7435 - val_loss: 1.5487 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.37681\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1604 - accuracy: 0.7435 - val_loss: 1.5485 - val_accuracy: 0.3623\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.37681\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Epoch 1/100\n",
      " 2/62 [..............................] - ETA: 1:28:32 - loss: 1.6886 - accuracy: 0.2000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-8b4b62bc367b>\", line 1, in <module>\n",
      "    trait_training_pipeline(trait_list)\n",
      "  File \"<ipython-input-8-17c622f02d43>\", line 23, in trait_training_pipeline\n",
      "    out = test_model.fit(X_train,\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 917, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3023, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2202, in _build_call_outputs\n",
      "    outputs_list = nest.flatten(\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py\", line 416, in flatten\n",
      "    return _pywrap_utils.Flatten(structure, expand_composites)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-8b4b62bc367b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrait_training_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrait_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-17c622f02d43>\u001b[0m in \u001b[0;36mtrait_training_pipeline\u001b[0;34m(trait_list)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/GPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             out = test_model.fit(X_train, \n\u001b[0m\u001b[1;32m     24\u001b[0m                                  \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \u001b[0;31m# Replace outputs with results, skipping over any 'None' values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2202\u001b[0;31m     outputs_list = nest.flatten(\n\u001b[0m\u001b[1;32m   2203\u001b[0m         self._func_graph.structured_outputs, expand_composites=True)\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    415\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HDD_Linux/Praca_magisterska/instagram_analysis/insta_venv/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "trait_training_pipeline(trait_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a6ebe-a3db-4ba8-bdec-d2c854da2fde",
   "metadata": {},
   "source": [
    "# Test stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c0392da-044b-4e80-864a-e0582e8e63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare weights for \n",
    "\n",
    "test_model.get_layer(\"AGDS_weight_layer\").set_weights([softmax_word_df.loc[\"innocent\"].to_numpy().T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d62be87d-49ea-438b-9ff1-7c775afa97b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.1431 - accuracy: 0.7614 - val_loss: 1.0792 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82609, saving model to ./agds_structures/saved-model-01-0.83.hdf5\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0897 - accuracy: 0.8149 - val_loss: 1.0637 - val_accuracy: 0.8406\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.82609 to 0.84058, saving model to ./agds_structures/saved-model-02-0.84.hdf5\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0501 - accuracy: 0.8539 - val_loss: 1.0280 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.84058 to 0.86957, saving model to ./agds_structures/saved-model-03-0.87.hdf5\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0146 - accuracy: 0.8896 - val_loss: 1.0208 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.86957 to 0.88406, saving model to ./agds_structures/saved-model-04-0.88.hdf5\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0061 - accuracy: 0.8977 - val_loss: 1.0194 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.88406\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9976 - accuracy: 0.9075 - val_loss: 1.0131 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.88406\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9973 - accuracy: 0.9075 - val_loss: 1.0081 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.88406 to 0.89855, saving model to ./agds_structures/saved-model-07-0.90.hdf5\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9991 - accuracy: 0.9058 - val_loss: 1.0051 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.89855\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9928 - accuracy: 0.9123 - val_loss: 1.0073 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.89855\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9941 - accuracy: 0.9107 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.89855 to 0.91304, saving model to ./agds_structures/saved-model-10-0.91.hdf5\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9876 - accuracy: 0.9172 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91304\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91304\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91304\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91304\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91304\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91304\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91304\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91304\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91304\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91304\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91304\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.91304\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.91304\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.91304\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.91304\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.91304\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.91304\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.91304\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.91304\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9844 - accuracy: 0.9205 - val_loss: 0.9918 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.91304\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "test_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-2),\n",
    "                   loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "# Set callbacks\n",
    "model_save_callback = tf.keras.callbacks.ModelCheckpoint(\"./agds_structures/weight_finetuning/saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\", \n",
    "                                                      monitor='val_accuracy', \n",
    "                                                      verbose=1, save_best_only=True, save_weights_only=True, \n",
    "                                                      mode='auto')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs_agds_model\")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n",
    "                              patience=5, min_lr=1e-7, verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', min_delta=0, patience=20, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    out = test_model.fit(X_train, \n",
    "                         y_train,\n",
    "                         batch_size=10,\n",
    "                         validation_data=(X_val, y_val),\n",
    "                         epochs=100,\n",
    "                         callbacks=[model_save_callback, tensorboard_callback, reduce_lr, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aabb4cab-74ee-4ccd-822d-5cf371950fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 211596)]          0         \n",
      "_________________________________________________________________\n",
      "AGDS_weight_layer (SparseLay (None, 5)                 1057980   \n",
      "_________________________________________________________________\n",
      "tf.compat.v1.nn.softmax (TFO (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,057,980\n",
      "Trainable params: 1,057,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4a3557e-ca14-47b3-b729-04570ed0d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.6871972e-01  7.6641291e-02 -1.3664700e-01  3.3654189e-01\n",
      "  -1.1755135e-01]\n",
      " [ 1.0776323e+00  3.0333450e-01 -3.6403559e-02  2.3373212e-01\n",
      "  -9.4700076e-02]\n",
      " [ 1.0000000e+00  3.1873159e-02 -9.4676167e-02  6.7399435e-02\n",
      "  -3.1427972e-02]\n",
      " ...\n",
      " [ 0.0000000e+00  4.4363305e-02 -4.4368908e-02  1.8069198e-18\n",
      "   0.0000000e+00]\n",
      " [ 0.0000000e+00  4.4363305e-02 -4.4368908e-02  1.8069198e-18\n",
      "   0.0000000e+00]\n",
      " [ 0.0000000e+00  4.4363305e-02 -4.4368908e-02  1.8069198e-18\n",
      "   0.0000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_tmp = test_model.get_layer(\"AGDS_weight_layer\").get_weights()[0]\n",
    "print(weights_tmp)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ceeb21-5ee0-4f10-8830-4d048806c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to set the dataframe with new weights\n",
    "softmax_word_df.loc[\"innocent\"] = weights_tmp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "014901a9-e3ad-40e4-82d2-7a83c4849d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>morning</th>\n",
       "      <th>wish</th>\n",
       "      <th>you</th>\n",
       "      <th>nice</th>\n",
       "      <th>relaxing</th>\n",
       "      <th>thursday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>friday</th>\n",
       "      <th>start</th>\n",
       "      <th>...</th>\n",
       "      <th>#uÅ¼ywane</th>\n",
       "      <th>#podzielnia</th>\n",
       "      <th>#ekobiuro</th>\n",
       "      <th>#goHi2020</th>\n",
       "      <th>#hackaton</th>\n",
       "      <th>#jachranka</th>\n",
       "      <th>#greenladies</th>\n",
       "      <th>#greenguys</th>\n",
       "      <th>#polishheroes</th>\n",
       "      <th>#bestgifts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">innocent</th>\n",
       "      <th>0</th>\n",
       "      <td>0.968720</td>\n",
       "      <td>1.077632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.797529e-01</td>\n",
       "      <td>0.978891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076641</td>\n",
       "      <td>0.303335</td>\n",
       "      <td>0.031873</td>\n",
       "      <td>0.898432</td>\n",
       "      <td>-0.014613</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.934082e-31</td>\n",
       "      <td>-1.018130e-01</td>\n",
       "      <td>9.946581e-01</td>\n",
       "      <td>0.350028</td>\n",
       "      <td>...</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "      <td>4.436330e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.136647</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>-0.094676</td>\n",
       "      <td>0.711773</td>\n",
       "      <td>0.089594</td>\n",
       "      <td>3.168382e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.369519e-02</td>\n",
       "      <td>3.892035e-02</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "      <td>-4.436891e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336542</td>\n",
       "      <td>0.233732</td>\n",
       "      <td>0.067399</td>\n",
       "      <td>0.597796</td>\n",
       "      <td>0.042476</td>\n",
       "      <td>1.589736e-10</td>\n",
       "      <td>2.159156e-02</td>\n",
       "      <td>1.882142e-01</td>\n",
       "      <td>2.493641e-01</td>\n",
       "      <td>0.341023</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "      <td>1.806920e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.117551</td>\n",
       "      <td>-0.094700</td>\n",
       "      <td>-0.031428</td>\n",
       "      <td>-0.173881</td>\n",
       "      <td>-0.017539</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.486718e-30</td>\n",
       "      <td>-1.334374e-22</td>\n",
       "      <td>-0.012682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 211596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                good   morning      wish       you      nice      relaxing  \\\n",
       "innocent 0  0.968720  1.077632  1.000000  0.922863  1.000000  1.000000e+00   \n",
       "         1  0.076641  0.303335  0.031873  0.898432 -0.014613  0.000000e+00   \n",
       "         2 -0.136647 -0.036404 -0.094676  0.711773  0.089594  3.168382e-03   \n",
       "         3  0.336542  0.233732  0.067399  0.597796  0.042476  1.589736e-10   \n",
       "         4 -0.117551 -0.094700 -0.031428 -0.173881 -0.017539  0.000000e+00   \n",
       "\n",
       "                thursday      saturday        friday     start  ...  \\\n",
       "innocent 0  1.000000e+00  1.000000e+00  5.797529e-01  0.978891  ...   \n",
       "         1 -2.934082e-31 -1.018130e-01  9.946581e-01  0.350028  ...   \n",
       "         2  0.000000e+00 -2.369519e-02  3.892035e-02  0.199146  ...   \n",
       "         3  2.159156e-02  1.882142e-01  2.493641e-01  0.341023  ...   \n",
       "         4  0.000000e+00 -8.486718e-30 -1.334374e-22 -0.012682  ...   \n",
       "\n",
       "                #uÅ¼ywane   #podzielnia     #ekobiuro     #goHi2020  \\\n",
       "innocent 0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "         1  4.436330e-02  4.436330e-02  4.436330e-02  4.436330e-02   \n",
       "         2 -4.436891e-02 -4.436891e-02 -4.436891e-02 -4.436891e-02   \n",
       "         3  1.806920e-18  1.806920e-18  1.806920e-18  1.806920e-18   \n",
       "         4  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "               #hackaton    #jachranka  #greenladies    #greenguys  \\\n",
       "innocent 0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "         1  4.436330e-02  4.436330e-02  4.436330e-02  4.436330e-02   \n",
       "         2 -4.436891e-02 -4.436891e-02 -4.436891e-02 -4.436891e-02   \n",
       "         3  1.806920e-18  1.806920e-18  1.806920e-18  1.806920e-18   \n",
       "         4  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "            #polishheroes    #bestgifts  \n",
       "innocent 0   0.000000e+00  0.000000e+00  \n",
       "         1   4.436330e-02  4.436330e-02  \n",
       "         2  -4.436891e-02 -4.436891e-02  \n",
       "         3   1.806920e-18  1.806920e-18  \n",
       "         4   0.000000e+00  0.000000e+00  \n",
       "\n",
       "[5 rows x 211596 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ce664-ea39-42cd-a103-cf4efe11796b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
