{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2386ecd2-193a-40a0-981e-43d8edce8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate words with archetypes/character traits as intermediate layer\n",
    "# and with influencer as the \"last\" layer\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import os\n",
    "import toml\n",
    "import re\n",
    "import itertools\n",
    "from text_cleaner import *\n",
    "import operator\n",
    "from collections import Counter\n",
    "from spmf import Spmf\n",
    "\n",
    "def extract_hashtags(post_text):\n",
    "    HASH_RE = re.compile(r\"\\#\\w+\")\n",
    "    out_list = re.findall(HASH_RE, post_text)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367d5f27-6428-4e65-8311-3fafe4df4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['innocent', 'sage', 'explorer', 'outlaw', 'magician', 'hero', 'lover', 'jester', 'everyman', 'caregiver', 'ruler', 'creator', 'dominant', 'submissive', 'maximalist', 'minimalist', 'inspiring', 'systematic', 'discovering', 'conservative', 'verifying', 'overlooking', 'sharpening', 'harmonic', 'empathic', 'matter_of_fact', 'brave', 'protective', 'generous', 'thrifty', 'favourable', 'balanced', 'sensuality', 'intelligent', 'believe', 'egocentric', 'allocentric']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marek_grodzki</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vege_style_life</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliwka__2007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_przestrzeni_serca</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaradne_warsztaty</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "id                                                                             \n",
       "marek_grodzki             0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "vege_style_life           0.0   0.0       4.0     0.0       0.0   0.0    0.0   \n",
       "oliwka__2007              0.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "z_przestrzeni_serca       4.0   0.0       0.0     0.0       0.0   0.0    0.0   \n",
       "zaradne_warsztaty         3.0   0.0       0.0     0.0       3.0   0.0    0.0   \n",
       "\n",
       "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
       "id                                                ...                         \n",
       "marek_grodzki           4.0       0.0        0.0  ...         2.0       3.0   \n",
       "vege_style_life         0.0       0.0        0.0  ...         4.0       4.0   \n",
       "oliwka__2007            0.0       4.0        0.0  ...         2.0       2.0   \n",
       "z_przestrzeni_serca     0.0       0.0        0.0  ...         4.0       3.0   \n",
       "zaradne_warsztaty       2.0       3.0        4.0  ...         3.0       4.0   \n",
       "\n",
       "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "id                                                                            \n",
       "marek_grodzki            4.0         4.0       3.0         4.0          4.0   \n",
       "vege_style_life          4.0         4.0       3.0         3.0          3.0   \n",
       "oliwka__2007             0.0         3.0       1.0         2.0          4.0   \n",
       "z_przestrzeni_serca      0.0         4.0       4.0         3.0          4.0   \n",
       "zaradne_warsztaty        0.0         2.0       2.0         4.0          2.0   \n",
       "\n",
       "                     believe  egocentric  allocentric  \n",
       "id                                                     \n",
       "marek_grodzki            3.0         0.0          0.0  \n",
       "vege_style_life          2.0         0.0          3.0  \n",
       "oliwka__2007             1.0         0.0          3.0  \n",
       "z_przestrzeni_serca      4.0         0.0          1.0  \n",
       "zaradne_warsztaty        3.0         1.0          3.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .csv with archetypes\n",
    "arch_df = pd.read_csv('archetypes_pl.csv', index_col=0)\n",
    "\n",
    "# Save the order of columns\n",
    "trait_list = arch_df.columns.tolist()\n",
    "\n",
    "# Show the table header and column list\n",
    "print(trait_list)\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48c394e-8c8b-4712-abd2-2924ad9af4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innocent</th>\n",
       "      <th>sage</th>\n",
       "      <th>explorer</th>\n",
       "      <th>outlaw</th>\n",
       "      <th>magician</th>\n",
       "      <th>hero</th>\n",
       "      <th>lover</th>\n",
       "      <th>jester</th>\n",
       "      <th>everyman</th>\n",
       "      <th>caregiver</th>\n",
       "      <th>...</th>\n",
       "      <th>protective</th>\n",
       "      <th>generous</th>\n",
       "      <th>thrifty</th>\n",
       "      <th>favourable</th>\n",
       "      <th>balanced</th>\n",
       "      <th>sensuality</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>believe</th>\n",
       "      <th>egocentric</th>\n",
       "      <th>allocentric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marek_grodzki</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vege_style_life</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oliwka__2007</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_przestrzeni_serca</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaradne_warsztaty</th>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
       "id                                                                             \n",
       "marek_grodzki            -1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "vege_style_life          -1.0  -1.0       1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "oliwka__2007             -1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "z_przestrzeni_serca       1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
       "zaradne_warsztaty         0.5  -1.0      -1.0    -1.0       0.5  -1.0   -1.0   \n",
       "\n",
       "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
       "id                                                ...                         \n",
       "marek_grodzki           1.0      -1.0       -1.0  ...         0.0       0.5   \n",
       "vege_style_life        -1.0      -1.0       -1.0  ...         1.0       1.0   \n",
       "oliwka__2007           -1.0       1.0       -1.0  ...         0.0       0.0   \n",
       "z_przestrzeni_serca    -1.0      -1.0       -1.0  ...         1.0       0.5   \n",
       "zaradne_warsztaty       0.0       0.5        1.0  ...         0.5       1.0   \n",
       "\n",
       "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
       "id                                                                            \n",
       "marek_grodzki            1.0         1.0       0.5         1.0          1.0   \n",
       "vege_style_life          1.0         1.0       0.5         0.5          0.5   \n",
       "oliwka__2007            -1.0         0.5      -0.5         0.0          1.0   \n",
       "z_przestrzeni_serca     -1.0         1.0       1.0         0.5          1.0   \n",
       "zaradne_warsztaty       -1.0         0.0       0.0         1.0          0.0   \n",
       "\n",
       "                     believe  egocentric  allocentric  \n",
       "id                                                     \n",
       "marek_grodzki            0.5        -1.0         -1.0  \n",
       "vege_style_life          0.0        -1.0          0.5  \n",
       "oliwka__2007            -0.5        -1.0          0.5  \n",
       "z_przestrzeni_serca      1.0        -1.0         -0.5  \n",
       "zaradne_warsztaty        0.5        -0.5          0.5  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table preprocessing - replace all NaN with 2 (Unrelated/Don't know class), replace 0-5 values with the ones in range -1.0 - 1.0\n",
    "arch_df = arch_df.fillna(2.0)\n",
    "\n",
    "arch_df = arch_df.replace(0.0, -1.0)\n",
    "arch_df = arch_df.replace(1.0, -0.5)\n",
    "arch_df = arch_df.replace(2.0, 0.0)\n",
    "arch_df = arch_df.replace(3.0, 0.5)\n",
    "arch_df = arch_df.replace(4.0, 1.0)\n",
    "\n",
    "# Remove duplicated annotations, to exclude conflicting entries\n",
    "arch_df = arch_df[~arch_df.index.duplicated(keep='first')]\n",
    "\n",
    "# Print the head of the dataset after modification\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8659fba-1ad3-4029-aabd-09f24b25a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 39.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile zaradne_warsztaty has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 47.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile ilona_browstylist has no posts.\n",
      "Profile pracownia.lepiej has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:00, 44.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile kamann_living has no posts.\n",
      "Profile natalie_interiors has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:01, 45.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile krewetkowo has no posts.\n",
      "Profile eliza.gwiazda_official has no posts.\n",
      "Profile gettinenglish has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:01, 45.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile paulina.ihnat has no posts.\n",
      "Profile home_in_garden has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [00:01, 44.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile karola_moskal has no posts.\n",
      "Profile wierzbowa_architektura has no posts.\n",
      "Profile justka.ka has no posts.\n",
      "Profile mamologia has no posts.\n",
      "Profile kwejk has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:02, 37.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile swiatwiedzy has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:03, 45.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile klaudia_lasecka has no posts.\n",
      "Profile dom.w.kwiatach has no posts.\n",
      "Profile ak.kingamadej has no posts.\n",
      "Profile owsianapl has no posts.\n",
      "Profile _agnieszka_leszczynska has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [00:03, 45.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile czarna.owieczka has no posts.\n",
      "Profile hellohomla has no posts.\n",
      "Profile kulturoholiczka has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:03, 41.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile aniolnaresorach has no posts.\n",
      "Profile krusia_domatorka has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [00:04, 46.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile gotowanie_po_zmianie has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [00:04, 50.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile ahojprzyrodo has no posts.\n",
      "Profile mr.stejku has no posts.\n",
      "Profile kinianieruda has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [00:04, 42.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile remont_ciala has no posts.\n",
      "Profile cooosure has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [00:05, 54.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile martapazera has no posts.\n",
      "Profile zdrowy_talerz has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [00:05, 56.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile annamboland has no posts.\n",
      "Profile marketing_w_pigulce has no posts.\n",
      "Profile achdeco_polska has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:05, 51.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile imsokayka has no posts.\n",
      "Profile prosto.w.szarosci has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [00:05, 53.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile podroze.rodzinne has no posts.\n",
      "Profile fitbadurka has no posts.\n",
      "Profile panifortuna has no posts.\n",
      "Profile kinga_strzalka has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "277it [00:06, 52.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile gotowe_projekty_domow_archon has no posts.\n",
      "Profile myblogyoll has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289it [00:06, 50.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile zuzia_niemczycka has no posts.\n",
      "Profile justa_w_ogrodzie has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "307it [00:06, 52.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile agiksonn has no posts.\n",
      "Profile 620_nad_poziomem_morza has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:06, 47.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile fit_gruszecka has no posts.\n",
      "Profile wydawnictwoznakpl has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [00:07, 48.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile martynagrajcke has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "332it [00:07, 46.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile staraochota_skrawki has no posts.\n",
      "Profile nabakowskapracowniawnetrz has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "354it [00:07, 43.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile paulinarubaszka has no posts.\n",
      "Profile karolina_er_ has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "383it [00:08, 43.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile aga_bugaj has no posts.\n",
      "Profile lab.07 has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "405it [00:09, 41.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile pani_tester has no posts.\n",
      "Profile blogtasteaway has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "423it [00:09, 50.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile onajedna_home has no posts.\n",
      "Profile languagebay has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "442it [00:09, 56.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile alabasterfox has no posts.\n",
      "Profile aleksandra.herec has no posts.\n",
      "Profile rykalskaa has no posts.\n",
      "Profile domiogrod_przedsnem has no posts.\n",
      "Profile maddlajnn has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [00:10, 44.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile poczujsielepiej has no posts.\n",
      "Profile naszswiatt has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "472it [00:10, 47.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile zdrowoczylisexy has no posts.\n",
      "Profile rutynowa has no posts.\n",
      "Profile aga.lanius has no posts.\n",
      "Profile balickadesign has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [00:11, 55.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile nowinki.sklepowe has no posts.\n",
      "Profile moda_na_klasyki has no posts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [00:11, 45.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Check if a user has a non-empty directory in the dataset, otherwise delete the user from the list\n",
    "available_arch_df = copy.deepcopy(arch_df)\n",
    "posts = []\n",
    "hashtags = []\n",
    "\n",
    "BASE_DIR = \"instagram_dataset/pl\"\n",
    "\n",
    "# Iterate over whole DataFrame\n",
    "for i, row in tqdm(arch_df.iterrows()):\n",
    "    profile_posts = []\n",
    "    profile_hashtags = []\n",
    "    \n",
    "    # Iterate over all categories in base directory\n",
    "    for cat_dir in os.listdir(BASE_DIR):\n",
    "        whole_cat_dir = os.path.join(BASE_DIR, cat_dir)\n",
    "        \n",
    "        # If profile exists in the database\n",
    "        if i in os.listdir(whole_cat_dir):\n",
    "            profile_path = os.path.join(whole_cat_dir, i)\n",
    "            profile_config_path = os.path.join(whole_cat_dir, i, f\"{i}.toml\")\n",
    "            \n",
    "            # Check if there's a .toml file - if not, omit the profile\n",
    "            is_present = False            \n",
    "            if os.path.exists(profile_config_path):\n",
    "                is_present = True\n",
    "                for file in os.listdir(profile_path):\n",
    "                    if not file.endswith(\".toml\"):\n",
    "                        with open(os.path.join(profile_path, file), \"r\") as post_f:\n",
    "                            read_text = post_f.read()\n",
    "                            profile_posts.append(remove_stopwords(clean_up_text(read_text)))\n",
    "                            profile_hashtags.append(extract_hashtags(read_text))\n",
    "            else:\n",
    "                available_arch_df = available_arch_df.drop(i, axis=0)\n",
    "                print(f\"Profile {i} has no posts.\")\n",
    "            # Create new list for a given user    \n",
    "            if is_present:\n",
    "                # Merge lists - a single list for a single influencer\n",
    "                profile_hashtags = list(itertools.chain.from_iterable(profile_hashtags))\n",
    "                hashtags.append(profile_hashtags)\n",
    "                posts.append(list(itertools.chain.from_iterable([profile_posts])))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2006a7b-128b-45db-9115-b79504a4341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     innocent  sage  explorer  outlaw  magician  hero  lover  \\\n",
      "id                                                                             \n",
      "marek_grodzki            -1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
      "vege_style_life          -1.0  -1.0       1.0    -1.0      -1.0  -1.0   -1.0   \n",
      "oliwka__2007             -1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
      "z_przestrzeni_serca       1.0  -1.0      -1.0    -1.0      -1.0  -1.0   -1.0   \n",
      "snatch.machine           -1.0  -0.5       0.5     0.5       0.0   1.0   -1.0   \n",
      "\n",
      "                     jester  everyman  caregiver  ...  protective  generous  \\\n",
      "id                                                ...                         \n",
      "marek_grodzki           1.0      -1.0       -1.0  ...         0.0       0.5   \n",
      "vege_style_life        -1.0      -1.0       -1.0  ...         1.0       1.0   \n",
      "oliwka__2007           -1.0       1.0       -1.0  ...         0.0       0.0   \n",
      "z_przestrzeni_serca    -1.0      -1.0       -1.0  ...         1.0       0.5   \n",
      "snatch.machine         -0.5       0.0       -1.0  ...        -0.5       0.0   \n",
      "\n",
      "                     thrifty  favourable  balanced  sensuality  intelligent  \\\n",
      "id                                                                            \n",
      "marek_grodzki            1.0         1.0       0.5         1.0          1.0   \n",
      "vege_style_life          1.0         1.0       0.5         0.5          0.5   \n",
      "oliwka__2007            -1.0         0.5      -0.5         0.0          1.0   \n",
      "z_przestrzeni_serca     -1.0         1.0       1.0         0.5          1.0   \n",
      "snatch.machine          -0.5         0.5      -0.5        -0.5          0.0   \n",
      "\n",
      "                     believe  egocentric  allocentric  \n",
      "id                                                     \n",
      "marek_grodzki            0.5        -1.0         -1.0  \n",
      "vege_style_life          0.0        -1.0          0.5  \n",
      "oliwka__2007            -0.5        -1.0          0.5  \n",
      "z_przestrzeni_serca      1.0        -1.0         -0.5  \n",
      "snatch.machine          -0.5         0.5         -0.5  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "Available dataset length: 433\n"
     ]
    }
   ],
   "source": [
    "# Show the current, filtered out database\n",
    "print(available_arch_df.head())\n",
    "print(f\"Available dataset length: {len(available_arch_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b962179-b007-40b8-b34f-b9b038576884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map usernames to indices\n",
    "users = list(available_arch_df.index.values)\n",
    "user_indices = {k: users.index(k) for k in users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "098add10-36bb-4a3e-bd87-5b552d6f0b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6171 ms\n",
      " Frequent sequences count : 1862729\n",
      " Max memory (mb) : 1029.111328125\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 1862729\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                         innocent\n",
      "['zainspirowany']                    1.298465e-05\n",
      "['wczorajszym']                      5.193861e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.412996e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  4.845665e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.930397e-06\n",
      "...                                           ...\n",
      "#ì—¬ì„±                                  3.679975e-06\n",
      "#ï¬tnessgirl                          3.679975e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           5.151965e-05\n",
      "#ğğœğ¨ğƒğ²ğ°                              3.679975e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 3.679975e-06\n",
      "\n",
      "[1913357 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–         | 1/37 [00:22<13:33, 22.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 7880 ms\n",
      " Frequent sequences count : 3318340\n",
      " Max memory (mb) : 1131.62109375\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3318340\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                             sage\n",
      "['zainspirowany']                    1.159027e-05\n",
      "['wczorajszym']                      5.505379e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.071720e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.600215e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.657376e-06\n",
      "...                                           ...\n",
      "#Ñ–Ğ½Ñ‚ĞµÑ€                               4.562231e-06\n",
      "#ã­ã“                                  9.124462e-06\n",
      "#çŒ«                                   9.124462e-06\n",
      "#ï¬tnessgirl                          4.562231e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 4.562231e-06\n",
      "\n",
      "[3362192 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 2/37 [01:30<28:48, 49.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6922 ms\n",
      " Frequent sequences count : 3474220\n",
      " Max memory (mb) : 1060.6376953125\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3474220\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                         explorer\n",
      "['zainspirowany']                    1.625472e-05\n",
      "['wczorajszym']                      5.851698e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.364591e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.269538e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.418754e-06\n",
      "...                                           ...\n",
      "#çŒ«                                   8.769122e-06\n",
      "#ï¬tnessgirl                          4.384561e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           4.384561e-05\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                            4.384561e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 4.384561e-06\n",
      "\n",
      "[3519096 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 3/37 [03:23<44:23, 78.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6257 ms\n",
      " Frequent sequences count : 3025204\n",
      " Max memory (mb) : 1024.6738204956055\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3025204\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                           outlaw\n",
      "['zainspirowany']                    1.422910e-05\n",
      "['wczorajszym']                      5.691641e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.762100e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.827676e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.657260e-06\n",
      "...                                           ...\n",
      "#ã­ã“                                  1.000655e-05\n",
      "#çŒ«                                   1.000655e-05\n",
      "#ï¬tnessgirl                          5.003277e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           5.003277e-05\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 5.003277e-06\n",
      "\n",
      "[3067681 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 4/37 [05:14<50:11, 91.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6314 ms\n",
      " Frequent sequences count : 3051974\n",
      " Max memory (mb) : 942.35009765625\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3051974\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                         magician\n",
      "['zainspirowany']                    1.482937e-05\n",
      "['wczorajszym']                      5.931748e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.782643e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.768889e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.669586e-06\n",
      "...                                           ...\n",
      "#çŒ«                                   1.050873e-05\n",
      "#ç¾å°‘å¥³æˆ¦å£«ã‚»ãƒ¼ãƒ©ãƒ¼ãƒ ãƒ¼ãƒ³                        5.254364e-06\n",
      "#ï¬tnessgirl                          5.254364e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           5.254364e-05\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 5.254364e-06\n",
      "\n",
      "[3092284 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 5/37 [07:10<53:25, 100.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6152 ms\n",
      " Frequent sequences count : 3045090\n",
      " Max memory (mb) : 956.677734375\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3045090\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                             hero\n",
      "['zainspirowany']                    1.849530e-05\n",
      "['wczorajszym']                      7.398119e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.810517e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.792890e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.686310e-06\n",
      "...                                           ...\n",
      "#çŒ«                                   1.039652e-05\n",
      "#ï¬tbody                              5.198262e-06\n",
      "#ï¬tnessgirl                          5.198262e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           5.198262e-05\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 5.198262e-06\n",
      "\n",
      "[3084848 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 6/37 [09:01<53:42, 103.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 5447 ms\n",
      " Frequent sequences count : 1684610\n",
      " Max memory (mb) : 1066.08349609375\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 1684610\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                            lover\n",
      "['zainspirowany']                    1.217345e-05\n",
      "['wczorajszym']                      4.565043e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.885330e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  5.350438e-07\n",
      "['wczorajszym', 'innymi']            2.308264e-06\n",
      "...                                           ...\n",
      "#ï¬tfam                               4.215105e-06\n",
      "#ï¬tnessgirl                          4.215105e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           4.215105e-05\n",
      "#ğğœğ¨ğƒğ²ğ°                              4.215105e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 4.215105e-06\n",
      "\n",
      "[1730639 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 7/37 [10:22<48:14, 96.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6130 ms\n",
      " Frequent sequences count : 3220611\n",
      " Max memory (mb) : 937.3232421875\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3220611\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                           jester\n",
      "['zainspirowany']                    1.712851e-05\n",
      "['wczorajszym']                      5.823693e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.545038e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.576034e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.527023e-06\n",
      "...                                           ...\n",
      "#çŒ«                                   9.677076e-06\n",
      "#ï¬tfam                               4.838538e-06\n",
      "#ï¬tnessgirl                          4.838538e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           4.838538e-05\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 4.838538e-06\n",
      "\n",
      "[3263198 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 8/37 [12:07<47:54, 99.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6813 ms\n",
      " Frequent sequences count : 1982895\n",
      " Max memory (mb) : 1155.046875\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 1982895\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                         everyman\n",
      "['zainspirowany']                    1.008090e-05\n",
      "['wczorajszym']                      6.048540e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.243302e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  4.506976e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.794642e-06\n",
      "...                                           ...\n",
      "#ç¾å°‘å¥³æˆ¦å£«ã‚»ãƒ¼ãƒ©ãƒ¼ãƒ ãƒ¼ãƒ³                        3.542005e-06\n",
      "#ì—¬ì„±                                  3.542005e-06\n",
      "#ï¬tnessgirl                          3.542005e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           4.958806e-05\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 3.542005e-06\n",
      "\n",
      "[2033546 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 9/37 [13:23<42:50, 91.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6850 ms\n",
      " Frequent sequences count : 3409258\n",
      " Max memory (mb) : 979.24365234375\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3409258\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                        caregiver\n",
      "['zainspirowany']                    1.215166e-05\n",
      "['wczorajszym']                      5.164458e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.275906e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.379707e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.365544e-06\n",
      "...                                           ...\n",
      "#çŒ«                                   9.038690e-06\n",
      "#é‹¸                                   4.519345e-06\n",
      "#ï¬tnessgirl                          4.519345e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           4.519345e-05\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 4.519345e-06\n",
      "\n",
      "[3453316 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 10/37 [14:59<41:56, 93.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 5625 ms\n",
      " Frequent sequences count : 2845383\n",
      " Max memory (mb) : 939.92236328125\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 2845383\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                            ruler\n",
      "['zainspirowany']                    1.474252e-05\n",
      "['wczorajszym']                      5.897009e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.819134e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  4.015145e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.691481e-06\n",
      "...                                           ...\n",
      "#æœ¨å·¥æ•™å®¤                                5.330178e-06\n",
      "#çŒ«                                   1.066036e-05\n",
      "#é‹¸                                   5.330178e-06\n",
      "#ï¬tnessgirl                          5.330178e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 5.330178e-06\n",
      "\n",
      "[2884646 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–‰       | 11/37 [16:58<43:48, 101.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 5961 ms\n",
      " Frequent sequences count : 3116909\n",
      " Max memory (mb) : 1004.85595703125\n",
      " minsup = 3 sequences.\n",
      " Pattern count : 3116909\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                          creator\n",
      "['zainspirowany']                    1.355128e-05\n",
      "['wczorajszym']                      5.759295e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.647918e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  3.704289e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.588751e-06\n",
      "...                                           ...\n",
      "#ï¬tnessgirl                          4.515509e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           4.515509e-05\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                            4.515509e-06\n",
      "#ğğœğ¨ğƒğ²ğ°                              4.515509e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 4.515509e-06\n",
      "\n",
      "[3160797 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 12/37 [18:46<43:00, 103.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6545 ms\n",
      " Frequent sequences count : 1117635\n",
      " Max memory (mb) : 1224.47900390625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1117635\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            dominant\n",
      "['zainspirowany']           0.000013\n",
      "['wczorajszym']             0.000053\n",
      "['wczorajszym', 'poÅ›cie']   0.000002\n",
      "['wczorajszym', 'przepis']  0.000002\n",
      "['odnoÅ›nie']                0.000096\n",
      "...                              ...\n",
      "#ï¬tnessgirl                 0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                  0.000042\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                   0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                     0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…        0.000003\n",
      "\n",
      "[1175258 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/37 [20:49<43:38, 109.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6731 ms\n",
      " Frequent sequences count : 1143408\n",
      " Max memory (mb) : 1174.66796875\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1143408\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            submissive\n",
      "['zainspirowany']             0.000013\n",
      "['wczorajszym']               0.000050\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000094\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000041\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1202417 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 14/37 [22:54<43:40, 113.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6449 ms\n",
      " Frequent sequences count : 1115610\n",
      " Max memory (mb) : 1156.72900390625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1115610\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            maximalist\n",
      "['zainspirowany']             0.000013\n",
      "['wczorajszym']               0.000055\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000091\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000041\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1173796 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 15/37 [25:01<43:15, 117.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6608 ms\n",
      " Frequent sequences count : 1128848\n",
      " Max memory (mb) : 1152.71923828125\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1128848\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            minimalist\n",
      "['zainspirowany']             0.000013\n",
      "['wczorajszym']               0.000054\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000096\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000042\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1186302 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/37 [27:06<41:58, 119.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6766 ms\n",
      " Frequent sequences count : 1215650\n",
      " Max memory (mb) : 1159.3076171875\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1215650\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            inspiring\n",
      "['zainspirowany']            0.000012\n",
      "['wczorajszym']              0.000054\n",
      "['wczorajszym', 'poÅ›cie']    0.000002\n",
      "['wczorajszym', 'przepis']   0.000002\n",
      "['odnoÅ›nie']                 0.000093\n",
      "...                               ...\n",
      "#ï¬tnessgirl                  0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                   0.000041\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                    0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                      0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…         0.000003\n",
      "\n",
      "[1275002 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 17/37 [29:17<41:03, 123.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6423 ms\n",
      " Frequent sequences count : 1159984\n",
      " Max memory (mb) : 1161.966796875\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1159984\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            systematic\n",
      "['zainspirowany']             0.000013\n",
      "['wczorajszym']               0.000052\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000085\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000043\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1217298 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 18/37 [31:25<39:32, 124.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 7056 ms\n",
      " Frequent sequences count : 1222535\n",
      " Max memory (mb) : 1102.037109375\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1222535\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            discovering\n",
      "['zainspirowany']              0.000012\n",
      "['wczorajszym']                0.000052\n",
      "['wczorajszym', 'poÅ›cie']      0.000002\n",
      "['wczorajszym', 'przepis']     0.000002\n",
      "['odnoÅ›nie']                   0.000092\n",
      "...                                 ...\n",
      "#ï¬tnessgirl                    0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                     0.000040\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                      0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                        0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…           0.000003\n",
      "\n",
      "[1283415 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/37 [33:37<38:02, 126.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 5990 ms\n",
      " Frequent sequences count : 1091872\n",
      " Max memory (mb) : 1241.73291015625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1091872\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            conservative\n",
      "['zainspirowany']               0.000014\n",
      "['wczorajszym']                 0.000052\n",
      "['wczorajszym', 'poÅ›cie']       0.000002\n",
      "['wczorajszym', 'przepis']      0.000002\n",
      "['odnoÅ›nie']                    0.000097\n",
      "...                                  ...\n",
      "#ï¬tnessgirl                     0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                      0.000044\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                       0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                         0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…            0.000003\n",
      "\n",
      "[1148328 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 20/37 [35:41<35:43, 126.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6299 ms\n",
      " Frequent sequences count : 1167901\n",
      " Max memory (mb) : 894.4108734130859\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1167901\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            verifying\n",
      "['zainspirowany']            0.000013\n",
      "['wczorajszym']              0.000053\n",
      "['wczorajszym', 'poÅ›cie']    0.000002\n",
      "['wczorajszym', 'przepis']   0.000002\n",
      "['odnoÅ›nie']                 0.000091\n",
      "...                               ...\n",
      "#ï¬tnessgirl                  0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                   0.000043\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                    0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                      0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…         0.000003\n",
      "\n",
      "[1225118 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 21/37 [37:54<34:10, 128.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6231 ms\n",
      " Frequent sequences count : 1144627\n",
      " Max memory (mb) : 1208.8984375\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1144627\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            overlooking\n",
      "['zainspirowany']              0.000013\n",
      "['wczorajszym']                0.000053\n",
      "['wczorajszym', 'przepis']     0.000002\n",
      "['odnoÅ›nie']                   0.000099\n",
      "['odnoÅ›nie', 'Å¼ycia']          0.000003\n",
      "...                                 ...\n",
      "#ï¬tnessgirl                    0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                     0.000044\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                      0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                        0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…           0.000003\n",
      "\n",
      "[1200713 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 22/37 [40:01<31:58, 127.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6101 ms\n",
      " Frequent sequences count : 1118895\n",
      " Max memory (mb) : 1176.20556640625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1118895\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            sharpening\n",
      "['zainspirowany']             0.000013\n",
      "['wczorajszym']               0.000053\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000098\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000013\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1173796 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/37 [42:07<29:42, 127.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6326 ms\n",
      " Frequent sequences count : 1174126\n",
      " Max memory (mb) : 1121.947265625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1174126\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            harmonic\n",
      "['zainspirowany']           0.000013\n",
      "['wczorajszym']             0.000049\n",
      "['wczorajszym', 'poÅ›cie']   0.000002\n",
      "['wczorajszym', 'przepis']  0.000002\n",
      "['odnoÅ›nie']                0.000092\n",
      "...                              ...\n",
      "#ï¬tnessgirl                 0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                  0.000043\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                   0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                     0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…        0.000003\n",
      "\n",
      "[1232017 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 24/37 [44:18<27:46, 128.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6587 ms\n",
      " Frequent sequences count : 1144450\n",
      " Max memory (mb) : 1168.9755859375\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1144450\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            empathic\n",
      "['zainspirowany']           0.000013\n",
      "['wczorajszym']             0.000051\n",
      "['wczorajszym', 'poÅ›cie']   0.000002\n",
      "['wczorajszym', 'przepis']  0.000002\n",
      "['odnoÅ›nie']                0.000093\n",
      "...                              ...\n",
      "#ï¬tnessgirl                 0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                  0.000042\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                   0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                     0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…        0.000003\n",
      "\n",
      "[1201915 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 25/37 [46:24<25:31, 127.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 8022 ms\n",
      " Frequent sequences count : 2269783\n",
      " Max memory (mb) : 1205.90185546875\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 2269783\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                     matter_of_fact\n",
      "['zainspirowany']                      1.286281e-05\n",
      "['wczorajszym']                        5.145125e-05\n",
      "['wczorajszym', 'poÅ›cie']              1.857884e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']    3.915640e-07\n",
      "['wczorajszym', 'naprawdÄ™']            1.486307e-06\n",
      "...                                             ...\n",
      "#ï¬tnessgirl                            3.227879e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                             4.519030e-05\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                              3.227879e-06\n",
      "#ğğœğ¨ğƒğ²ğ°                                3.227879e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                   3.227879e-06\n",
      "\n",
      "[2324086 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 26/37 [48:28<23:13, 126.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 7245 ms\n",
      " Frequent sequences count : 2030430\n",
      " Max memory (mb) : 1216.26025390625\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 2030430\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                            brave\n",
      "['zainspirowany']                    1.341787e-05\n",
      "['wczorajszym']                      5.590777e-05\n",
      "['wczorajszym', 'poÅ›cie']            2.018550e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  4.479120e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.614840e-06\n",
      "...                                           ...\n",
      "#ï¬tnessgirl                          3.222906e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           1.289162e-05\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                            3.222906e-06\n",
      "#ğğœğ¨ğƒğ²ğ°                              3.222906e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 3.222906e-06\n",
      "\n",
      "[2084627 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 27/37 [50:18<20:16, 121.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 5914 ms\n",
      " Frequent sequences count : 1084519\n",
      " Max memory (mb) : 1218.8056640625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1084519\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                      protective\n",
      "['niezmiennie']         0.000043\n",
      "['nr']                  0.000090\n",
      "['nr', 'nr']            0.000003\n",
      "['ciasto']              0.000703\n",
      "['ciasto', 'ciasto']    0.000072\n",
      "...                          ...\n",
      "#ï¬tnessgirl             0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ              0.000043\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“               0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                 0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…    0.000003\n",
      "\n",
      "[1140164 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 28/37 [52:20<18:14, 121.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6713 ms\n",
      " Frequent sequences count : 2118072\n",
      " Max memory (mb) : 1098.7607421875\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 2118072\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                             generous\n",
      "['zainspirowany']            0.000015\n",
      "['wczorajszym']              0.000058\n",
      "['wczorajszym', 'poÅ›cie']    0.000002\n",
      "['wczorajszym', 'naprawdÄ™']  0.000002\n",
      "['wczorajszym', 'przepis']   0.000002\n",
      "...                               ...\n",
      "#ï¬tfam                       0.000003\n",
      "#ï¬tnessgirl                  0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                   0.000014\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                    0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                      0.000003\n",
      "\n",
      "[2169568 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 29/37 [54:06<15:34, 116.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6836 ms\n",
      " Frequent sequences count : 2115434\n",
      " Max memory (mb) : 1239.5400390625\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 2115434\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                              thrifty\n",
      "['zainspirowany']            0.000014\n",
      "['wczorajszym']              0.000055\n",
      "['wczorajszym', 'poÅ›cie']    0.000002\n",
      "['wczorajszym', 'naprawdÄ™']  0.000002\n",
      "['wczorajszym', 'przepis']   0.000002\n",
      "...                               ...\n",
      "#ï¬tfam                       0.000003\n",
      "#ï¬tnessgirl                  0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                   0.000048\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                    0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                      0.000003\n",
      "\n",
      "[2166705 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 30/37 [55:52<13:15, 113.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6126 ms\n",
      " Frequent sequences count : 1140295\n",
      " Max memory (mb) : 1208.818359375\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1140295\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            favourable\n",
      "['zainspirowany']             0.000013\n",
      "['wczorajszym']               0.000059\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000090\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000030\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1196592 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 31/37 [57:55<11:38, 116.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6179 ms\n",
      " Frequent sequences count : 1092718\n",
      " Max memory (mb) : 1244.75390625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1092718\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            balanced\n",
      "['zainspirowany']           0.000013\n",
      "['wczorajszym']             0.000054\n",
      "['wczorajszym', 'poÅ›cie']   0.000002\n",
      "['wczorajszym', 'przepis']  0.000002\n",
      "['odnoÅ›nie']                0.000094\n",
      "...                              ...\n",
      "#ï¬tnessgirl                 0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                  0.000043\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                   0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                     0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…        0.000003\n",
      "\n",
      "[1149995 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 32/37 [59:59<09:54, 118.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6475 ms\n",
      " Frequent sequences count : 1187423\n",
      " Max memory (mb) : 1197.12744140625\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1187423\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            sensuality\n",
      "['zainspirowany']             0.000012\n",
      "['wczorajszym']               0.000052\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000085\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000041\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1246274 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 33/37 [1:02:06<08:05, 121.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 7809 ms\n",
      " Frequent sequences count : 2253739\n",
      " Max memory (mb) : 1122.96044921875\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 2253739\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                             intelligent\n",
      "['zainspirowany']               0.000013\n",
      "['wczorajszym']                 0.000054\n",
      "['wczorajszym', 'poÅ›cie']       0.000002\n",
      "['wczorajszym', 'naprawdÄ™']     0.000002\n",
      "['wczorajszym', 'przepis']      0.000002\n",
      "...                                  ...\n",
      "#ï¬tfam                          0.000003\n",
      "#ï¬tnessgirl                     0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                      0.000048\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…            0.000003\n",
      "\n",
      "[2306337 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/37 [1:04:08<06:04, 121.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 7450 ms\n",
      " Frequent sequences count : 2141040\n",
      " Max memory (mb) : 1197.59521484375\n",
      " minsup = 4 sequences.\n",
      " Pattern count : 2141040\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                                          believe\n",
      "['zainspirowany']                    1.351147e-05\n",
      "['wczorajszym']                      4.954207e-05\n",
      "['wczorajszym', 'poÅ›cie']            1.981674e-06\n",
      "['wczorajszym', 'poÅ›cie', 'innymi']  4.193610e-07\n",
      "['wczorajszym', 'naprawdÄ™']          1.585339e-06\n",
      "...                                           ...\n",
      "#ï¬tnessgirl                          3.349455e-06\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                           4.689238e-05\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                            3.349455e-06\n",
      "#ğğœğ¨ğƒğ²ğ°                              3.349455e-06\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…                 3.349455e-06\n",
      "\n",
      "[2193611 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 35/37 [1:05:54<03:53, 116.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6317 ms\n",
      " Frequent sequences count : 1156266\n",
      " Max memory (mb) : 1158.98095703125\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1156266\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            egocentric\n",
      "['zainspirowany']             0.000013\n",
      "['wczorajszym']               0.000051\n",
      "['wczorajszym', 'poÅ›cie']     0.000002\n",
      "['wczorajszym', 'przepis']    0.000002\n",
      "['odnoÅ›nie']                  0.000094\n",
      "...                                ...\n",
      "#ï¬tnessgirl                   0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                    0.000042\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                     0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                       0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…          0.000003\n",
      "\n",
      "[1213760 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 36/37 [1:08:01<01:59, 119.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 6562 ms\n",
      " Frequent sequences count : 1164640\n",
      " Max memory (mb) : 1242.158203125\n",
      " minsup = 5 sequences.\n",
      " Pattern count : 1164640\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n",
      "                            allocentric\n",
      "['zainspirowany']              0.000013\n",
      "['wczorajszym']                0.000051\n",
      "['wczorajszym', 'poÅ›cie']      0.000002\n",
      "['wczorajszym', 'przepis']     0.000002\n",
      "['odnoÅ›nie']                   0.000090\n",
      "...                                 ...\n",
      "#ï¬tnessgirl                    0.000003\n",
      "#ï½ï½…ï½“ï½”ï½ˆï½…ï½”ï½‰ï½ƒ                     0.000042\n",
      "#ï½”ï½ˆï½ï½•ï½‡ï½ˆï½”ï½“                      0.000003\n",
      "#ğğœğ¨ğƒğ²ğ°                        0.000003\n",
      "#ğ• ğ•”ğ•™ğ•›ğ•’ğ•œğ•—ğ•’ğ•›ğ•Ÿğ•šğ•–ğ•“ğ•ªÄ‡ğ•ğ•’ğ•Ä…           0.000003\n",
      "\n",
      "[1221534 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [1:10:13<00:00, 113.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get the word count and create a dataframe, where columns are archetypes/traits, and rows are single words\n",
    "# Initialize a word DataFrame\n",
    "word_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over all of the traits/archetypes\n",
    "for trait in tqdm(trait_list):\n",
    "    # Test procedure for a single trait\n",
    "    subset_df = available_arch_df[available_arch_df[trait] != 0][trait]\n",
    "    subset_indices = [user_indices[idx] for idx in subset_df.index.values]\n",
    "\n",
    "    # Get all posts for the list of influencers\n",
    "    f = operator.itemgetter(*subset_indices)\n",
    "    sublist = list(f(posts))\n",
    "    post_list = []\n",
    "    for user in sublist:\n",
    "        for post in user:\n",
    "            post_list.append(\" \".join(post))\n",
    "\n",
    "    # SPMF - get the most frequent sequences\n",
    "    spmf = Spmf(\"PrefixSpan\", input_direct=post_list,\n",
    "                output_filename=\"output.txt\", arguments=[0.00025, 3], input_type=\"text\")\n",
    "    spmf.run()\n",
    "    spmf_df = spmf.to_pandas_dataframe(pickle=False)\n",
    "\n",
    "    # Normalize the data for all lengths\n",
    "    spmf_df.loc[spmf_df[\"pattern\"].map(len) == 3, \"sup\"] = spmf_df.loc[spmf_df[\"pattern\"].map(len) == 3].sup / spmf_df[spmf_df[\"pattern\"].map(len) == 3][\"sup\"].sum()\n",
    "    spmf_df.loc[spmf_df[\"pattern\"].map(len) == 2, \"sup\"] = spmf_df.loc[spmf_df[\"pattern\"].map(len) == 2].sup / spmf_df[spmf_df[\"pattern\"].map(len) == 2][\"sup\"].sum()\n",
    "    spmf_df.loc[spmf_df[\"pattern\"].map(len) == 1, \"sup\"] = spmf_df.loc[spmf_df[\"pattern\"].map(len) == 1].sup / spmf_df[spmf_df[\"pattern\"].map(len) == 1][\"sup\"].sum()\n",
    "\n",
    "    # Convert lists to tuples\n",
    "    spmf_df[\"pattern\"] = spmf_df[\"pattern\"].apply(lambda x: str(x))\n",
    "\n",
    "    sublist = list(f(hashtags))\n",
    "\n",
    "    # Counter to calculate each word occurrences\n",
    "    sublist = list(itertools.chain.from_iterable(sublist))\n",
    "    trait_ctr = Counter(sublist)\n",
    "    trait_total = sum(trait_ctr.values())\n",
    "    trait_ctr = {k: float(v / trait_total) for k, v in trait_ctr.items() if v >= 1}\n",
    "    trait_ctr = {trait: trait_ctr}\n",
    "\n",
    "    tmp_df = pd.DataFrame.from_dict(trait_ctr, orient=\"columns\")\n",
    "\n",
    "    # Change column name\n",
    "    spmf_df = spmf_df.rename(columns={\"sup\": trait})\n",
    "\n",
    "    # Change index to pattern\n",
    "    spmf_df = spmf_df.reset_index(drop=True)\n",
    "    spmf_df = spmf_df.set_index(\"pattern\")\n",
    "\n",
    "    # Append the hashtags\n",
    "    spmf_df = spmf_df.append(tmp_df)\n",
    "    print(spmf_df)\n",
    "\n",
    "    spmf_df = spmf_df.transpose()\n",
    "    spmf_df.to_pickle(f\"dfs/{trait}.pickle\")\n",
    "\n",
    "    # Append the dataframe to word_df\n",
    "    word_df = word_df.append(spmf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99c6bf53-495a-413a-a9bd-f036af42a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word_df to file\n",
    "word_df.to_pickle(\"word_trait_array.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fab531b-f50c-4900-a7df-6c1364f4aa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>['zainspirowany']</th>\n",
       "      <th>['wczorajszym']</th>\n",
       "      <th>['wczorajszym', 'poÅ›cie']</th>\n",
       "      <th>['wczorajszym', 'poÅ›cie', 'innymi']</th>\n",
       "      <th>['wczorajszym', 'naprawdÄ™']</th>\n",
       "      <th>['wczorajszym', 'przepis']</th>\n",
       "      <th>['wczorajszym', 'innymi']</th>\n",
       "      <th>['odnoÅ›nie']</th>\n",
       "      <th>['odnoÅ›nie', 'Å¼ycia']</th>\n",
       "      <th>['odnoÅ›nie', 'naprawdÄ™']</th>\n",
       "      <th>...</th>\n",
       "      <th>['podkÅ‚ad', 'serii']</th>\n",
       "      <th>['konkursu', 'udziaÅ‚', 'nagrody']</th>\n",
       "      <th>['this', 'hope', 'you']</th>\n",
       "      <th>['zadowolony', 'temu']</th>\n",
       "      <th>['przeczytaniu', 'czytajÄ…c']</th>\n",
       "      <th>['potoczÄ…', 'czekam']</th>\n",
       "      <th>['help', 'and', 'with']</th>\n",
       "      <th>['noszenia', 'maseczek']</th>\n",
       "      <th>['best', 'much']</th>\n",
       "      <th>['care', 'it']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>innocent</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.845665e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sage</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.600215e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explorer</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.269538e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlaw</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.827676e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magician</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.768889e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hero</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.792890e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lover</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.350438e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jester</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.576034e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everyman</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.506976e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caregiver</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.379707e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruler</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.015145e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creator</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.704289e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominant</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submissive</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximalist</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimalist</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inspiring</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systematic</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discovering</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verifying</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overlooking</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharpening</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harmonic</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empathic</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matter_of_fact</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.915640e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brave</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.479120e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protective</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generous</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thrifty</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favourable</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensuality</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intelligent</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>believe</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.193610e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.193610e-07</td>\n",
       "      <td>4.193610e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.193610e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>egocentric</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allocentric</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows Ã— 4745869 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ['zainspirowany']  ['wczorajszym']  ['wczorajszym', 'poÅ›cie']  \\\n",
       "innocent                 0.000013         0.000052                   0.000002   \n",
       "sage                     0.000012         0.000055                   0.000002   \n",
       "explorer                 0.000016         0.000059                   0.000002   \n",
       "outlaw                   0.000014         0.000057                   0.000003   \n",
       "magician                 0.000015         0.000059                   0.000003   \n",
       "hero                     0.000018         0.000074                   0.000003   \n",
       "lover                    0.000012         0.000046                   0.000003   \n",
       "jester                   0.000017         0.000058                   0.000003   \n",
       "everyman                 0.000010         0.000060                   0.000002   \n",
       "caregiver                0.000012         0.000052                   0.000002   \n",
       "ruler                    0.000015         0.000059                   0.000003   \n",
       "creator                  0.000014         0.000058                   0.000003   \n",
       "dominant                 0.000013         0.000053                   0.000002   \n",
       "submissive               0.000013         0.000050                   0.000002   \n",
       "maximalist               0.000013         0.000055                   0.000002   \n",
       "minimalist               0.000013         0.000054                   0.000002   \n",
       "inspiring                0.000012         0.000054                   0.000002   \n",
       "systematic               0.000013         0.000052                   0.000002   \n",
       "discovering              0.000012         0.000052                   0.000002   \n",
       "conservative             0.000014         0.000052                   0.000002   \n",
       "verifying                0.000013         0.000053                   0.000002   \n",
       "overlooking              0.000013         0.000053                   0.000000   \n",
       "sharpening               0.000013         0.000053                   0.000002   \n",
       "harmonic                 0.000013         0.000049                   0.000002   \n",
       "empathic                 0.000013         0.000051                   0.000002   \n",
       "matter_of_fact           0.000013         0.000051                   0.000002   \n",
       "brave                    0.000013         0.000056                   0.000002   \n",
       "protective               0.000011         0.000049                   0.000002   \n",
       "generous                 0.000015         0.000058                   0.000002   \n",
       "thrifty                  0.000014         0.000055                   0.000002   \n",
       "favourable               0.000013         0.000059                   0.000002   \n",
       "balanced                 0.000013         0.000054                   0.000002   \n",
       "sensuality               0.000012         0.000052                   0.000002   \n",
       "intelligent              0.000013         0.000054                   0.000002   \n",
       "believe                  0.000014         0.000050                   0.000002   \n",
       "egocentric               0.000013         0.000051                   0.000002   \n",
       "allocentric              0.000013         0.000051                   0.000002   \n",
       "\n",
       "                ['wczorajszym', 'poÅ›cie', 'innymi']  \\\n",
       "innocent                               4.845665e-07   \n",
       "sage                                   3.600215e-07   \n",
       "explorer                               3.269538e-07   \n",
       "outlaw                                 3.827676e-07   \n",
       "magician                               3.768889e-07   \n",
       "hero                                   3.792890e-07   \n",
       "lover                                  5.350438e-07   \n",
       "jester                                 3.576034e-07   \n",
       "everyman                               4.506976e-07   \n",
       "caregiver                              3.379707e-07   \n",
       "ruler                                  4.015145e-07   \n",
       "creator                                3.704289e-07   \n",
       "dominant                               0.000000e+00   \n",
       "submissive                             0.000000e+00   \n",
       "maximalist                             0.000000e+00   \n",
       "minimalist                             0.000000e+00   \n",
       "inspiring                              0.000000e+00   \n",
       "systematic                             0.000000e+00   \n",
       "discovering                            0.000000e+00   \n",
       "conservative                           0.000000e+00   \n",
       "verifying                              0.000000e+00   \n",
       "overlooking                            0.000000e+00   \n",
       "sharpening                             0.000000e+00   \n",
       "harmonic                               0.000000e+00   \n",
       "empathic                               0.000000e+00   \n",
       "matter_of_fact                         3.915640e-07   \n",
       "brave                                  4.479120e-07   \n",
       "protective                             0.000000e+00   \n",
       "generous                               0.000000e+00   \n",
       "thrifty                                0.000000e+00   \n",
       "favourable                             0.000000e+00   \n",
       "balanced                               0.000000e+00   \n",
       "sensuality                             0.000000e+00   \n",
       "intelligent                            0.000000e+00   \n",
       "believe                                4.193610e-07   \n",
       "egocentric                             0.000000e+00   \n",
       "allocentric                            0.000000e+00   \n",
       "\n",
       "                ['wczorajszym', 'naprawdÄ™']  ['wczorajszym', 'przepis']  \\\n",
       "innocent                           0.000002                    0.000002   \n",
       "sage                               0.000002                    0.000001   \n",
       "explorer                           0.000001                    0.000000   \n",
       "outlaw                             0.000002                    0.000000   \n",
       "magician                           0.000002                    0.000000   \n",
       "hero                               0.000002                    0.000000   \n",
       "lover                              0.000000                    0.000000   \n",
       "jester                             0.000002                    0.000000   \n",
       "everyman                           0.000002                    0.000002   \n",
       "caregiver                          0.000001                    0.000000   \n",
       "ruler                              0.000002                    0.000000   \n",
       "creator                            0.000002                    0.000000   \n",
       "dominant                           0.000000                    0.000002   \n",
       "submissive                         0.000000                    0.000002   \n",
       "maximalist                         0.000000                    0.000002   \n",
       "minimalist                         0.000000                    0.000002   \n",
       "inspiring                          0.000000                    0.000002   \n",
       "systematic                         0.000000                    0.000002   \n",
       "discovering                        0.000000                    0.000002   \n",
       "conservative                       0.000000                    0.000002   \n",
       "verifying                          0.000000                    0.000002   \n",
       "overlooking                        0.000000                    0.000002   \n",
       "sharpening                         0.000000                    0.000002   \n",
       "harmonic                           0.000000                    0.000002   \n",
       "empathic                           0.000000                    0.000002   \n",
       "matter_of_fact                     0.000001                    0.000002   \n",
       "brave                              0.000002                    0.000002   \n",
       "protective                         0.000000                    0.000002   \n",
       "generous                           0.000002                    0.000002   \n",
       "thrifty                            0.000002                    0.000002   \n",
       "favourable                         0.000000                    0.000002   \n",
       "balanced                           0.000000                    0.000002   \n",
       "sensuality                         0.000000                    0.000002   \n",
       "intelligent                        0.000002                    0.000002   \n",
       "believe                            0.000002                    0.000002   \n",
       "egocentric                         0.000000                    0.000002   \n",
       "allocentric                        0.000000                    0.000002   \n",
       "\n",
       "                ['wczorajszym', 'innymi']  ['odnoÅ›nie']  \\\n",
       "innocent                         0.000002      0.000081   \n",
       "sage                             0.000002      0.000113   \n",
       "explorer                         0.000002      0.000088   \n",
       "outlaw                           0.000002      0.000096   \n",
       "magician                         0.000002      0.000100   \n",
       "hero                             0.000002      0.000081   \n",
       "lover                            0.000002      0.000085   \n",
       "jester                           0.000002      0.000092   \n",
       "everyman                         0.000002      0.000093   \n",
       "caregiver                        0.000002      0.000106   \n",
       "ruler                            0.000002      0.000100   \n",
       "creator                          0.000002      0.000091   \n",
       "dominant                         0.000000      0.000096   \n",
       "submissive                       0.000000      0.000094   \n",
       "maximalist                       0.000000      0.000091   \n",
       "minimalist                       0.000000      0.000096   \n",
       "inspiring                        0.000000      0.000093   \n",
       "systematic                       0.000000      0.000085   \n",
       "discovering                      0.000000      0.000092   \n",
       "conservative                     0.000000      0.000097   \n",
       "verifying                        0.000000      0.000091   \n",
       "overlooking                      0.000000      0.000099   \n",
       "sharpening                       0.000000      0.000098   \n",
       "harmonic                         0.000000      0.000092   \n",
       "empathic                         0.000000      0.000093   \n",
       "matter_of_fact                   0.000001      0.000088   \n",
       "brave                            0.000002      0.000096   \n",
       "protective                       0.000000      0.000090   \n",
       "generous                         0.000000      0.000075   \n",
       "thrifty                          0.000000      0.000086   \n",
       "favourable                       0.000000      0.000090   \n",
       "balanced                         0.000000      0.000094   \n",
       "sensuality                       0.000000      0.000085   \n",
       "intelligent                      0.000000      0.000081   \n",
       "believe                          0.000002      0.000095   \n",
       "egocentric                       0.000000      0.000094   \n",
       "allocentric                      0.000000      0.000090   \n",
       "\n",
       "                ['odnoÅ›nie', 'Å¼ycia']  ['odnoÅ›nie', 'naprawdÄ™']  ...  \\\n",
       "innocent                     0.000002                  0.000003  ...   \n",
       "sage                         0.000003                  0.000002  ...   \n",
       "explorer                     0.000002                  0.000003  ...   \n",
       "outlaw                       0.000003                  0.000003  ...   \n",
       "magician                     0.000003                  0.000003  ...   \n",
       "hero                         0.000003                  0.000002  ...   \n",
       "lover                        0.000003                  0.000003  ...   \n",
       "jester                       0.000003                  0.000003  ...   \n",
       "everyman                     0.000003                  0.000003  ...   \n",
       "caregiver                    0.000003                  0.000003  ...   \n",
       "ruler                        0.000003                  0.000003  ...   \n",
       "creator                      0.000003                  0.000003  ...   \n",
       "dominant                     0.000003                  0.000003  ...   \n",
       "submissive                   0.000003                  0.000003  ...   \n",
       "maximalist                   0.000003                  0.000003  ...   \n",
       "minimalist                   0.000003                  0.000003  ...   \n",
       "inspiring                    0.000003                  0.000003  ...   \n",
       "systematic                   0.000003                  0.000000  ...   \n",
       "discovering                  0.000003                  0.000002  ...   \n",
       "conservative                 0.000003                  0.000003  ...   \n",
       "verifying                    0.000003                  0.000003  ...   \n",
       "overlooking                  0.000003                  0.000003  ...   \n",
       "sharpening                   0.000003                  0.000003  ...   \n",
       "harmonic                     0.000003                  0.000003  ...   \n",
       "empathic                     0.000003                  0.000003  ...   \n",
       "matter_of_fact               0.000002                  0.000002  ...   \n",
       "brave                        0.000002                  0.000002  ...   \n",
       "protective                   0.000002                  0.000000  ...   \n",
       "generous                     0.000002                  0.000000  ...   \n",
       "thrifty                      0.000002                  0.000002  ...   \n",
       "favourable                   0.000003                  0.000000  ...   \n",
       "balanced                     0.000003                  0.000003  ...   \n",
       "sensuality                   0.000003                  0.000000  ...   \n",
       "intelligent                  0.000002                  0.000000  ...   \n",
       "believe                      0.000003                  0.000002  ...   \n",
       "egocentric                   0.000003                  0.000003  ...   \n",
       "allocentric                  0.000003                  0.000003  ...   \n",
       "\n",
       "                ['podkÅ‚ad', 'serii']  ['konkursu', 'udziaÅ‚', 'nagrody']  \\\n",
       "innocent                    0.000000                       0.000000e+00   \n",
       "sage                        0.000000                       0.000000e+00   \n",
       "explorer                    0.000000                       0.000000e+00   \n",
       "outlaw                      0.000000                       0.000000e+00   \n",
       "magician                    0.000000                       0.000000e+00   \n",
       "hero                        0.000000                       0.000000e+00   \n",
       "lover                       0.000000                       0.000000e+00   \n",
       "jester                      0.000000                       0.000000e+00   \n",
       "everyman                    0.000000                       0.000000e+00   \n",
       "caregiver                   0.000000                       0.000000e+00   \n",
       "ruler                       0.000000                       0.000000e+00   \n",
       "creator                     0.000000                       0.000000e+00   \n",
       "dominant                    0.000000                       0.000000e+00   \n",
       "submissive                  0.000000                       0.000000e+00   \n",
       "maximalist                  0.000000                       0.000000e+00   \n",
       "minimalist                  0.000000                       0.000000e+00   \n",
       "inspiring                   0.000000                       0.000000e+00   \n",
       "systematic                  0.000000                       0.000000e+00   \n",
       "discovering                 0.000000                       0.000000e+00   \n",
       "conservative                0.000000                       0.000000e+00   \n",
       "verifying                   0.000000                       0.000000e+00   \n",
       "overlooking                 0.000000                       0.000000e+00   \n",
       "sharpening                  0.000000                       0.000000e+00   \n",
       "harmonic                    0.000000                       0.000000e+00   \n",
       "empathic                    0.000000                       0.000000e+00   \n",
       "matter_of_fact              0.000000                       0.000000e+00   \n",
       "brave                       0.000000                       0.000000e+00   \n",
       "protective                  0.000000                       0.000000e+00   \n",
       "generous                    0.000000                       0.000000e+00   \n",
       "thrifty                     0.000000                       0.000000e+00   \n",
       "favourable                  0.000000                       0.000000e+00   \n",
       "balanced                    0.000000                       0.000000e+00   \n",
       "sensuality                  0.000000                       0.000000e+00   \n",
       "intelligent                 0.000000                       0.000000e+00   \n",
       "believe                     0.000002                       4.193610e-07   \n",
       "egocentric                  0.000000                       0.000000e+00   \n",
       "allocentric                 0.000000                       0.000000e+00   \n",
       "\n",
       "                ['this', 'hope', 'you']  ['zadowolony', 'temu']  \\\n",
       "innocent                   0.000000e+00                0.000000   \n",
       "sage                       0.000000e+00                0.000000   \n",
       "explorer                   0.000000e+00                0.000000   \n",
       "outlaw                     0.000000e+00                0.000000   \n",
       "magician                   0.000000e+00                0.000000   \n",
       "hero                       0.000000e+00                0.000000   \n",
       "lover                      0.000000e+00                0.000000   \n",
       "jester                     0.000000e+00                0.000000   \n",
       "everyman                   0.000000e+00                0.000000   \n",
       "caregiver                  0.000000e+00                0.000000   \n",
       "ruler                      0.000000e+00                0.000000   \n",
       "creator                    0.000000e+00                0.000000   \n",
       "dominant                   0.000000e+00                0.000000   \n",
       "submissive                 0.000000e+00                0.000000   \n",
       "maximalist                 0.000000e+00                0.000000   \n",
       "minimalist                 0.000000e+00                0.000000   \n",
       "inspiring                  0.000000e+00                0.000000   \n",
       "systematic                 0.000000e+00                0.000000   \n",
       "discovering                0.000000e+00                0.000000   \n",
       "conservative               0.000000e+00                0.000000   \n",
       "verifying                  0.000000e+00                0.000000   \n",
       "overlooking                0.000000e+00                0.000000   \n",
       "sharpening                 0.000000e+00                0.000000   \n",
       "harmonic                   0.000000e+00                0.000000   \n",
       "empathic                   0.000000e+00                0.000000   \n",
       "matter_of_fact             0.000000e+00                0.000000   \n",
       "brave                      0.000000e+00                0.000000   \n",
       "protective                 0.000000e+00                0.000000   \n",
       "generous                   0.000000e+00                0.000000   \n",
       "thrifty                    0.000000e+00                0.000000   \n",
       "favourable                 0.000000e+00                0.000000   \n",
       "balanced                   0.000000e+00                0.000000   \n",
       "sensuality                 0.000000e+00                0.000000   \n",
       "intelligent                0.000000e+00                0.000000   \n",
       "believe                    4.193610e-07                0.000002   \n",
       "egocentric                 0.000000e+00                0.000000   \n",
       "allocentric                0.000000e+00                0.000000   \n",
       "\n",
       "                ['przeczytaniu', 'czytajÄ…c']  ['potoczÄ…', 'czekam']  \\\n",
       "innocent                            0.000000               0.000000   \n",
       "sage                                0.000000               0.000000   \n",
       "explorer                            0.000000               0.000000   \n",
       "outlaw                              0.000000               0.000000   \n",
       "magician                            0.000000               0.000000   \n",
       "hero                                0.000000               0.000000   \n",
       "lover                               0.000000               0.000000   \n",
       "jester                              0.000000               0.000000   \n",
       "everyman                            0.000000               0.000000   \n",
       "caregiver                           0.000000               0.000000   \n",
       "ruler                               0.000000               0.000000   \n",
       "creator                             0.000000               0.000000   \n",
       "dominant                            0.000000               0.000000   \n",
       "submissive                          0.000000               0.000000   \n",
       "maximalist                          0.000000               0.000000   \n",
       "minimalist                          0.000000               0.000000   \n",
       "inspiring                           0.000000               0.000000   \n",
       "systematic                          0.000000               0.000000   \n",
       "discovering                         0.000000               0.000000   \n",
       "conservative                        0.000000               0.000000   \n",
       "verifying                           0.000000               0.000000   \n",
       "overlooking                         0.000000               0.000000   \n",
       "sharpening                          0.000000               0.000000   \n",
       "harmonic                            0.000000               0.000000   \n",
       "empathic                            0.000000               0.000000   \n",
       "matter_of_fact                      0.000000               0.000000   \n",
       "brave                               0.000000               0.000000   \n",
       "protective                          0.000000               0.000000   \n",
       "generous                            0.000000               0.000000   \n",
       "thrifty                             0.000000               0.000000   \n",
       "favourable                          0.000000               0.000000   \n",
       "balanced                            0.000000               0.000000   \n",
       "sensuality                          0.000000               0.000000   \n",
       "intelligent                         0.000000               0.000000   \n",
       "believe                             0.000002               0.000002   \n",
       "egocentric                          0.000000               0.000000   \n",
       "allocentric                         0.000000               0.000000   \n",
       "\n",
       "                ['help', 'and', 'with']  ['noszenia', 'maseczek']  \\\n",
       "innocent                   0.000000e+00                  0.000000   \n",
       "sage                       0.000000e+00                  0.000000   \n",
       "explorer                   0.000000e+00                  0.000000   \n",
       "outlaw                     0.000000e+00                  0.000000   \n",
       "magician                   0.000000e+00                  0.000000   \n",
       "hero                       0.000000e+00                  0.000000   \n",
       "lover                      0.000000e+00                  0.000000   \n",
       "jester                     0.000000e+00                  0.000000   \n",
       "everyman                   0.000000e+00                  0.000000   \n",
       "caregiver                  0.000000e+00                  0.000000   \n",
       "ruler                      0.000000e+00                  0.000000   \n",
       "creator                    0.000000e+00                  0.000000   \n",
       "dominant                   0.000000e+00                  0.000000   \n",
       "submissive                 0.000000e+00                  0.000000   \n",
       "maximalist                 0.000000e+00                  0.000000   \n",
       "minimalist                 0.000000e+00                  0.000000   \n",
       "inspiring                  0.000000e+00                  0.000000   \n",
       "systematic                 0.000000e+00                  0.000000   \n",
       "discovering                0.000000e+00                  0.000000   \n",
       "conservative               0.000000e+00                  0.000000   \n",
       "verifying                  0.000000e+00                  0.000000   \n",
       "overlooking                0.000000e+00                  0.000000   \n",
       "sharpening                 0.000000e+00                  0.000000   \n",
       "harmonic                   0.000000e+00                  0.000000   \n",
       "empathic                   0.000000e+00                  0.000000   \n",
       "matter_of_fact             0.000000e+00                  0.000000   \n",
       "brave                      0.000000e+00                  0.000000   \n",
       "protective                 0.000000e+00                  0.000000   \n",
       "generous                   0.000000e+00                  0.000000   \n",
       "thrifty                    0.000000e+00                  0.000000   \n",
       "favourable                 0.000000e+00                  0.000000   \n",
       "balanced                   0.000000e+00                  0.000000   \n",
       "sensuality                 0.000000e+00                  0.000000   \n",
       "intelligent                0.000000e+00                  0.000000   \n",
       "believe                    4.193610e-07                  0.000002   \n",
       "egocentric                 0.000000e+00                  0.000000   \n",
       "allocentric                0.000000e+00                  0.000000   \n",
       "\n",
       "                ['best', 'much']  ['care', 'it']  \n",
       "innocent                0.000000        0.000000  \n",
       "sage                    0.000000        0.000000  \n",
       "explorer                0.000000        0.000000  \n",
       "outlaw                  0.000000        0.000000  \n",
       "magician                0.000000        0.000000  \n",
       "hero                    0.000000        0.000000  \n",
       "lover                   0.000000        0.000000  \n",
       "jester                  0.000000        0.000000  \n",
       "everyman                0.000000        0.000000  \n",
       "caregiver               0.000000        0.000000  \n",
       "ruler                   0.000000        0.000000  \n",
       "creator                 0.000000        0.000000  \n",
       "dominant                0.000000        0.000000  \n",
       "submissive              0.000000        0.000000  \n",
       "maximalist              0.000000        0.000000  \n",
       "minimalist              0.000000        0.000000  \n",
       "inspiring               0.000000        0.000000  \n",
       "systematic              0.000000        0.000000  \n",
       "discovering             0.000000        0.000000  \n",
       "conservative            0.000000        0.000000  \n",
       "verifying               0.000000        0.000000  \n",
       "overlooking             0.000000        0.000000  \n",
       "sharpening              0.000000        0.000000  \n",
       "harmonic                0.000000        0.000000  \n",
       "empathic                0.000000        0.000000  \n",
       "matter_of_fact          0.000000        0.000000  \n",
       "brave                   0.000000        0.000000  \n",
       "protective              0.000000        0.000000  \n",
       "generous                0.000000        0.000000  \n",
       "thrifty                 0.000000        0.000000  \n",
       "favourable              0.000000        0.000000  \n",
       "balanced                0.000000        0.000000  \n",
       "sensuality              0.000000        0.000000  \n",
       "intelligent             0.000000        0.000000  \n",
       "believe                 0.000002        0.000002  \n",
       "egocentric              0.000000        0.000000  \n",
       "allocentric             0.000000        0.000000  \n",
       "\n",
       "[37 rows x 4745869 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the resulting DataFrame\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cf89527-553f-4c26-8880-64e2b86e84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all NaN with 0.0\n",
    "word_df = word_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21c13154-632f-413b-aac8-b228bd4e119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save non-NaN word_df to file\n",
    "word_df.to_pickle(\"word_trait_array_no_nan.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8cefb12-2f38-45da-af10-11aa81a4f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a pickle\n",
    "import pickle\n",
    "\n",
    "with open(\"influencer_index_map.pickle\", \"wb\") as f:\n",
    "    pickle.dump(user_indices, f)\n",
    "    \n",
    "word_df.to_pickle(\"word_frequency_table.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "679da2ad-180c-4e09-95e7-1ff94de16431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating an output vector for dot product calculation\n",
    "# Word map - to easily create output vectors\n",
    "word_map = word_df.columns.tolist()\n",
    "\n",
    "def get_trait_dot_product(post_text: str, word_map: list, word_dataframe: pd.DataFrame) -> list:\n",
    "    # Filter out the text\n",
    "    filtered_post = remove_stopwords(clean_up_text(post_text))\n",
    "    \n",
    "    filtered_post = [\" \".join(pst) for pst in filtered_post]\n",
    "    filtered_post.extend(extract_hashtags(post_text))\n",
    "    \n",
    "    # Create a vector for dot product vector\n",
    "    post_vector = [0] * len(word_map)\n",
    "    \n",
    "    # Calculate word occurrences\n",
    "    spmf = Spmf(\"PrefixSpan\", input_direct=filtered_post,\n",
    "                output_filename=\"output.txt\", arguments=[0.00025, 3], input_type=\"text\")\n",
    "    spmf.run()\n",
    "    spmf_df = spmf.to_pandas_dataframe(pickle=False)\n",
    "    \n",
    "    for idx, row in tqdm(spmf_df.iterrows()):\n",
    "        phrase = str(row[\"pattern\"])\n",
    "        freq = int(row[\"sup\"])\n",
    "        try:\n",
    "            post_vector[word_map.index(phrase)] = freq\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Calculate dot product for a given text\n",
    "    word_dot = word_dataframe.dot(post_vector)\n",
    "    return word_dot.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a38b7660-1342-4b4a-afdc-d15d0c8734c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 2 ms\n",
      " Frequent sequences count : 85\n",
      " Max memory (mb) : 8.991737365722656\n",
      " minsup = 1 sequences.\n",
      " Pattern count : 85\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:07, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00016620354740696497, 0.00012749299512918806, 0.0001690490664915492, 0.00014584830353522058, 0.0001594157228390828, 0.00015536049182692842, 0.00018260170915199766, 0.00016443368012853234, 0.00016633483706746642, 0.00010936498436992098, 0.00015111084902183367, 0.00016939103921402557, 0.00017278599281551573, 0.0001591613036986155, 0.00017426378862227474, 0.00016502322112468682, 0.0001605453602390891, 0.0001723152627698697, 0.0001679472645589285, 0.00016507620641309755, 0.00016276248092296895, 0.00015667617021652205, 0.00016640781007321942, 0.00016311498103788345, 0.00015501571392168522, 0.00015649754213106778, 0.00016995963458678562, 0.00016629475070394366, 0.00018173183166301588, 0.00018088433398864235, 0.00015980665583775904, 0.00016073035875016072, 0.00016210352180292368, 0.00014350258416762895, 0.00015313004569130333, 0.00017351924885445163, 0.00015830908779736435]\n"
     ]
    }
   ],
   "source": [
    "# Test the trait dot_product\n",
    "print(get_trait_dot_product(\"CzeÅ›Ä‡ reasda  asdasda         #hello #man\", word_map, word_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e3a8543-ded4-4807-8999-d9c68c4910ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating the dot product of trait <-> influencer relation\n",
    "def get_influencer_dot_product(trait_output: list, influencer_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    return influencer_dataframe.dot(trait_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2189d6d6-5ecd-4898-a47d-d849e61db033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating the similarity\n",
    "def calculate_similarity(post_text: str, \n",
    "                         word_map: list, \n",
    "                         word_dataframe: pd.DataFrame,\n",
    "                         influencer_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Calculate word-trait dot product\n",
    "    post_result = get_trait_dot_product(post_text, word_map, word_dataframe)\n",
    "    \n",
    "    # Calculate trate-influencer dot-product\n",
    "    return get_influencer_dot_product(post_result, influencer_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae883b94-1542-4a70-9368-d97bc5690edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/media/maciek/HDD_Linux/Praca_magisterska/instagram_analysis/spmf.jar\n",
      "Converting TEXT to SPMF format.\n",
      "Conversion completed.\n",
      "=============  PREFIXSPAN 0.99-2016 - STATISTICS =============\n",
      " Total time ~ 14 ms\n",
      " Frequent sequences count : 2445\n",
      " Max memory (mb) : 10.53741455078125\n",
      " minsup = 1 sequences.\n",
      " Pattern count : 2445\n",
      "===================================================\n",
      "\n",
      "Post-processing to show result in terms of string values.\n",
      "Post-processing completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2445it [03:20, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum similarity:\n",
      "User: muzykujemy\n",
      "Similarity score: 6.420715563113335e-05\n"
     ]
    }
   ],
   "source": [
    "# Test the method\n",
    "sim_df = calculate_similarity(\"\"\"Jak to jest byÄ‡ skrybÄ…, dobrze? \n",
    "A, wie pan, moim zdaniem to nie ma tak, Å¼e dobrze, albo Å¼e niedobrze. \n",
    "Gdybym miaÅ‚ powiedzieÄ‡, co ceniÄ™ w Å¼yciu najbardziej, powiedziaÅ‚bym, Å¼e ludzi. \n",
    "Ludzi, ktÃ³rzy podali mi pomocnÄ… dÅ‚oÅ„, kiedy sobie nie radziÅ‚em, kiedy byÅ‚em sam, i co ciekawe, to wÅ‚aÅ›nie przypadkowe spotkania wpÅ‚ywajÄ… na nasze Å¼ycie. \n",
    "Chodzi o to, Å¼e kiedy wyznaje siÄ™ pewne wartoÅ›ci, nawet pozornie uniwersalne, bywa, Å¼e nie znajduje siÄ™ zrozumienia, \n",
    "ktÃ³re by tak rzec, ktÃ³re pomaga siÄ™ nam rozwijaÄ‡. \n",
    "Ja miaÅ‚em szczÄ™Å›cie, by tak rzec, poniewaÅ¼ je znalazÅ‚em, i dziÄ™kujÄ™ Å¼yciu! \n",
    "DziÄ™kujÄ™ mu; Å¼ycie to Å›piew, Å¼ycie to taniec, Å¼ycie to miÅ‚oÅ›Ä‡! \n",
    "Wielu ludzi pyta mnie o to samo: ale jak ty to robisz, skÄ…d czerpiesz tÄ™ radoÅ›Ä‡? \n",
    "A ja odpowiadam, Å¼e to proste! To umiÅ‚owanie Å¼ycia. \n",
    "To wÅ‚aÅ›nie ono sprawia, Å¼e dzisiaj na przykÅ‚ad budujÄ™ maszyny, a jutro â€“ kto wie? \n",
    "Dlaczego by nie â€“ oddam siÄ™ pracy spoÅ‚ecznej i bÄ™dÄ™, ot, choÄ‡by, sadziÄ‡... doÄ‡â€” m-marchew...\"\"\", word_map, word_df, available_arch_df)\n",
    "print(\"Maximum similarity:\\n\"\n",
    "        f\"User: {sim_df.idxmax()}\\n\"\n",
    "        f\"Similarity score: {sim_df.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64c951-ea72-47ab-9b15-ce071441cbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751cdee-37a1-4f5e-9734-bac89a4517e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
